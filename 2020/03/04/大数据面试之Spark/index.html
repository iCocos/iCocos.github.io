<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="http://pd1l3bbt7.bkt.clouddn.com/img/favicon.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="http://pd1l3bbt7.bkt.clouddn.com/img/favicon.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="http://pd1l3bbt7.bkt.clouddn.com/img/favicon.png?v=6.3.0">


  <link rel="mask-icon" href="http://pd1l3bbt7.bkt.clouddn.com/img/favicon.png?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="讲一下spark 的运行架构  Cluster Manager(Master)：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器  Worker节点：从节点，负责控制计算节点，启动Executor或者Driver。  Driver： 运行Application 的main()函数  Executor：执行器，是为某个Applicati">
<meta name="keywords" content="大数据,面试,Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据面试之Spark">
<meta property="og:url" content="https://icocos.github.io/2020/03/04/大数据面试之Spark/index.html">
<meta property="og:site_name" content="iCocos">
<meta property="og:description" content="讲一下spark 的运行架构  Cluster Manager(Master)：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器  Worker节点：从节点，负责控制计算节点，启动Executor或者Driver。  Driver： 运行Application 的main()函数  Executor：执行器，是为某个Applicati">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark架构图.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark程序执行流程.jpg">
<meta property="og:image" content="d:/Note/big-data-interview/BigData-Interview/pictures/spark-shuffle-v1.png">
<meta property="og:image" content="d:/Note/big-data-interview/BigData-Interview/pictures/spark-shuffle-v3.png">
<meta property="og:image" content="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/sparkShuffleWriter.jpg">
<meta property="og:image" content="d:/Note/big-data-interview/BigData-Interview/pictures/stageDivide.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark中的广播变量.png">
<meta property="og:image" content="https://github.com/JerryLead/SparkInternals/raw/master/markdown/PNGfigures/TorrentBroadcast.png">
<meta property="og:updated_time" content="2020-04-02T15:03:41.521Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="大数据面试之Spark">
<meta name="twitter:description" content="讲一下spark 的运行架构  Cluster Manager(Master)：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器  Worker节点：从节点，负责控制计算节点，启动Executor或者Driver。  Driver： 运行Application 的main()函数  Executor：执行器，是为某个Applicati">
<meta name="twitter:image" content="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark架构图.jpg">



  <link rel="alternate" href="/atom.xml" title="iCocos" type="application/atom+xml" />




  <link rel="canonical" href="https://icocos.github.io/2020/03/04/大数据面试之Spark/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>大数据面试之Spark | iCocos</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">iCocos</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">www.icocos.cn</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-首页">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-归档">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-关于">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-作品">
    <a href="/works/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />作品</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  
    <div class="reading-progress-bar"></div>
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://icocos.github.io/2020/03/04/大数据面试之Spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="曹理鹏@iCocos">
      <meta itemprop="description" content="纯码迷、爱学习、爱交友、喜欢接触新鲜事物、迎接新的挑战，更爱游离于错综复杂的编码与逻辑中！">
      <meta itemprop="image" content="http://pd1l3bbt7.bkt.clouddn.com/icocos_user_icon.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="iCocos">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">大数据面试之Spark
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-03-04 18:56:46" itemprop="dateCreated datePublished" datetime="2020-03-04T18:56:46+08:00">2020-03-04</time>
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-comment-o"></i>
              </span>
              
                <a href="/2020/03/04/大数据面试之Spark/#SOHUCS" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span id="changyan_count_unit" class="post-comments-count hc-comment-count" data-xid="2020/03/04/大数据面试之Spark/" itemprop="commentsCount"></span>
                </a>
              
            
          

          
          
             <span id="/2020/03/04/大数据面试之Spark/" class="leancloud_visitors" data-flag-title="大数据面试之Spark">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数：</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon"
            >
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">20k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">18 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="讲一下spark-的运行架构"><a href="#讲一下spark-的运行架构" class="headerlink" title="讲一下spark 的运行架构"></a>讲一下spark 的运行架构</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark架构图.jpg" alt=""></p>
<ul>
<li><p><strong>Cluster Manager(Master)</strong>：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器</p>
</li>
<li><p><strong>Worker节点</strong>：从节点，负责控制计算节点，启动Executor或者Driver。</p>
</li>
<li><p><strong>Driver</strong>： 运行Application 的main()函数</p>
</li>
<li><p><strong>Executor</strong>：执行器，是为某个Application运行在worker node上的一个进程</p>
</li>
</ul>
<a id="more"></a>
<p><a href="https://juejin.im/post/5a73c8386fb9a0635e3cafaa" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="一个spark程序的执行流程"><a href="#一个spark程序的执行流程" class="headerlink" title="一个spark程序的执行流程"></a>一个spark程序的执行流程</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark程序执行流程.jpg" alt=""></p>
<ul>
<li><strong>A -&gt;</strong> 当 Driver 进程被启动之后,首先它将发送请求到Master节点上,进行Spark应用程序的注册</li>
<li><strong>B -&gt;</strong> Master在接受到Spark应用程序的注册申请之后,会发送给Worker,让其进行资源的调度和分配.</li>
<li><strong>C -&gt;</strong> Worker 在接受Master的请求之后,会为Spark应用程序启动Executor, 来分配资源</li>
<li><strong>D -&gt;</strong> Executor启动分配资源好后,就会想Driver进行反注册,这是Driver已经知道哪些Executor为他服务了</li>
<li><strong>E -&gt;</strong> 当Driver得到注册了Executor之后,就可以开始正式执行spark应用程序了. 首先第一步,就是创建初始RDD,读取数据源,再执行之后的一系列算子. HDFS文件内容被读取到多个worker节点上,形成内存中的分布式数据集,也就是初始RDD</li>
<li><strong>F -&gt;</strong> Driver就会根据 Job 任务任务中的算子形成对应的task,最后提交给 Executor, 来分配给task进行计算的线程</li>
<li><strong>G -&gt;</strong> task就会去调用对应的任务数据来计算,并task会对调用过来的RDD的partition数据执行指定的算子操作,形成新的RDD的partition,这时一个大的循环就结束了</li>
<li>后续的RDD的partition数据又通过Driver形成新的一批task提交给Executor执行,循环这个操作,直到所有的算子结束</li>
</ul>
<p><a href="https://zhuanlan.zhihu.com/p/35713084" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="spark的shuffle介绍"><a href="#spark的shuffle介绍" class="headerlink" title="spark的shuffle介绍"></a>spark的shuffle介绍</h2><p><strong>spark中的shuffle主要有3种:</strong></p>
<ul>
<li><p><strong>Hash Shuffle</strong> 2.0以后移除</p>
<p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\spark-shuffle-v1.png" alt=""></p>
<p>在map阶段(shuffle write)，每个map都会为下游stage的每个partition写一个临时文件，假如下游stage有1000个partition，那么每个map都会生成1000个临时文件，一般来说一个executor上会运行多个map task，这样下来，一个executor上会有非常多的临时文件，假如一个executor上运行M个map task，下游stage有N个partition，那么一个executor上会生成M<em>N个文件。另一方面，如果一个executor上有K个core，那么executor同时可运行K个task，这样一来，就会同时申请K</em>N个文件描述符，一旦partition数较多，势必会耗尽executor上的文件描述符，同时生成K*N个write handler也会带来大量内存的消耗。</p>
<p>在reduce阶段(shuffle read)，每个reduce task都会拉取所有map对应的那部分partition数据，那么executor会打开所有临时文件准备网络传输，这里又涉及到大量文件描述符，另外，如果reduce阶段有combiner操作，那么它会把网络中拉到的数据保存在一个<code>HashMap</code>中进行合并操作，如果数据量较大，很容易引发OOM操作。</p>
</li>
<li><p><strong>Sort Shuffle</strong> 1.1开始(sort shuffle也经历过优化升级,详细见参考文章1)</p>
<p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\spark-shuffle-v3.png" alt=""></p>
<p>在map阶段(shuffle write)，会按照partition id以及key对记录进行排序，将所有partition的数据写在同一个文件中，该文件中的记录首先是按照partition id排序一个一个分区的顺序排列，每个partition内部是按照key进行排序存放，map task运行期间会顺序写每个partition的数据，并通过一个索引文件记录每个partition的大小和偏移量。这样一来，每个map task一次只开两个文件描述符，一个写数据，一个写索引，大大减轻了Hash Shuffle大量文件描述符的问题，即使一个executor有K个core，那么最多一次性开K*2个文件描述符。</p>
<p>在reduce阶段(shuffle read)，reduce task拉取数据做combine时不再是采用<code>HashMap</code>，而是采用<code>ExternalAppendOnlyMap</code>，该数据结构在做combine时，如果内存不足，会刷写磁盘，很大程度的保证了鲁棒性，避免大数据情况下的OOM。</p>
</li>
<li><p><strong>Unsafe Shuffle</strong> 1.5开始, 1.6与Sort shuffle合并</p>
<p>从spark 1.5.0开始，spark开始了钨丝计划(Tungsten)，目的是优化内存和CPU的使用，进一步提升spark的性能。为此，引入Unsafe Shuffle，它的做法是将数据记录用二进制的方式存储，直接在序列化的二进制数据上sort而不是在java 对象上，这样一方面可以减少memory的使用和GC的开销，另一方面避免shuffle过程中频繁的序列化以及反序列化。在排序过程中，它提供cache-efficient sorter，使用一个8 bytes的指针，把排序转化成了一个指针数组的排序，极大的优化了排序性能.</p>
</li>
</ul>
<hr>
<p><strong>现在2.1 分为三种writer， 分为 BypassMergeSortShuffleWriter， SortShuffleWriter 和 UnsafeShuffleWriter</strong></p>
<h4 id="三种Writer的分类"><a href="#三种Writer的分类" class="headerlink" title="三种Writer的分类"></a>三种Writer的分类</h4><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/sparkShuffleWriter.jpg" alt=""></p>
<p>上面是使用哪种 writer 的判断依据， 是否开启 mapSideCombine 这个判断，是因为有些算子会在 map 端先进行一次 combine， 减少传输数据。 因为 BypassMergeSortShuffleWriter 会临时输出Reducer个（分区数目）小文件，所以分区数必须要小于一个阀值，默认是小于200</p>
<p>UnsafeShuffleWriter需要Serializer支持relocation，Serializer支持relocation：原始数据首先被序列化处理，并且再也不需要反序列，在其对应的元数据被排序后，需要Serializer支持relocation，在指定位置读取对应数据</p>
<p><a href="http://sharkdtu.com/posts/spark-shuffle.html" target="_blank" rel="noopener">参考文章1</a></p>
<p><a href="http://spark.coolplayer.net/?p=576" target="_blank" rel="noopener">参考文章2</a></p>
<h2 id="Spark的-partitioner-都有哪些"><a href="#Spark的-partitioner-都有哪些" class="headerlink" title="Spark的 partitioner 都有哪些?"></a>Spark的 partitioner 都有哪些?</h2><p><strong>Partitioner主要有两个实现类：HashPartitioner和RangePartitioner,HashPartitioner是大部分transformation的默认实现，sortBy、sortByKey使用RangePartitioner实现，也可以自定义Partitioner.</strong></p>
<ul>
<li><p><strong>HashPartitioner</strong></p>
<p>numPartitions方法返回传入的分区数，getPartition方法使用key的hashCode值对分区数取模得到PartitionId，写入到对应的bucket中。</p>
</li>
<li><p><strong>RangePartitioner</strong></p>
<p>RangePartitioner是先根据所有partition中数据的分布情况，尽可能均匀地构造出重分区的分隔符，再将数据的key值根据分隔符进行重新分区</p>
<ul>
<li>使用reservoir Sample方法对每个Partition进行分别抽样</li>
<li>对数据量大(大于sampleSizePerPartition)的分区进行重新抽样</li>
<li>由权重信息计算出分区分隔符rangeBounds</li>
<li>由rangeBounds计算分区数和key的所属分区</li>
</ul>
</li>
</ul>
<p><a href="https://blog.csdn.net/qq_34842671/article/details/83685179" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="spark有哪几种join"><a href="#spark有哪几种join" class="headerlink" title="spark有哪几种join"></a>spark有哪几种join</h2><p><strong>Spark 中和 join 相关的算子有这几个</strong>：<code>join</code>、<code>fullOuterJoin</code>、<code>leftOuterJoin</code>、<code>rightOuterJoin</code></p>
<ul>
<li><p><strong>join</strong></p>
<p>join函数会输出两个RDD中key相同的所有项，并将它们的value联结起来，它联结的key要求在两个表中都存在，类似于SQL中的INNER JOIN。但它不满足交换律，a.join(b)与b.join(a)的结果不完全相同，值插入的顺序与调用关系有关。</p>
</li>
<li><p><strong>leftOuterJoin</strong></p>
<p>leftOuterJoin会保留对象的所有key，而用None填充在参数RDD other中缺失的值，因此调用顺序会使结果完全不同。如下面展示的结果，</p>
</li>
<li><p><strong>rightOuterJoin</strong></p>
<p>rightOuterJoin与leftOuterJoin基本一致，区别在于它的结果保留的是参数other这个RDD中所有的key。</p>
</li>
<li><p><strong>fullOuterJoin</strong></p>
<p>fullOuterJoin会保留两个RDD中所有的key，因此所有的值列都有可能出现缺失的情况，所有的值列都会转为Some对象。</p>
</li>
</ul>
<p><a href="http://www.neilron.xyz/join-in-spark/" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="RDD有哪些特点"><a href="#RDD有哪些特点" class="headerlink" title="RDD有哪些特点"></a>RDD有哪些特点</h2><ol>
<li><p><strong>A list of partitions</strong><br>RDD是一个由多个partition（某个节点里的某一片连续的数据）组成的的list；将数据加载为RDD时，一般会遵循数据的本地性（一般一个hdfs里的block会加载为一个partition）。</p>
</li>
<li><p><strong>A function for computing each split</strong><br>RDD的每个partition上面都会有function，也就是函数应用，其作用是实现RDD之间partition的转换。</p>
</li>
<li><p><strong>A list of dependencies on other RDDs</strong><br>RDD会记录它的依赖 ，为了容错（重算，cache，checkpoint），也就是说在内存中的RDD操作时出错或丢失会进行重算。</p>
</li>
<li><p><strong>Optionally,a Partitioner for Key-value RDDs</strong><br>  可选项，如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，例如这里自定义的Partitioner是基于key进行分区，那则会将不同RDD里面的相同key的数据放到同一个partition里面</p>
</li>
<li><p><strong>Optionally, a list of preferred locations to compute each split on</strong></p>
<p>最优的位置去计算，也就是数据的本地性。</p>
</li>
</ol>
<h2 id="讲一下宽依赖和窄依赖"><a href="#讲一下宽依赖和窄依赖" class="headerlink" title="讲一下宽依赖和窄依赖"></a>讲一下宽依赖和窄依赖</h2><p>区别宽窄依赖的核心点是 <strong>子RDD的partition与父RDD的partition是否是1对多的关系</strong>,如果是这样的关系的话,</p>
<p>说明多个父rdd的partition需要经过shuffle过程汇总到一个子rdd的partition,这样就是一次宽依赖,在DAGScheduler中会产生stage的切分.</p>
<h2 id="Spark中的算子都有哪些"><a href="#Spark中的算子都有哪些" class="headerlink" title="Spark中的算子都有哪些"></a>Spark中的算子都有哪些</h2><p>总的来说,spark分为两大类算子:</p>
<ul>
<li><p><strong>Transformation 变换/转换算子：这种变换并不触发提交作业，完成作业中间过程处理</strong></p>
<p>Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算</p>
</li>
<li><p><strong>Action 行动算子：这类算子会触发 SparkContext 提交 Job 作业</strong></p>
<p>Action 算子会触发 Spark 提交作业（Job），并将数据输出 Spark系统</p>
<hr>
</li>
</ul>
<h4 id="1-Value数据类型的Transformation算子"><a href="#1-Value数据类型的Transformation算子" class="headerlink" title="1. Value数据类型的Transformation算子"></a>1. Value数据类型的Transformation算子</h4><ul>
<li><p>输入分区与输出分区一对一型</p>
<ul>
<li>map算子</li>
<li>flatMap算子</li>
<li>mapPartitions算子</li>
<li>glom算子</li>
</ul>
</li>
<li><p>输入分区与输出分区多对一型</p>
<ul>
<li>union算子</li>
<li>cartesian算子</li>
</ul>
</li>
<li><p>输入分区与输出分区多对多型</p>
<ul>
<li>grouBy算子</li>
</ul>
</li>
<li><p>输出分区为输入分区子集型</p>
<ul>
<li>filter算子</li>
<li>distinct算子</li>
<li>subtract算子</li>
<li>sample算子</li>
<li>takeSample算子</li>
</ul>
</li>
<li><p>Cache型</p>
<ul>
<li>cache算子</li>
<li>persist算子</li>
</ul>
</li>
</ul>
<h4 id="2-Key-Value数据类型的Transfromation算子"><a href="#2-Key-Value数据类型的Transfromation算子" class="headerlink" title="2. Key-Value数据类型的Transfromation算子"></a>2. Key-Value数据类型的Transfromation算子</h4><ul>
<li><p>输入分区与输出分区一对一</p>
<ul>
<li>mapValues算子</li>
</ul>
</li>
<li><p>对单个RDD或两个RDD聚集</p>
<ul>
<li>combineByKey算子</li>
<li>reduceByKey算子</li>
<li>partitionBy算子</li>
<li>Cogroup算子</li>
</ul>
</li>
<li><p>连接</p>
<ul>
<li>join算子</li>
<li>leftOutJoin 和 rightOutJoin算子</li>
</ul>
</li>
</ul>
<h4 id="3-Action算子"><a href="#3-Action算子" class="headerlink" title="3. Action算子"></a>3. Action算子</h4><ul>
<li><p>无输出</p>
<ul>
<li>foreach算子</li>
</ul>
</li>
<li><p>HDFS算子</p>
<ul>
<li>saveAsTextFile算子</li>
<li>saveAsObjectFile算子</li>
</ul>
</li>
<li><p>Scala集合和数据类型</p>
<ul>
<li>collect算子</li>
<li>collectAsMap算子</li>
<li>reduceByKeyLocally算子</li>
<li>lookup算子</li>
<li>count算子</li>
<li>top算子</li>
<li>reduce算子</li>
<li>fold算子</li>
<li>aggregate算子</li>
<li>countByValue</li>
<li>countByKey</li>
</ul>
</li>
</ul>
<p><a href="https://www.cnblogs.com/kpsmile/p/10434390.html" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="RDD的缓存级别都有哪些"><a href="#RDD的缓存级别都有哪些" class="headerlink" title="RDD的缓存级别都有哪些"></a>RDD的缓存级别都有哪些</h2><p>NONE :什么类型都不是<br>DISK_ONLY：磁盘<br>DISK_ONLY_2：磁盘；双副本<br>MEMORY_ONLY： 内存；反序列化；把RDD作为反序列化的方式存储，假如RDD的内容存不下，剩余的分区在以后需要时会重新计算，不会刷到磁盘上。<br>MEMORY_ONLY_2：内存；反序列化；双副本<br>MEMORY_ONLY_SER：内存；序列化；这种序列化方式，每一个partition以字节数据存储，好处是能带来更好的空间存储，但CPU耗费高<br>MEMORY_ONLY_SER_2 : 内存；序列化；双副本<br>MEMORY_AND_DISK：内存 + 磁盘；反序列化；双副本；RDD以反序列化的方式存内存，假如RDD的内容存不下，剩余的会存到磁盘<br>MEMORY_AND_DISK_2 : 内存 + 磁盘；反序列化；双副本<br>MEMORY_AND_DISK_SER：内存 + 磁盘；序列化<br>MEMORY_AND_DISK_SER_2：内存 + 磁盘；序列化；双副本</p>
<h2 id="RDD懒加载是什么意思"><a href="#RDD懒加载是什么意思" class="headerlink" title="RDD懒加载是什么意思"></a>RDD懒加载是什么意思</h2><p>Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Acion 操作的时候才会真正触发运算,这也就是懒加载.</p>
<h2 id="讲一下spark的几种部署方式"><a href="#讲一下spark的几种部署方式" class="headerlink" title="讲一下spark的几种部署方式"></a>讲一下spark的几种部署方式</h2><p><strong>目前,除了local模式为本地调试模式以为, Spark支持三种分布式部署方式，分别是standalone、spark on mesos和 spark on YARN</strong></p>
<ul>
<li><p><strong>Standalone模式</strong></p>
<p>即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。从一定程度上说，该模式是其他两种的基础。目前Spark在standalone模式下是没有任何单点故障问题的，这是借助zookeeper实现的，思想类似于Hbase master单点故障解决方案。将Spark standalone与MapReduce比较，会发现它们两个在架构上是完全一致的： </p>
<ul>
<li>都是由master/slaves服务组成的，且起初master均存在单点故障，后来均通过zookeeper解决（Apache MRv1的JobTracker仍存在单点问题，但CDH版本得到了解决）； </li>
<li>各个节点上的资源被抽象成粗粒度的slot，有多少slot就能同时运行多少task。不同的是，MapReduce将slot分为map slot和reduce slot，它们分别只能供Map Task和Reduce Task使用，而不能共享，这是MapReduce资源利率低效的原因之一，而Spark则更优化一些，它不区分slot类型，只有一种slot，可以供各种类型的Task使用，这种方式可以提高资源利用率，但是不够灵活，不能为不同类型的Task定制slot资源。总之，这两种方式各有优缺点。 </li>
</ul>
</li>
<li><p><strong>Spark On YARN模式</strong></p>
<p><strong>spark on yarn 的支持两种模式：</strong> </p>
<ul>
<li>yarn-cluster：适用于生产环境； </li>
<li>yarn-client：适用于交互、调试，希望立即看到app的输出 </li>
</ul>
<p>yarn-cluster和yarn-client的区别在于yarn appMaster，每个yarn app实例有一个appMaster进程，是为app启动的第一个container；负责从ResourceManager请求资源，获取到资源后，告诉NodeManager为其启动container。yarn-cluster和yarn-client模式内部实现还是有很大的区别。如果你需要用于生产环境，那么请选择yarn-cluster；而如果你仅仅是Debug程序，可以选择yarn-client。</p>
</li>
<li><p><strong>Spark On Mesos模式</strong></p>
<p>Spark运行在Mesos上会比运行在YARN上更加灵活，更加自然。目前在Spark On Mesos环境中，用户可选择两种调度模式之一运行自己的应用程序</p>
<ul>
<li><p>粗粒度模式（Coarse-grained Mode）：每个应用程序的运行环境由一个Dirver和若干个Executor组成，其中，每个Executor占用若干资源，内部可运行多个Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。</p>
</li>
<li><p>细粒度模式（Fine-grained Mode）：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个Task运行完之后可以马上释放对应的资源。</p>
</li>
</ul>
<h2 id="spark-on-yarn-模式下的-cluster模式和-client模式有什么区别"><a href="#spark-on-yarn-模式下的-cluster模式和-client模式有什么区别" class="headerlink" title="spark on yarn 模式下的 cluster模式和 client模式有什么区别"></a>spark on yarn 模式下的 cluster模式和 client模式有什么区别</h2></li>
</ul>
<ol>
<li>yarn-cluster 适用于生产环境。而 yarn-client 适用于交互和调试，也就是希望快速地看到 application 的输出.</li>
<li>yarn-cluster 和 yarn-client 模式的区别其实就是 <strong>Application Master 进程</strong>的区别，yarn-cluster 模式下，driver 运行在 AM(Application Master)中，它负责向 YARN 申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉 Client，作业会继续在 YARN 上运行。然而 yarn-cluster 模式不适合运行交互类型的作业。而 yarn-client 模式下，Application Master 仅仅向 YARN 请求 executor，Client 会和请求的container 通信来调度他们工作，也就是说 Client 不能离开。</li>
</ol>
<h2 id="spark运行原理-从提交一个jar到最后返回结果-整个过程"><a href="#spark运行原理-从提交一个jar到最后返回结果-整个过程" class="headerlink" title="spark运行原理,从提交一个jar到最后返回结果,整个过程"></a>spark运行原理,从提交一个jar到最后返回结果,整个过程</h2><ol>
<li><code>spark-submit</code> 提交代码，执行 <code>new SparkContext()</code>，在 SparkContext 里构造 <code>DAGScheduler</code> 和 <code>TaskScheduler</code>。</li>
<li>TaskScheduler 会通过后台的一个进程，连接 Master，向 Master 注册 Application。</li>
<li>Master 接收到 Application 请求后，会使用相应的资源调度算法，在 Worker 上为这个 Application 启动多个 Executer。</li>
<li>Executor 启动后，会自己反向注册到 TaskScheduler 中。 所有 Executor 都注册到 Driver 上之后，SparkContext 结束初始化，接下来往下执行我们自己的代码。</li>
<li>每执行到一个 Action，就会创建一个 Job。Job 会提交给 DAGScheduler。</li>
<li>DAGScheduler 会将 Job划分为多个 stage，然后每个 stage 创建一个 TaskSet。</li>
<li>TaskScheduler 会把每一个 TaskSet 里的 Task，提交到 Executor 上执行。</li>
<li>Executor 上有线程池，每接收到一个 Task，就用 TaskRunner 封装，然后从线程池里取出一个线程执行这个 task。(TaskRunner 将我们编写的代码，拷贝，反序列化，执行 Task，每个 Task 执行 RDD 里的一个 partition)</li>
</ol>
<h2 id="spark的stage是如何划分的"><a href="#spark的stage是如何划分的" class="headerlink" title="spark的stage是如何划分的"></a>spark的stage是如何划分的</h2><p><strong>stage的划分依据就是看是否产生了shuflle(即宽依赖),遇到一个shuffle操作就划分为前后两个stage.</strong></p>
<p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\stageDivide.jpg" alt=""></p>
<h2 id="spark2-0为什么放弃了akka-而用netty"><a href="#spark2-0为什么放弃了akka-而用netty" class="headerlink" title="spark2.0为什么放弃了akka 而用netty"></a>spark2.0为什么放弃了akka 而用netty</h2><ol>
<li>很多Spark用户也使用Akka，但是由于Akka不同版本之间无法互相通信，这就要求用户必须使用跟Spark完全一样的Akka版本，导致用户无法升级Akka。</li>
<li>Spark的Akka配置是针对Spark自身来调优的，可能跟用户自己代码中的Akka配置冲突。</li>
<li>Spark用的Akka特性很少，这部分特性很容易自己实现。同时，这部分代码量相比Akka来说少很多，debug比较容易。如果遇到什么bug，也可以自己马上fix，不需要等Akka上游发布新版本。而且，Spark升级Akka本身又因为第一点会强制要求用户升级他们使用的Akka，对于某些用户来说是不现实的。</li>
</ol>
<p><a href="https://www.zhihu.com/question/61638635" target="_blank" rel="noopener">参考文章</a></p>
<h2 id="spark的各种HA-master-worker-executor的ha"><a href="#spark的各种HA-master-worker-executor的ha" class="headerlink" title="spark的各种HA,  master/worker/executor的ha"></a>spark的各种HA,  master/worker/executor的ha</h2><ul>
<li><h4 id="Master异常"><a href="#Master异常" class="headerlink" title="Master异常"></a>Master异常</h4><p>spark可以在集群运行时启动一个或多个standby Master,当 Master 出现异常时,会根据规则启动某个standby master接管,在standlone模式下有如下几种配置</p>
<ul>
<li><p>ZOOKEEPER</p>
<p>集群数据持久化到zk中,当master出现异常时,zk通过选举机制选出新的master,新的master接管是需要从zk获取持久化信息</p>
</li>
<li><p>FILESYSTEM</p>
<p>集群元数据信息持久化到本地文件系统, 当master出现异常时,只需要在该机器上重新启动master,启动后新的master获取持久化信息并根据这些信息恢复集群状态</p>
</li>
<li><p>CUSTOM</p>
<p>自定义恢复方式,对 standloneRecoveryModeFactory 抽象类 进行实现并把该类配置到系统中,当master出现异常时,会根据用户自定义行为恢复集群</p>
</li>
<li><p>None</p>
<p>不持久化集群的元数据, 当 master出现异常时, 新启动的Master 不进行恢复集群状态,而是直接接管集群</p>
</li>
</ul>
</li>
<li><h4 id="Worker异常"><a href="#Worker异常" class="headerlink" title="Worker异常"></a>Worker异常</h4><p>Worker 以定时发送心跳给 Master, 让 Master 知道 Worker 的实时状态,当worker出现超时时,Master 调用 timeOutDeadWorker 方法进行处理,在处理时根据 Worker 运行的是 Executor 和 Driver 分别进行处理</p>
<ul>
<li>如果是Executor, Master先把该 Worker 上运行的Executor 发送信息ExecutorUpdate给对应的Driver,告知Executor已经丢失,同时把这些Executor从其应用程序列表删除, 另外, 相关Executor的异常也需要处理</li>
<li>如果是Driver, 则判断是否设置重新启动,如果需要,则调用Master.shedule方法进行调度,分配合适节点重启Driver, 如果不需要重启, 则删除该应用程序</li>
</ul>
</li>
<li><h4 id="Executor异常"><a href="#Executor异常" class="headerlink" title="Executor异常"></a>Executor异常</h4><ol>
<li>Executor发生异常时由ExecutorRunner捕获该异常并发送ExecutorStateChanged信息给Worker</li>
<li>Worker接收到消息时, 在Worker的 handleExecutorStateChanged 方法中, 根据Executor状态进行信息更新,同时把Executor状态发送给Master</li>
<li>Master在接受Executor状态变化消息之后,如果发现其是异常退出,会尝试可用的Worker节点去启动Executor</li>
</ol>
</li>
</ul>
<h2 id="spark的内存管理机制"><a href="#spark的内存管理机制" class="headerlink" title="spark的内存管理机制"></a>spark的内存管理机制</h2><p><strong>spark的内存结构分为3大块:storage/execution/系统自留</strong></p>
<ul>
<li><p><strong>storage 内存</strong>：用于缓存 RDD、展开 partition、存放 Direct Task Result、存放广播变量。在 Spark Streaming receiver 模式中，也用来存放每个 batch 的 blocks</p>
</li>
<li><p><strong>execution 内存</strong>：用于 shuffle、join、sort、aggregation 中的缓存、buffer</p>
</li>
<li><p><strong>系统自留</strong>:</p>
<ul>
<li><p>在 spark 运行过程中使用：比如序列化及反序列化使用的内存，各个对象、元数据、临时变量使用的内存，函数调用使用的堆栈等</p>
</li>
<li><p>作为误差缓冲：由于 storage 和 execution 中有很多内存的使用是估算的，存在误差。当 storage 或 execution 内存使用超出其最大限制时，有这样一个安全的误差缓冲在可以大大减小 OOM 的概率</p>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="1-6版本以前的问题"><a href="#1-6版本以前的问题" class="headerlink" title="1.6版本以前的问题"></a>1.6版本以前的问题</h4><ul>
<li>旧方案最大的问题是 storage 和 execution 的内存大小都是固定的，不可改变，即使 execution 有大量的空闲内存且 storage 内存不足，storage 也无法使用 execution 的内存，只能进行 spill，反之亦然。所以，在很多情况下存在资源浪费</li>
<li>旧方案中，只有 execution 内存支持 off heap，storage 内存不支持 off heap</li>
</ul>
<h4 id="新方案的改进"><a href="#新方案的改进" class="headerlink" title="新方案的改进"></a>新方案的改进</h4><ul>
<li>新方案 storage 和 execution 内存可以互相借用，当一方内存不足可以向另一方借用内存，提高了整体的资源利用率</li>
<li>新方案中 execution 内存和 storage 内存均支持 off heap</li>
</ul>
<h2 id="spark中的广播变量"><a href="#spark中的广播变量" class="headerlink" title="spark中的广播变量"></a>spark中的广播变量</h2><p><a href="https://www.jianshu.com/p/6ef7f0a44fbf" target="_blank" rel="noopener">图片来源</a> /<a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/7-Broadcast.md" target="_blank" rel="noopener">文字来源</a></p>
<p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark中的广播变量.png" alt=""></p>
<p><strong>顾名思义，broadcast 就是将数据从一个节点发送到其他各个节点上去。这样的场景很多，比如 driver 上有一张表，其他节点上运行的 task 需要 lookup 这张表，那么 driver 可以先把这张表 copy 到这些节点，这样 task 就可以在本地查表了。如何实现一个可靠高效的 broadcast 机制是一个有挑战性的问题。先看看 Spark 官网上的一段话：</strong></p>
<p>Broadcast variables allow the programmer to keep a <strong>read-only</strong> variable cached on each <strong>machine</strong> rather than shipping a copy of it with <strong>tasks</strong>. They can be used, for example, to give every node a copy of a <strong>large input dataset</strong> in an efficient manner. Spark also attempts to distribute broadcast variables using <strong>efficient</strong> broadcast algorithms to reduce communication cost.</p>
<h3 id="问题：为什么只能-broadcast-只读的变量？"><a href="#问题：为什么只能-broadcast-只读的变量？" class="headerlink" title="问题：为什么只能 broadcast 只读的变量？"></a>问题：为什么只能 broadcast 只读的变量？</h3><p>这就涉及一致性的问题，如果变量可以被更新，那么一旦变量被某个节点更新，其他节点要不要一块更新？如果多个节点同时在更新，更新顺序是什么？怎么做同步？还会涉及 fault-tolerance 的问题。为了避免维护数据一致性问题，Spark 目前只支持 broadcast 只读变量。</p>
<h3 id="问题：broadcast-到节点而不是-broadcast-到每个-task？"><a href="#问题：broadcast-到节点而不是-broadcast-到每个-task？" class="headerlink" title="问题：broadcast 到节点而不是 broadcast 到每个 task？"></a>问题：broadcast 到节点而不是 broadcast 到每个 task？</h3><p>因为每个 task 是一个线程，而且同在一个进程运行 tasks 都属于同一个 application。因此每个节点（executor）上放一份就可以被所有 task 共享。</p>
<h3 id="问题：-具体怎么用-broadcast？"><a href="#问题：-具体怎么用-broadcast？" class="headerlink" title="问题： 具体怎么用 broadcast？"></a>问题： 具体怎么用 broadcast？</h3><p>driver program 例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val data = List(1, 2, 3, 4, 5, 6)</span><br><span class="line">val bdata = sc.broadcast(data)</span><br><span class="line"></span><br><span class="line">val rdd = sc.parallelize(1 to 6, 2)</span><br><span class="line">val observedSizes = rdd.map(_ =&gt; bdata.value.size)</span><br></pre></td></tr></table></figure>
<p>driver 使用 <code>sc.broadcast()</code> 声明要 broadcast 的 data，bdata 的类型是 Broadcast。</p>
<p>当 <code>rdd.transformation(func)</code> 需要用 bdata 时，直接在 func 中调用，比如上面的例子中的 map() 就使用了 bdata.value.size。</p>
<h3 id="问题：怎么实现-broadcast？"><a href="#问题：怎么实现-broadcast？" class="headerlink" title="问题：怎么实现 broadcast？"></a>问题：怎么实现 broadcast？</h3><p>broadcast 的实现机制很有意思：</p>
<h4 id="1-分发-task-的时候先分发-bdata-的元信息"><a href="#1-分发-task-的时候先分发-bdata-的元信息" class="headerlink" title="1. 分发 task 的时候先分发 bdata 的元信息"></a>1. 分发 task 的时候先分发 bdata 的元信息</h4><p>Driver 先建一个本地文件夹用以存放需要 broadcast 的 data，并启动一个可以访问该文件夹的 HttpServer。当调用<code>val bdata = sc.broadcast(data)</code>时就把 data 写入文件夹，同时写入 driver 自己的 blockManger 中（StorageLevel 为内存＋磁盘），获得一个 blockId，类型为 BroadcastBlockId。当调用<code>rdd.transformation(func)</code>时，如果 func 用到了 bdata，那么 driver submitTask() 的时候会将 bdata 一同 func 进行序列化得到 serialized task，<strong>注意序列化的时候不会序列化 bdata 中包含的 data。</strong>上一章讲到 serialized task 从 driverActor 传递到 executor 时使用 Akka 的传消息机制，消息不能太大，而实际的 data 可能很大，所以这时候还不能 broadcast data。</p>
<blockquote>
<p>driver 为什么会同时将 data 放到磁盘和 blockManager 里面？放到磁盘是为了让 HttpServer 访问到，放到 blockManager 是为了让 driver program 自身使用 bdata 时方便（其实我觉得不放到 blockManger 里面也行）。</p>
</blockquote>
<p><strong>那么什么时候传送真正的 data？</strong>在 executor 反序列化 task 的时候，会同时反序列化 task 中的 bdata 对象，这时候会调用 bdata 的 readObject() 方法。该方法先去本地 blockManager 那里询问 bdata 的 data 在不在 blockManager 里面，如果不在就使用下面的两种 fetch 方式之一去将 data fetch 过来。得到 data 后，将其存放到 blockManager 里面，这样后面运行的 task 如果需要 bdata 就不需要再去 fetch data 了。如果在，就直接拿来用了。</p>
<p>下面探讨 broadcast data 时候的两种实现方式：</p>
<h4 id="2-HttpBroadcast"><a href="#2-HttpBroadcast" class="headerlink" title="2. HttpBroadcast"></a>2. HttpBroadcast</h4><p>顾名思义，HttpBroadcast 就是每个 executor 通过的 http 协议连接 driver 并从 driver 那里 fetch data。</p>
<p>Driver 先准备好要 broadcast 的 data，调用<code>sc.broadcast(data)</code>后会调用工厂方法建立一个 HttpBroadcast 对象。该对象做的第一件事就是将 data 存到 driver 的 blockManager 里面，StorageLevel 为内存＋磁盘，blockId 类型为 BroadcastBlockId。</p>
<p>同时 driver 也会将 broadcast 的 data 写到本地磁盘，例如写入后得到 <code>/var/folders/87/grpn1_fn4xq5wdqmxk31v0l00000gp/T/spark-6233b09c-3c72-4a4d-832b-6c0791d0eb9c/broadcast_0</code>， 这个文件夹作为 HttpServer 的文件目录。</p>
<blockquote>
<p>Driver 和 executor 启动的时候，都会生成 broadcastManager 对象，调用 HttpBroadcast.initialize()，driver 会在本地建立一个临时目录用来存放 broadcast 的 data，并启动可以访问该目录的 httpServer。</p>
</blockquote>
<p><strong>Fetch data：</strong>在 executor 反序列化 task 的时候，会同时反序列化 task 中的 bdata 对象，这时候会调用 bdata 的 readObject() 方法。该方法先去本地 blockManager 那里询问 bdata 的 data 在不在 blockManager 里面，<strong>如果不在就使用 http 协议连接 driver 上的 httpServer，将 data fetch 过来。</strong>得到 data 后，将其存放到 blockManager 里面，这样后面运行的 task 如果需要 bdata 就不需要再去 fetch data 了。如果在，就直接拿来用了。</p>
<p>HttpBroadcast 最大的问题就是 <strong>driver 所在的节点可能会出现网络拥堵</strong>，因为 worker 上的 executor 都会去 driver 那里 fetch 数据。</p>
<h4 id="3-TorrentBroadcast"><a href="#3-TorrentBroadcast" class="headerlink" title="3. TorrentBroadcast"></a>3. TorrentBroadcast</h4><p>为了解决 HttpBroadast 中 driver 单点网络瓶颈的问题，Spark 又设计了一种 broadcast 的方法称为 TorrentBroadcast，<strong>这个类似于大家常用的 BitTorrent 技术。</strong>基本思想就是将 data 分块成 data blocks，然后假设有 executor fetch 到了一些 data blocks，那么这个 executor 就可以被当作 data server 了，随着 fetch 的 executor 越来越多，有更多的 data server 加入，data 就很快能传播到全部的 executor 那里去了。</p>
<p>HttpBroadcast 是通过传统的 http 协议和 httpServer 去传 data，在 TorrentBroadcast 里面使用在上一章介绍的 blockManager.getRemote() =&gt; NIO ConnectionManager 传数据的方法来传递，读取数据的过程与读取 cached rdd 的方式类似，可以参阅 <a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md" target="_blank" rel="noopener">CacheAndCheckpoint</a> 中的最后一张图。</p>
<p>下面讨论 TorrentBroadcast 的一些细节：</p>
<p><a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/PNGfigures/TorrentBroadcast.png" target="_blank" rel="noopener"><img src="https://github.com/JerryLead/SparkInternals/raw/master/markdown/PNGfigures/TorrentBroadcast.png" alt="TorrentBroadcast"></a></p>
<h4 id="driver-端："><a href="#driver-端：" class="headerlink" title="driver 端："></a>driver 端：</h4><p>Driver 先把 data 序列化到 byteArray，然后切割成 BLOCK_SIZE（由 <code>spark.broadcast.blockSize = 4MB</code> 设置）大小的 data block，每个 data block 被 TorrentBlock 对象持有。切割完 byteArray 后，会将其回收，因此内存消耗虽然可以达到 2 * Size(data)，但这是暂时的。</p>
<p>完成分块切割后，就将分块信息（称为 meta 信息）存放到 driver 自己的 blockManager 里面，StorageLevel 为内存＋磁盘，同时会通知 driver 自己的 blockManagerMaster 说 meta 信息已经存放好。<strong>通知 blockManagerMaster 这一步很重要，因为 blockManagerMaster 可以被 driver 和所有 executor 访问到，信息被存放到 blockManagerMaster 就变成了全局信息。</strong></p>
<p>之后将每个分块 data block 存放到 driver 的 blockManager 里面，StorageLevel 为内存＋磁盘。存放后仍然通知 blockManagerMaster 说 blocks 已经存放好。到这一步，driver 的任务已经完成。</p>
<h4 id="Executor-端："><a href="#Executor-端：" class="headerlink" title="Executor 端："></a>Executor 端：</h4><p>executor 收到 serialized task 后，先反序列化 task，这时候会反序列化 serialized task 中包含的 bdata 类型是 TorrentBroadcast，也就是去调用 TorrentBroadcast.readObject()。这个方法首先得到 bdata 对象，<strong>然后发现 bdata 里面没有包含实际的 data。怎么办？</strong>先询问所在的 executor 里的 blockManager 是会否包含 data（通过查询 data 的 broadcastId），包含就直接从本地 blockManager 读取 data。否则，就通过本地 blockManager 去连接 driver 的 blockManagerMaster 获取 data 分块的 meta 信息，获取信息后，就开始了 BT 过程。</p>
<p><strong>BT 过程：</strong>task 先在本地开一个数组用于存放将要 fetch 过来的 data blocks <code>arrayOfBlocks = new Array[TorrentBlock](totalBlocks)</code>，TorrentBlock 是对 data block 的包装。然后打乱要 fetch 的 data blocks 的顺序，比如如果 data block 共有 5 个，那么打乱后的 fetch 顺序可能是 3-1-2-4-5。然后按照打乱后的顺序去 fetch 一个个 data block。fetch 的过程就是通过 “本地 blockManager －本地 connectionManager－driver/executor 的 connectionManager－driver/executor 的 blockManager－data” 得到 data，这个过程与 fetch cached rdd 类似。<strong>每 fetch 到一个 block 就将其存放到 executor 的 blockManager 里面，同时通知 driver 上的 blockManagerMaster 说该 data block 多了一个存储地址。</strong>这一步通知非常重要，意味着 blockManagerMaster 知道 data block 现在在 cluster 中有多份，下一个不同节点上的 task 再去 fetch 这个 data block 的时候，可以有两个选择了，而且会随机选择一个去 fetch。这个过程持续下去就是 BT 协议，随着下载的客户端越来越多，data block 服务器也越来越多，就变成 p2p下载了。关于 BT 协议，Wikipedia 上有一个<a href="http://zh.wikipedia.org/wiki/BitTorrent_(%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">动画</a>)。</p>
<p>整个 fetch 过程结束后，task 会开一个大 Array[Byte]，大小为 data 的总大小，然后将 data block 都 copy 到这个 Array，然后对 Array 中 bytes 进行反序列化得到原始的 data，这个过程就是 driver 序列化 data 的反过程。</p>
<p>最后将 data 存放到 task 所在 executor 的 blockManager 里面，StorageLevel 为内存＋磁盘。显然，这时候 data 在 blockManager 里存了两份，不过等全部 executor 都 fetch 结束，存储 data blocks 那份可以删掉了。</p>
<h3 id="问题：broadcast-RDD-会怎样"><a href="#问题：broadcast-RDD-会怎样" class="headerlink" title="问题：broadcast RDD 会怎样?"></a>问题：broadcast RDD 会怎样?</h3><p><a href="http://weibo.com/u/1410938285" target="_blank" rel="noopener">@Andrew-Xia</a> 回答道：不会怎样，就是这个rdd在每个executor中实例化一份。</p>
<h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>公共数据的 broadcast 是很实用的功能，在 Hadoop 中使用 DistributedCache，比如常用的<code>-libjars</code>就是使用 DistributedCache 来将 task 依赖的 jars 分发到每个 task 的工作目录。不过分发前 DistributedCache 要先将文件上传到 HDFS。这种方式的主要问题是<strong>资源浪费</strong>，如果某个节点上要运行来自同一 job 的 4 个 mapper，那么公共数据会在该节点上存在 4 份（每个 task 的工作目录会有一份）。但是通过 HDFS 进行 broadcast 的好处在于<strong>单点瓶颈不明显</strong>，因为公共 data 首先被分成多个 block，然后不同的 block 存放在不同的节点。这样，只要所有的 task 不是同时去同一个节点 fetch 同一个 block，网络拥塞不会很严重。</p>
<p>对于 Spark 来讲，broadcast 时考虑的不仅是如何将公共 data 分发下去的问题，还要考虑如何让同一节点上的 task 共享 data。</p>
<p>对于第一个问题，Spark 设计了两种 broadcast 的方式，传统存在单点瓶颈问题的 HttpBroadcast，和类似 BT 方式的 TorrentBroadcast。HttpBroadcast 使用传统的 client-server 形式的 HttpServer 来传递真正的 data，而 TorrentBroadcast 使用 blockManager 自带的 NIO 通信方式来传递 data。TorrentBroadcast 存在的问题是<strong>慢启动</strong>和<strong>占内存</strong>，慢启动指的是刚开始 data 只在 driver 上有，要等 executors fetch 很多轮 data block 后，data server 才会变得可观，后面的 fetch 速度才会变快。executor 所占内存的在 fetch 完 data blocks 后进行反序列化时需要将近两倍 data size 的内存消耗。不管哪一种方式，driver 在分块时会有两倍 data size 的内存消耗。</p>
<p>对于第二个问题，每个 executor 都包含一个 blockManager 用来管理存放在 executor 里的数据，将公共数据存放在 blockManager 中（StorageLevel 为内存＋磁盘），可以保证在 executor 执行的 tasks 能够共享 data。</p>
<p>其实 Spark 之前还尝试了一种称为 TreeBroadcast 的机制，详情可以见技术报告 <a href="http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf" target="_blank" rel="noopener">Performance and Scalability of Broadcast in Spark</a>。</p>
<p>更深入点，broadcast 可以用多播协议来做，不过多播使用 UDP，不是可靠的，仍然需要应用层的设计一些可靠性保障机制。</p>
<h2 id="什么是数据倾斜-怎样去处理数据倾斜"><a href="#什么是数据倾斜-怎样去处理数据倾斜" class="headerlink" title="什么是数据倾斜,怎样去处理数据倾斜"></a>什么是数据倾斜,怎样去处理数据倾斜</h2><p>数据倾斜是一种很常见的问题（依据二八定律），简单来说，比方WordCount中某个Key对应的数据量非常大的话，就会产生数据倾斜，导致两个后果：</p>
<ul>
<li>OOM（单或少数的节点）；</li>
<li>拖慢整个Job执行时间（其他已经完成的节点都在等这个还在做的节点）</li>
</ul>
<h4 id="数据倾斜主要分为两类-聚合倾斜-和-join倾斜"><a href="#数据倾斜主要分为两类-聚合倾斜-和-join倾斜" class="headerlink" title="数据倾斜主要分为两类: 聚合倾斜 和 join倾斜"></a>数据倾斜主要分为两类: 聚合倾斜 和 join倾斜</h4><ul>
<li><p><strong>聚合倾斜</strong></p>
<ul>
<li><p><strong>双重聚合（局部聚合+全局聚合）</strong></p>
<p><strong>场景</strong>: 对RDD进行reduceByKey等聚合类shuffle算子，SparkSQL的groupBy做分组聚合这两种情况<br> 思路：首先通过map给每个key打上n以内的随机数的前缀并进行局部聚合，即(hello, 1) (hello, 1) (hello, 1) (hello, 1)变为(1_hello, 1) (1_hello, 1) (2_hello, 1)，并进行reduceByKey的局部聚合，然后再次map将key的前缀随机数去掉再次进行全局聚合；<br> <strong>原理</strong>: 对原本相同的key进行随机数附加，变成不同key，让原本一个task处理的数据分摊到多个task做局部聚合，规避单task数据过量。之后再去随机前缀进行全局聚合；<br> 优点：效果非常好（对聚合类Shuffle操作的倾斜问题）；<br> 缺点：范围窄（仅适用于聚合类的Shuffle操作，join类的Shuffle还需其它方案）</p>
</li>
</ul>
</li>
<li><p><strong>join倾斜</strong></p>
<ul>
<li><p><strong>将reduce join转为map join</strong></p>
<p><strong>场景</strong>: 对RDD或Spark SQL使用join类操作或语句，且join操作的RDD或表比较小（百兆或1,2G）； 思路：使用broadcast和map类算子实现join的功能替代原本的join，彻底规避shuffle。对较小RDD直接collect到内存，并创建broadcast变量；并对另外一个RDD执行map类算子，在该算子的函数中，从broadcast变量（collect出的较小RDD）与当前RDD中的每条数据依次比对key，相同的key执行你需要方式的join；</p>
<p><strong>原理</strong>: 若RDD较小，可采用广播小的RDD，并对大的RDD进行map，来实现与join同样的效果。简而言之，用broadcast-map代替join，规避join带来的shuffle（无Shuffle无倾斜）； 优点：效果很好（对join操作导致的倾斜），根治； </p>
<p><strong>缺点</strong>：适用场景小（大表+小表），广播（driver和executor节点都会驻留小表数据）小表也耗内存</p>
</li>
<li><p><strong>采样倾斜key并分拆join操作</strong></p>
<p><strong>场景</strong>: 两个较大的（无法采用方案五）RDD/Hive表进行join时，且一个RDD/Hive表中少数key数据量过大，另一个RDD/Hive表的key分布较均匀（RDD中两者之一有一个更倾斜）；<br><strong>思路</strong>:</p>
<ol>
<li>对更倾斜rdd1进行采样（RDD.sample）并统计出数据量最大的几个key；</li>
<li>对这几个倾斜的key从原本rdd1中拆出形成一个单独的rdd1_1，并打上0~n的随机数前缀，被拆分的原rdd1的另一部分（不包含倾斜key）又形成一个新rdd1_2；</li>
<li>对rdd2过滤出rdd1倾斜的key，得到rdd2_1，并将其中每条数据扩n倍，对每条数据按顺序附加0~n的前缀，被拆分出key的rdd2也独立形成另一个rdd2_2； 【个人认为，这里扩了n倍，最后union完还需要将每个倾斜key对应的value减去(n-1)】</li>
<li>将加了随机前缀的rdd1_1和rdd2_1进行join（此时原本倾斜的key被打散n份并被分散到更多的task中进行join）； 【个人认为，这里应该做两次join，两次join中间有一个map去前缀】</li>
<li>另外两个普通的RDD（rdd1_2、rdd2_2）照常join；</li>
<li>最后将两次join的结果用union结合得到最终的join结果。 原理：对join导致的倾斜是因为某几个key，可将原本RDD中的倾斜key拆分出原RDD得到新RDD，并以加随机前缀的方式打散n份做join，将倾斜key对应的大量数据分摊到更多task上来规避倾斜；</li>
</ol>
<p><strong>优点</strong>: 前提是join导致的倾斜（某几个key倾斜），避免占用过多内存（只需对少数倾斜key扩容n倍）；<br><strong>缺点</strong>: 对过多倾斜key不适用。</p>
</li>
<li><p><strong>用随机前缀和扩容RDD进行join</strong></p>
<p><strong>场景</strong>: RDD中有大量key导致倾斜； 思路：与方案六类似。</p>
<ol>
<li>查看RDD/Hive表中数据分布并找到造成倾斜的RDD/表；</li>
<li>对倾斜RDD中的每条数据打上n以内的随机数前缀；</li>
<li>对另外一个正常RDD的每条数据扩容n倍，扩容出的每条数据依次打上0到n的前缀；</li>
<li>对处理后的两个RDD进行join。</li>
</ol>
<p><strong>原理</strong>: 与方案六只有唯一不同在于这里对不倾斜RDD中所有数据进行扩大n倍，而不是找出倾斜key进行扩容；<br><strong>优点</strong>: 对join类的数据倾斜都可处理，效果非常显著；<br><strong>缺点</strong>: 缓解，扩容需要大内存</p>
</li>
</ul>
</li>
</ul>
<p><a href="https://juejin.im/post/5ccd5cc7f265da03474e1249#heading-9" target="_blank" rel="noopener">参考文章1</a></p>
<p><a href="https://blog.csdn.net/qq_35394891/article/details/82260907" target="_blank" rel="noopener">参考文章2</a></p>
<h2 id="分析一下一段spark代码中哪些部分在Driver端执行-哪些部分在Worker端执行"><a href="#分析一下一段spark代码中哪些部分在Driver端执行-哪些部分在Worker端执行" class="headerlink" title="分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行"></a>分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行</h2><p>Driver Program是用户编写的提交给Spark集群执行的application，它包含两部分</p>
<ul>
<li><strong>作为驱动</strong>： Driver与Master、Worker协作完成application进程的启动、DAG划分、计算任务封装、计算任务分发到各个计算节点(Worker)、计算资源的分配等。</li>
<li><strong>计算逻辑本身</strong>，当计算任务在Worker执行时，执行计算逻辑完成application的计算任务</li>
</ul>
<p>一般来说transformation算子均是在worker上执行的,其他类型的代码在driver端执行</p>

      
    </div>

    

    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="http://pd1l3bbt7.bkt.clouddn.com/img/wechatimg.jpg" alt="曹理鹏@iCocos 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="http://pd1l3bbt7.bkt.clouddn.com/img/alipayimg.jpg" alt="曹理鹏@iCocos 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>曹理鹏@iCocos</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://icocos.github.io/2020/03/04/大数据面试之Spark/" title="大数据面试之Spark">https://icocos.github.io/2020/03/04/大数据面试之Spark/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/大数据/" rel="tag"># 大数据</a>
          
            <a href="/tags/面试/" rel="tag"># 面试</a>
          
            <a href="/tags/Spark/" rel="tag"># Spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/02/大数据面试之Hive/" rel="next" title="大数据面试之Hive">
                <i class="fa fa-chevron-left"></i> 大数据面试之Hive
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/03/05/大数据面试之Flink/" rel="prev" title="大数据面试之Flink">
                大数据面试之Flink <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="SOHUCS"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="http://pd1l3bbt7.bkt.clouddn.com/icocos_user_icon.JPG"
                alt="曹理鹏@iCocos" />
            
              <p class="site-author-name" itemprop="name">曹理鹏@iCocos</p>
              <p class="site-description motion-element" itemprop="description">纯码迷、爱学习、爱交友、喜欢接触新鲜事物、迎接新的挑战，更爱游离于错综复杂的编码与逻辑中！</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">102</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">分类</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">116</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/al1020119" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:al1020119@163.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://stackoverflow.com/users/10186720" target="_blank" title="StackOverflow"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.icocos.cn/" title="梦工厂" target="_blank">梦工厂</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://al1020119.github.io/" title="iOS梦工厂" target="_blank">iOS梦工厂</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#讲一下spark-的运行架构"><span class="nav-number">1.</span> <span class="nav-text">讲一下spark 的运行架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一个spark程序的执行流程"><span class="nav-number">2.</span> <span class="nav-text">一个spark程序的执行流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark的shuffle介绍"><span class="nav-number">3.</span> <span class="nav-text">spark的shuffle介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#三种Writer的分类"><span class="nav-number">3.0.1.</span> <span class="nav-text">三种Writer的分类</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark的-partitioner-都有哪些"><span class="nav-number">4.</span> <span class="nav-text">Spark的 partitioner 都有哪些?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark有哪几种join"><span class="nav-number">5.</span> <span class="nav-text">spark有哪几种join</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD有哪些特点"><span class="nav-number">6.</span> <span class="nav-text">RDD有哪些特点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#讲一下宽依赖和窄依赖"><span class="nav-number">7.</span> <span class="nav-text">讲一下宽依赖和窄依赖</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark中的算子都有哪些"><span class="nav-number">8.</span> <span class="nav-text">Spark中的算子都有哪些</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-Value数据类型的Transformation算子"><span class="nav-number">8.0.1.</span> <span class="nav-text">1. Value数据类型的Transformation算子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Key-Value数据类型的Transfromation算子"><span class="nav-number">8.0.2.</span> <span class="nav-text">2. Key-Value数据类型的Transfromation算子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Action算子"><span class="nav-number">8.0.3.</span> <span class="nav-text">3. Action算子</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD的缓存级别都有哪些"><span class="nav-number">9.</span> <span class="nav-text">RDD的缓存级别都有哪些</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD懒加载是什么意思"><span class="nav-number">10.</span> <span class="nav-text">RDD懒加载是什么意思</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#讲一下spark的几种部署方式"><span class="nav-number">11.</span> <span class="nav-text">讲一下spark的几种部署方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark-on-yarn-模式下的-cluster模式和-client模式有什么区别"><span class="nav-number">12.</span> <span class="nav-text">spark on yarn 模式下的 cluster模式和 client模式有什么区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark运行原理-从提交一个jar到最后返回结果-整个过程"><span class="nav-number">13.</span> <span class="nav-text">spark运行原理,从提交一个jar到最后返回结果,整个过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark的stage是如何划分的"><span class="nav-number">14.</span> <span class="nav-text">spark的stage是如何划分的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark2-0为什么放弃了akka-而用netty"><span class="nav-number">15.</span> <span class="nav-text">spark2.0为什么放弃了akka 而用netty</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark的各种HA-master-worker-executor的ha"><span class="nav-number">16.</span> <span class="nav-text">spark的各种HA,  master/worker/executor的ha</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Master异常"><span class="nav-number">16.0.1.</span> <span class="nav-text">Master异常</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Worker异常"><span class="nav-number">16.0.2.</span> <span class="nav-text">Worker异常</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Executor异常"><span class="nav-number">16.0.3.</span> <span class="nav-text">Executor异常</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark的内存管理机制"><span class="nav-number">17.</span> <span class="nav-text">spark的内存管理机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-6版本以前的问题"><span class="nav-number">17.0.1.</span> <span class="nav-text">1.6版本以前的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#新方案的改进"><span class="nav-number">17.0.2.</span> <span class="nav-text">新方案的改进</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark中的广播变量"><span class="nav-number">18.</span> <span class="nav-text">spark中的广播变量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#问题：为什么只能-broadcast-只读的变量？"><span class="nav-number">18.1.</span> <span class="nav-text">问题：为什么只能 broadcast 只读的变量？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题：broadcast-到节点而不是-broadcast-到每个-task？"><span class="nav-number">18.2.</span> <span class="nav-text">问题：broadcast 到节点而不是 broadcast 到每个 task？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题：-具体怎么用-broadcast？"><span class="nav-number">18.3.</span> <span class="nav-text">问题： 具体怎么用 broadcast？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题：怎么实现-broadcast？"><span class="nav-number">18.4.</span> <span class="nav-text">问题：怎么实现 broadcast？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-分发-task-的时候先分发-bdata-的元信息"><span class="nav-number">18.4.1.</span> <span class="nav-text">1. 分发 task 的时候先分发 bdata 的元信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-HttpBroadcast"><span class="nav-number">18.4.2.</span> <span class="nav-text">2. HttpBroadcast</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-TorrentBroadcast"><span class="nav-number">18.4.3.</span> <span class="nav-text">3. TorrentBroadcast</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#driver-端："><span class="nav-number">18.4.4.</span> <span class="nav-text">driver 端：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Executor-端："><span class="nav-number">18.4.5.</span> <span class="nav-text">Executor 端：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题：broadcast-RDD-会怎样"><span class="nav-number">18.5.</span> <span class="nav-text">问题：broadcast RDD 会怎样?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Discussion"><span class="nav-number">19.</span> <span class="nav-text">Discussion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是数据倾斜-怎样去处理数据倾斜"><span class="nav-number">20.</span> <span class="nav-text">什么是数据倾斜,怎样去处理数据倾斜</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数据倾斜主要分为两类-聚合倾斜-和-join倾斜"><span class="nav-number">20.0.1.</span> <span class="nav-text">数据倾斜主要分为两类: 聚合倾斜 和 join倾斜</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分析一下一段spark代码中哪些部分在Driver端执行-哪些部分在Worker端执行"><span class="nav-number">21.</span> <span class="nav-text">分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 – <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">曹理鹏@iCocos</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">511k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">7:45</span>
  
</div>











        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  













  



  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/reading_progress/reading_progress.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  




  
    <script type="text/javascript">
    (function(){
      var appid = 'cytKHBEtW';
      var conf = '43989b8e63b25c4e9f1fde821c996a39';
      var width = window.innerWidth || document.documentElement.clientWidth;
      if (width < 960) {
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){
        window.changyan.api.config({appid:appid,conf:conf})});
      }
    })();
    </script>
    <script type="text/javascript" src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script>
  







  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("Tc7k1mbaieCUSgmM8LPk1IBO-gzGzoHsz", "sAb7L2vwENJTteRrvFKQacUU");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.get('time'));
            
            counter.save(null, {
              success: function(counter) {
                
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text('Counter not initialized! See more at console err msg.');
              console.error('ATTENTION! LeanCloud counter has security bug, see here how to solve it: https://github.com/theme-next/hexo-leancloud-counter-security. \n But you also can use LeanCloud without security, by set \'security\' option to \'false\'.');
            
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  
  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('复制成功')
          else $(this).text('复制失败')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>


  
  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("Tc7k1mbaieCUSgmM8LPk1IBO-gzGzoHsz", "sAb7L2vwENJTteRrvFKQacUU");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>


  
</body>
</html>
