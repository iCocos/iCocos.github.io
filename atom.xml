<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>iCocos</title>
  
  <subtitle>www.icocos.cn</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://icocos.github.io/"/>
  <updated>2020-04-02T15:03:21.057Z</updated>
  <id>https://icocos.github.io/</id>
  
  <author>
    <name>曹理鹏@iCocos</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大数据面试之Zookeeper</title>
    <link href="https://icocos.github.io/2020/03/12/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8BZookeeper/"/>
    <id>https://icocos.github.io/2020/03/12/大数据面试之Zookeeper/</id>
    <published>2020-03-12T10:56:46.000Z</published>
    <updated>2020-04-02T15:03:21.057Z</updated>
    
    <content type="html"><![CDATA[<h2 id="zookeeper是什么-有什么功能"><a href="#zookeeper是什么-有什么功能" class="headerlink" title="zookeeper是什么,有什么功能"></a>zookeeper是什么,有什么功能</h2><p>Zookeeper 是 一个典型的分布式数据一致性的解决方案.</p><p><strong>Zookeeper的典型应用场景</strong>:</p><ul><li>数据发布/订阅</li><li>负载均衡</li><li>命名服务</li><li>分布式协调/通知</li><li>集群管理</li><li>Master</li><li>分布式锁</li><li>分布式队列</li></ul><a id="more"></a><h2 id="zk-有几种部署模式"><a href="#zk-有几种部署模式" class="headerlink" title="zk 有几种部署模式"></a>zk 有几种部署模式</h2><p>zookeeper有两种运行模式: 集群模式和单机模式,还有一种伪集群模式,在单机模式下模拟集群的zookeeper服务</p><h2 id="zk是怎样保证主从节点的状态同步"><a href="#zk是怎样保证主从节点的状态同步" class="headerlink" title="zk是怎样保证主从节点的状态同步"></a>zk是怎样保证主从节点的状态同步</h2><p>zookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 zab 协议。 zab 协议有两种模式，分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，zab 就进入了恢复模式，当领导者被选举出来，且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 server 具有相同的系统状态。</p><h2 id="说一下zk的通知机制"><a href="#说一下zk的通知机制" class="headerlink" title="说一下zk的通知机制"></a>说一下zk的通知机制</h2><p>客户端端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些客户端会收到 zookeeper 的通知，然后客户端可以根据 znode 变化来做出业务上的改变</p><h2 id="zk的分布式锁实现方式"><a href="#zk的分布式锁实现方式" class="headerlink" title="zk的分布式锁实现方式"></a>zk的分布式锁实现方式</h2><p>使用zookeeper实现分布式锁的算法流程，假设锁空间的根节点为/lock：</p><ol><li>客户端连接zookeeper，并在/lock下创建<strong>临时的</strong>且<strong>有序的</strong>子节点，第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。</li><li>客户端获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中<strong>序号最小</strong>的子节点，如果是则认为获得锁，否则<strong>监听刚好在自己之前一位的子节点删除消息</strong>，获得子节点变更通知后重复此步骤直至获得锁；</li><li>执行业务代码；</li><li>完成业务流程后，删除对应的子节点释放锁。</li></ol><p><a href="http://www.dengshenyu.com/java/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/10/23/zookeeper-distributed-lock.html" target="_blank" rel="noopener">参考文章</a></p><h2 id="zk-采用的哪种分布式一致性协议-还有哪些分布式一致性协议"><a href="#zk-采用的哪种分布式一致性协议-还有哪些分布式一致性协议" class="headerlink" title="zk 采用的哪种分布式一致性协议? 还有哪些分布式一致性协议"></a>zk 采用的哪种分布式一致性协议? 还有哪些分布式一致性协议</h2><p>常见的分布式一致性协议有: 两阶段提交协议，三阶段提交协议，向量时钟，RWN协议，paxos协议，Raft协议. zk采用的是paxos协议.</p><ul><li><h4 id="两阶段提交协议-2PC"><a href="#两阶段提交协议-2PC" class="headerlink" title="两阶段提交协议(2PC)"></a>两阶段提交协议(2PC)</h4><p>两阶段提交协议，简称2PC，是比较常用的解决分布式事务问题的方式，要么所有参与进程都提交事务，要么都取消事务，即实现ACID中的原子性(A)的常用手段。</p></li><li><h4 id="三阶段提交协议-3PC"><a href="#三阶段提交协议-3PC" class="headerlink" title="三阶段提交协议(3PC)"></a>三阶段提交协议(3PC)</h4><p>3PC就是在2PC基础上将2PC的提交阶段细分位两个阶段：预提交阶段和提交阶段</p></li><li><h4 id="向量时钟"><a href="#向量时钟" class="headerlink" title="向量时钟"></a>向量时钟</h4><p>通过向量空间祖先继承的关系比较, 使数据保持最终一致性,这就是向量时钟的基本定义。</p></li><li><h4 id="NWR协议"><a href="#NWR协议" class="headerlink" title="NWR协议"></a>NWR协议</h4><p>NWR是一种在分布式存储系统中用于控制一致性级别的一种策略。在Amazon的Dynamo云存储系统中，就应用NWR来控制一致性。<br>让我们先来看看这三个字母的含义：<br>N：在分布式存储系统中，有多少份备份数据<br>W：代表一次成功的更新操作要求至少有w份数据写入成功<br>R： 代表一次成功的读数据操作要求至少有R份数据成功读取<br>NWR值的不同组合会产生不同的一致性效果，当W+R&gt;N的时候，整个系统对于客户端来讲能保证强一致性。当W+R 以常见的N=3、W=2、R=2为例：<br>N=3，表示，任何一个对象都必须有三个副本（Replica），W=2表示，对数据的修改操作（Write）只需要在3个Replica中的2个上面完成就返回，R=2表示，从三个对象中要读取到2个数据对象，才能返回。<br>在分布式系统中，数据的单点是不允许存在的。即线上正常存在的Replica数量是1的情况是非常危险的，因为一旦这个Replica再次错误，就 可能发生数据的永久性错误。假如我们把N设置成为2，那么，只要有一个存储节点发生损坏，就会有单点的存在。所以N必须大于2。N约高，系统的维护和整体 成本就越高。工业界通常把N设置为3。<br>当W是2、R是2的时候，W+R&gt;N，这种情况对于客户端就是强一致性的。</p></li><li><h4 id="paxos协议"><a href="#paxos协议" class="headerlink" title="paxos协议"></a>paxos协议</h4><p><a href="http://chuansong.me/n/2189245" target="_blank" rel="noopener">架构师需要了解的Paxos原理，历程及实践</a></p></li><li><h4 id="Raft协议"><a href="#Raft协议" class="headerlink" title="Raft协议"></a>Raft协议</h4><p><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">Raft协议的动画</a></p></li></ul><p><a href="https://blog.csdn.net/chdhust/article/details/52651741" target="_blank" rel="noopener">参考文章</a></p><h2 id="讲一下leader-选举过程"><a href="#讲一下leader-选举过程" class="headerlink" title="讲一下leader 选举过程"></a>讲一下leader 选举过程</h2><p>　　这里选取3台机器组成的服务器集群为例。在集群初始化阶段，当有一台服务器Server1启动时，其单独无法进行和完成Leader选举，当第二台服务器Server2启动时，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。选举过程如下</p><p>　　<strong>(1) 每个Server发出一个投票</strong>。由于是初始情况，Server1和Server2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时Server1的投票为(1, 0)，Server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。</p><p>　　<strong>(2) 接受来自各个服务器的投票</strong>。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。</p><p>　　<strong>(3) 处理投票</strong>。针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下</p><p>　　　　<strong>· 优先检查ZXID</strong>。ZXID比较大的服务器优先作为Leader。</p><p>　　　　<strong>· 如果ZXID相同，那么就比较myid</strong>。myid较大的服务器作为Leader服务器。</p><p>　　对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时Server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，对于Server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。</p><p>　　<strong>(4) 统计投票</strong>。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。</p><p>　　<strong>(5) 改变服务器状态</strong>。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。</p><h3 id="Leader选举算法分析"><a href="#Leader选举算法分析" class="headerlink" title="Leader选举算法分析"></a>Leader选举算法分析</h3><p>在3.4.0后的Zookeeper的版本只保留了TCP版本的FastLeaderElection选举算法。当一台机器进入Leader选举时，当前集群可能会处于以下两种状态</p><p>　　　　· 集群中已经存在Leader。</p><p>　　　　· 集群中不存在Leader。</p><p>　　对于集群中已经存在Leader而言，此种情况一般都是某台机器启动得较晚，在其启动之前，集群已经在正常工作，对这种情况，该机器试图去选举Leader时，会被告知当前服务器的Leader信息，对于该机器而言，仅仅需要和Leader机器建立起连接，并进行状态同步即可。而在集群中不存在Leader情况下则会相对复杂，其步骤如下</p><p>　　(1) <strong>第一次投票</strong>。无论哪种导致进行Leader选举，集群的所有机器都处于试图选举出一个Leader的状态，即LOOKING状态，LOOKING机器会向所有其他机器发送消息，该消息称为投票。投票中包含了SID（服务器的唯一标识）和ZXID（事务ID），(SID, ZXID)形式来标识一次投票信息。假定Zookeeper由5台机器组成，SID分别为1、2、3、4、5，ZXID分别为9、9、9、8、8，并且此时SID为2的机器是Leader机器，某一时刻，1、2所在机器出现故障，因此集群开始进行Leader选举。在第一次投票时，每台机器都会将自己作为投票对象，于是SID为3、4、5的机器投票情况分别为(3, 9)，(4, 8)， (5, 8)。</p><p>　　(2) <strong>变更投票</strong>。每台机器发出投票后，也会收到其他机器的投票，每台机器会根据一定规则来处理收到的其他机器的投票，并以此来决定是否需要变更自己的投票，这个规则也是整个Leader选举算法的核心所在，其中术语描述如下</p><p>　　　　<strong>· vote_sid</strong>：接收到的投票中所推举Leader服务器的SID。</p><p>　　　　<strong>· vote_zxid</strong>：接收到的投票中所推举Leader服务器的ZXID。</p><p>　　　　<strong>· self_sid</strong>：当前服务器自己的SID。</p><p>　　　　<strong>· self_zxid</strong>：当前服务器自己的ZXID。</p><p>　　每次对收到的投票的处理，都是对(vote_sid, vote_zxid)和(self_sid, self_zxid)对比的过程。</p><p>　　　　规则一：如果vote_zxid大于self_zxid，就认可当前收到的投票，并再次将该投票发送出去。</p><p>　　　　规则二：如果vote_zxid小于self_zxid，那么坚持自己的投票，不做任何变更。</p><p>　　　　规则三：如果vote_zxid等于self_zxid，那么就对比两者的SID，如果vote_sid大于self_sid，那么就认可当前收到的投票，并再次将该投票发送出去。</p><p>　　　　规则四：如果vote_zxid等于self_zxid，并且vote_sid小于self_sid，那么坚持自己的投票，不做任何变更。</p><p>　　结合上面规则，给出下面的集群变更过程。</p><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/leader选举算法.png" alt=""></p><p>​    (3) <strong>确定Leader</strong>。经过第二轮投票后，集群中的每台机器都会再次接收到其他机器的投票，然后开始统计投票，如果一台机器收到了超过半数的相同投票，那么这个投票对应的SID机器即为Leader。此时Server3将成为Leader。</p><p>　　由上面规则可知，通常那台服务器上的数据越新（ZXID会越大），其成为Leader的可能性越大，也就越能够保证数据的恢复。如果ZXID相同，则SID越大机会越大。</p><p><a href="https://www.cnblogs.com/leesf456/p/6107600.html" target="_blank" rel="noopener">参考文章</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;zookeeper是什么-有什么功能&quot;&gt;&lt;a href=&quot;#zookeeper是什么-有什么功能&quot; class=&quot;headerlink&quot; title=&quot;zookeeper是什么,有什么功能&quot;&gt;&lt;/a&gt;zookeeper是什么,有什么功能&lt;/h2&gt;&lt;p&gt;Zookeeper 是 一个典型的分布式数据一致性的解决方案.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zookeeper的典型应用场景&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据发布/订阅&lt;/li&gt;
&lt;li&gt;负载均衡&lt;/li&gt;
&lt;li&gt;命名服务&lt;/li&gt;
&lt;li&gt;分布式协调/通知&lt;/li&gt;
&lt;li&gt;集群管理&lt;/li&gt;
&lt;li&gt;Master&lt;/li&gt;
&lt;li&gt;分布式锁&lt;/li&gt;
&lt;li&gt;分布式队列&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Zookeeper" scheme="https://icocos.github.io/categories/Zookeeper/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Zookeeper" scheme="https://icocos.github.io/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试之Kafka</title>
    <link href="https://icocos.github.io/2020/03/10/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8Bkafka/"/>
    <id>https://icocos.github.io/2020/03/10/大数据面试之kafka/</id>
    <published>2020-03-10T10:56:46.000Z</published>
    <updated>2020-04-02T15:03:49.645Z</updated>
    
    <content type="html"><![CDATA[<h2 id="讲一下kafka-的架构"><a href="#讲一下kafka-的架构" class="headerlink" title="讲一下kafka 的架构"></a>讲一下kafka 的架构</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/kafka架构图.png" alt=""></p><ul><li><p><strong>Producer</strong>：消息生产者</p><ul><li><p>Producer可以发送消息到Topic</p></li><li><ul><li>Topic的消息存放在不同Partition中，不同Partition存放在不同Broker中</li><li>Producer只需要指定Topic的名字、要连接到的Broker，这样Kafka就可以自动地把消息数据路由到合适的Broker（不一定是指定连接的Broker）</li></ul></li></ul></li></ul><a id="more"></a><ul><li><p>Producer发送消息后，可以选择是否要确认消息写入成功（ACK，Acknowledgment）</p></li><li><ul><li>ACK=0：Producer不会等待ACK（消息可能丢失）</li><li>ACK=1：Producer会等待Leader Partition的ACK（Follower Partition消息可能丢失）</li><li>ACK=all：Producer会等待Leader Partition和Follower Partition的ACK（消息不会丢失）</li></ul></li><li><p>消息key：Producer可以给消息加上key，带相同key的消息会被分发到同一个Partition，这样就可以保证带相同key的消息的消费是有序的</p></li></ul><ul><li><p><strong>Broker</strong>：每个Broker里包含了不同Topic的不同Partition，Partition中包含了有序的消息</p><ul><li>一个Kafka集群由多个Broker（server）组成</li><li>每个Broker都有ID标识</li><li>每个Broker里保存一定数量的Partition</li><li>客户端只要连接上任意一个Broker，就可以连接上整个Kafka集群</li><li>大多数Kafka集群刚开始的时候建议使用至少3个Broker，集群大了可以有上百个Broker</li></ul></li><li><p><strong>Consumer</strong>：消息消费者</p><ul><li><p>Consumer可以从Topic读取消息进行消费</p></li><li><ul><li>Topic的消息存放在不同Partition中，不同Partition存放在不同Broker中</li><li>Consumer只需要指定Topic的名字、要连接到的Broker，这样Kafka就可以自动地把Consumer路由到合适的Broker拉取消息进行消费（不一定是指定连接的Broker）</li><li>每一个Partition中的消息都会被有序消费</li></ul></li><li><p>Consumer Group：</p></li><li><ul><li>Consumer Group由多个Consumer组成</li><li>Consumer Group里的每个Consumer都会从不同的Partition中读取消息</li><li>如果Consumer的数量大于Partition的数量，那么多出来的Consumer就会空闲下来（浪费资源）</li></ul></li><li><p>Consumer offset：</p></li><li><ul><li>Kafka会为Consumer Group要消费的每个Partion保存一个offset，这个offset标记了该Consumer Group最后消费消息的位置</li><li>这个offset保存在Kafka里一个名为“__consumer_offsets”的Topic中；当Consumer从Kafka拉取消息消费时，同时也要对这个offset提交修改更新操作。这样若一个Consumer消费消息时挂了，其他Consumer可以通过这个offset值重新找到上一个消息再进行处理</li></ul></li></ul></li></ul><p><a href="https://zhuanlan.zhihu.com/p/48896367" target="_blank" rel="noopener">参考文章</a></p><h2 id="kafka-与其他消息组件对比"><a href="#kafka-与其他消息组件对比" class="headerlink" title="kafka 与其他消息组件对比"></a>kafka 与其他消息组件对比</h2><p><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/why-mq.md" target="_blank" rel="noopener">推荐阅读文章</a></p><table><thead><tr><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>同 ActiveMQ</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr><tr><td>topic 数量对吞吐量的影响</td><td></td><td></td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td>基本不丢</td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr><tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr></tbody></table><h2 id="kafka-实现高吞吐的原理"><a href="#kafka-实现高吞吐的原理" class="headerlink" title="kafka 实现高吞吐的原理"></a>kafka 实现高吞吐的原理</h2><ul><li>读写文件依赖OS文件系统的页缓存，而不是在JVM内部缓存数据，利用OS来缓存，内存利用率高</li><li>sendfile技术（零拷贝），避免了传统网络IO四步流程</li><li>支持End-to-End的压缩</li><li>顺序IO以及常量时间get、put消息</li><li>Partition 可以很好的横向扩展和提供高并发处理</li></ul><p><a href="https://www.jianshu.com/p/d6a73be9d803" target="_blank" rel="noopener">参考文章1</a></p><p><a href="https://blog.csdn.net/stark_summer/article/details/50144591" target="_blank" rel="noopener">参考文章2</a></p><h2 id="kafka怎样保证不重复消费"><a href="#kafka怎样保证不重复消费" class="headerlink" title="kafka怎样保证不重复消费"></a>kafka怎样保证不重复消费</h2><p>此问题其实等价于保证消息队列消费的幂等性</p><p>主要需要结合实际业务来操作:</p><ul><li>比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。</li><li>比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。</li><li>比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</li><li>比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。</li></ul><p><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md" target="_blank" rel="noopener">参考文章</a></p><h2 id="kafka怎样保证不丢失消息"><a href="#kafka怎样保证不丢失消息" class="headerlink" title="kafka怎样保证不丢失消息"></a>kafka怎样保证不丢失消息</h2><h4 id="消费端弄丢了数据"><a href="#消费端弄丢了数据" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><p>唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边<strong>自动提交了 offset</strong>，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p><p>这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要<strong>关闭自动提交</strong> offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是<strong>可能会有重复消费</strong>，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p><p>生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。</p><h4 id="Kafka-弄丢了数据"><a href="#Kafka-弄丢了数据" class="headerlink" title="Kafka 弄丢了数据"></a>Kafka 弄丢了数据</h4><p>这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。</p><p>生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。</p><p>所以此时一般是要求起码设置如下 4 个参数：</p><ul><li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</li><li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</li><li>在 producer 端设置 <code>acks=all</code>：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</li><li>在 producer 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li></ul><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p><h4 id="生产者会不会弄丢数据？"><a href="#生产者会不会弄丢数据？" class="headerlink" title="生产者会不会弄丢数据？"></a>生产者会不会弄丢数据？</h4><p>如果按照上述的思路设置了 <code>acks=all</code>，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><p><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md" target="_blank" rel="noopener">参考文章</a></p><h2 id="kafka-与-spark-streaming-集成-如何保证-exactly-once-语义"><a href="#kafka-与-spark-streaming-集成-如何保证-exactly-once-语义" class="headerlink" title="kafka 与 spark streaming 集成,如何保证 exactly once 语义"></a>kafka 与 spark streaming 集成,如何保证 exactly once 语义</h2><ul><li><h3 id="Spark-Streaming上游对接kafka时保证Exactly-Once"><a href="#Spark-Streaming上游对接kafka时保证Exactly-Once" class="headerlink" title="Spark Streaming上游对接kafka时保证Exactly Once"></a>Spark Streaming上游对接kafka时保证Exactly Once</h3><p>Spark Streaming使用Direct模式对接上游kafka。无论kafka有多少个partition， 使用Direct模式总能保证SS中有相同数量的partition与之相对， 也就是说SS中的KafkaRDD的并发数量在Direct模式下是由上游kafka决定的。 在这个模式下，kafka的offset是作为KafkaRDD的一部分存在，会存储在checkpoints中， 由于checkpoints只存储offset内容，而不存储数据，这就使得checkpoints是相对轻的操作。 这就使得SS在遇到故障时，可以从checkpoint中恢复上游kafka的offset，从而保证exactly once</p></li><li><h3 id="Spark-Streaming输出下游保证Exactly-once"><a href="#Spark-Streaming输出下游保证Exactly-once" class="headerlink" title="Spark Streaming输出下游保证Exactly once"></a>Spark Streaming输出下游保证Exactly once</h3><ul><li><p>第一种“鸵鸟做法”，就是期望下游（数据）具有幂等特性。</p><p>多次尝试总是写入相同的数据，例如，saveAs***Files 总是将相同的数据写入生成的文件</p></li></ul></li><li><ul><li><p>使用事务更新</p><p>所有更新都是事务性的，以便更新完全按原子进行。这样做的一个方法如下： 使用批处理时间(在foreachRDD中可用)和RDD的partitionIndex（分区索引）来创建identifier（标识符)。 该标识符唯一地标识streaming application 中的blob数据。 使用该identifier，blob 事务地更新到外部系统中。也就是说，如果identifier尚未提交，则以 (atomicall)原子方式提交分区数据和identifier。否则，如果已经提交，请跳过更新。</p></li></ul></li></ul><p><a href="http://www.aihacks.life/post/spark-streaming%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81exactly-once%E8%AF%AD%E4%B9%89/" target="_blank" rel="noopener">参考文章1</a></p><p><a href="https://www.jianshu.com/p/10de8f3b1be8" target="_blank" rel="noopener">参考文章2</a></p><p><a href="https://blog.csdn.net/cymvp/article/details/52605987" target="_blank" rel="noopener">参考文章3</a></p><h2 id="Ack-有哪几种-生产中怎样选择"><a href="#Ack-有哪几种-生产中怎样选择" class="headerlink" title="Ack 有哪几种, 生产中怎样选择?"></a>Ack 有哪几种, 生产中怎样选择?</h2><p>ack=0/1/-1的不同情况：</p><ul><li><p>Ack = 0</p><p>producer不等待broker的ack，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</p></li><li><p>Ack = 1</p><p>producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据；</p></li><li><p>Ack = -1</p><p>producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack，数据一般不会丢失，延迟时间长但是可靠性高。</p></li></ul><p><strong>生产中主要以 Ack=-1为主,如果压力过大,可切换为Ack=1. Ack=0的情况只能在测试中使用.</strong></p><h2 id="如何通过offset寻找数据"><a href="#如何通过offset寻找数据" class="headerlink" title="如何通过offset寻找数据"></a>如何通过offset寻找数据</h2><p>如果consumer要找offset是1008的消息，那么，</p><p>1，按照二分法找到小于1008的segment，也就是00000000000000001000.log和00000000000000001000.index</p><p>2，用目标offset减去文件名中的offset得到消息在这个segment中的偏移量。也就是1008-1000=8，偏移量是8。</p><p>3，再次用二分法在index文件中找到对应的索引，也就是第三行6,45。</p><p>4，到log文件中，从偏移量45的位置开始（实际上这里的消息offset是1006），顺序查找，直到找到offset为1008的消息。查找期间kafka是按照log的存储格式来判断一条消息是否结束的。</p><p><a href="https://blog.csdn.net/lkforce/article/details/77854813" target="_blank" rel="noopener">参考文章</a></p><h2 id="如何清理过期数据"><a href="#如何清理过期数据" class="headerlink" title="如何清理过期数据"></a>如何清理过期数据</h2><ul><li><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>log.cleanup.policy=delete启用删除策略</p><ul><li>直接删除，删除后的消息不可恢复。可配置以下两个策略：<br>清理超过指定时间清理：<br>log.retention.hours=16</li><li>超过指定大小后，删除旧的消息：<br>log.retention.bytes=1073741824<br>为了避免在删除时阻塞读操作，采用了copy-on-write形式的实现，删除操作进行时，读取操作的二分查找功能实际是在一个静态的快照副本上进行的，这类似于Java的CopyOnWriteArrayList。</li></ul></li><li><h4 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h4><p>将数据压缩，只保留每个key最后一个版本的数据。<br>首先在broker的配置中设置log.cleaner.enable=true启用cleaner，这个默认是关闭的。<br>在topic的配置中设置log.cleanup.policy=compact启用压缩策略。</p><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/kafka压缩.png" alt=""></p><p>如上图，在整个数据流中，每个Key都有可能出现多次，压缩时将根据Key将消息聚合，只保留最后一次出现时的数据。这样，无论什么时候消费消息，都能拿到每个Key的最新版本的数据。<br>压缩后的offset可能是不连续的，比如上图中没有5和7，因为这些offset的消息被merge了，当从这些offset消费消息时，将会拿到比这个offset大的offset对应的消息，比如，当试图获取offset为5的消息时，实际上会拿到offset为6的消息，并从这个位置开始消费。<br>这种策略只适合特俗场景，比如消息的key是用户ID，消息体是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。<br>压缩策略支持删除，当某个Key的最新版本的消息没有内容时，这个Key将被删除，这也符合以上逻辑。</p></li></ul><p><a href="https://blog.csdn.net/honglei915/article/details/49683065" target="_blank" rel="noopener">参考文章</a></p><h2 id="1条message中包含哪些信息"><a href="#1条message中包含哪些信息" class="headerlink" title="1条message中包含哪些信息"></a>1条message中包含哪些信息</h2><table><thead><tr><th><strong>Field</strong></th><th>Description</th></tr></thead><tbody><tr><td>Attributes</td><td>该字节包含有关消息的元数据属性。 最低的2位包含用于消息的压缩编解码器。 其他位应设置为0。</td></tr><tr><td>Crc</td><td>CRC是消息字节的其余部分的CRC32。 这用于检查代理和使用者上的消息的完整性。</td></tr><tr><td></td><td>key是用于分区分配的可选参数。 key可以为null。</td></tr><tr><td>MagicByte</td><td>这是用于允许向后兼容的消息二进制格式演变的版本ID。 当前值为0。</td></tr><tr><td>Offset</td><td>这是kafka中用作日志序列号的偏移量。 当producer发送消息时，它实际上并不知道偏移量，并且可以填写它喜欢的任何值。</td></tr><tr><td>Value</td><td>该值是实际的消息内容，作为不透明的字节数组。 Kafka支持递归消息，在这种情况下，它本身可能包含消息集。 消息可以为null。</td></tr></tbody></table><h2 id="讲一下zookeeper在kafka中的作用"><a href="#讲一下zookeeper在kafka中的作用" class="headerlink" title="讲一下zookeeper在kafka中的作用"></a>讲一下zookeeper在kafka中的作用</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/kafka在zk中的存储结构.png" alt=""></p><h4 id="zk的作用主要有如下几点"><a href="#zk的作用主要有如下几点" class="headerlink" title="zk的作用主要有如下几点:"></a>zk的作用主要有如下几点:</h4><ol><li>kafka的元数据都存放在zk上面,由zk来管理</li><li>0.8之前版本的kafka, consumer的消费状态，group的管理以及 offset的值都是由zk管理的,现在offset会保存在本地topic文件里</li><li>负责borker的lead选举和管理</li></ol><h2 id="kafka-可以脱离-zookeeper-单独使用吗"><a href="#kafka-可以脱离-zookeeper-单独使用吗" class="headerlink" title="kafka 可以脱离 zookeeper 单独使用吗"></a>kafka 可以脱离 zookeeper 单独使用吗</h2><p>kafka 不能脱离 zookeeper 单独使用，因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。</p><h2 id="kafka-有几种数据保留策略"><a href="#kafka-有几种数据保留策略" class="headerlink" title="kafka 有几种数据保留策略"></a>kafka 有几种数据保留策略</h2><p>kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。</p><h2 id="kafka同时设置了7天和10G清除数据-到第5天的时候消息到达了10G-这个时候kafka如何处理"><a href="#kafka同时设置了7天和10G清除数据-到第5天的时候消息到达了10G-这个时候kafka如何处理" class="headerlink" title="kafka同时设置了7天和10G清除数据,到第5天的时候消息到达了10G,这个时候kafka如何处理?"></a>kafka同时设置了7天和10G清除数据,到第5天的时候消息到达了10G,这个时候kafka如何处理?</h2><p>这个时候 kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;讲一下kafka-的架构&quot;&gt;&lt;a href=&quot;#讲一下kafka-的架构&quot; class=&quot;headerlink&quot; title=&quot;讲一下kafka 的架构&quot;&gt;&lt;/a&gt;讲一下kafka 的架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/kafka架构图.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Producer&lt;/strong&gt;：消息生产者&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Producer可以发送消息到Topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Topic的消息存放在不同Partition中，不同Partition存放在不同Broker中&lt;/li&gt;
&lt;li&gt;Producer只需要指定Topic的名字、要连接到的Broker，这样Kafka就可以自动地把消息数据路由到合适的Broker（不一定是指定连接的Broker）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Kafka" scheme="https://icocos.github.io/categories/Kafka/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Kafka" scheme="https://icocos.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试之HBase</title>
    <link href="https://icocos.github.io/2020/03/08/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8BHBase/"/>
    <id>https://icocos.github.io/2020/03/08/大数据面试之HBase/</id>
    <published>2020-03-08T10:56:46.000Z</published>
    <updated>2020-04-02T15:04:01.940Z</updated>
    
    <content type="html"><![CDATA[<h2 id="讲一下-Hbase-架构"><a href="#讲一下-Hbase-架构" class="headerlink" title="讲一下 Hbase 架构"></a>讲一下 Hbase 架构</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hbase架构图.png" alt=""></p><p><strong>Hbase主要包含HMaster/HRegionServer/Zookeeper</strong></p><a id="more"></a><ul><li><p><strong>HRegionServer 负责实际数据的读写. 当访问数据时, 客户端直接与RegionServer通信.</strong></p><p>HBase的表根据Row Key的区域分成多个Region, 一个Region包含这这个区域内所有数据. 而Region server负责管理多个Region, 负责在这个Region server上的所有region的读写操作. </p></li><li><p><strong>HMaster 负责管理Region的位置, DDL(新增和删除表结构)</strong></p><ul><li>协调RegionServer</li><li>在集群处于数据恢复或者动态调整负载时,分配Region到某一个RegionServer中</li><li>管控集群,监控所有Region Server的状态</li><li>提供DDL相关的API, 新建(create),删除(delete)和更新(update)表结构.</li></ul></li><li><p><strong>Zookeeper 负责维护和记录整个Hbase集群的状态</strong></p><p>zookeeper探测和记录Hbase集群中服务器的状态信息.如果zookeeper发现服务器宕机,它会通知Hbase的master节点.</p></li></ul><h2 id="hbase-如何设计rowkey"><a href="#hbase-如何设计rowkey" class="headerlink" title="hbase 如何设计rowkey"></a>hbase 如何设计rowkey</h2><ul><li><p><strong>RowKey长度原则</strong></p><p>Rowkey是一个二进制码流，Rowkey的长度被很多开发者建议说设计在10~100个字节，不过建议是越短越好，不要超过16个字节。</p><p>原因如下：</p><ul><li><p>数据的持久化文件HFile中是按照KeyValue存储的，如果Rowkey过长比如100个字节，1000万列数据光Rowkey就要占用100*1000万=10亿个字节，将近1G数据，这会极大影响HFile的存储效率；</p></li><li><p>MemStore将缓存部分数据到内存，如果Rowkey字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。因此Rowkey的字节长度越短越好。</p></li><li><p>目前操作系统是都是64位系统，内存8字节对齐。控制在16个字节，8字节的整数倍利用操作系统的最佳特性。</p></li></ul></li><li><p><strong>RowKey散列原则</strong></p><p>如果Rowkey是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将Rowkey的高位作为散列字段，由程序循环生成，低位放时间字段，这样将提高数据均衡分布在每个Regionserver实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有新数据都在一个RegionServer上堆积的热点现象，这样在做数据检索的时候负载将会集中在个别RegionServer，降低查询效率。</p></li><li><p><strong>RowKey唯一原则</strong></p><p>必须在设计上保证其唯一性。</p></li></ul><p><a href="https://zhuanlan.zhihu.com/p/30074408" target="_blank" rel="noopener">参考文章1</a></p><p><a href="http://www.nosqlnotes.com/technotes/hbase/hbase-rowkey-design/" target="_blank" rel="noopener">参考文章2</a></p><h2 id="讲一下hbase的存储结构-这样的存储结构有什么优缺点"><a href="#讲一下hbase的存储结构-这样的存储结构有什么优缺点" class="headerlink" title="讲一下hbase的存储结构,这样的存储结构有什么优缺点"></a>讲一下hbase的存储结构,这样的存储结构有什么优缺点</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures\hbase逻辑结构.png" alt=""></p><p><strong>Hbase的优点及应用场景</strong>:</p><ol><li>半结构化或非结构化数据:<br>对于数据结构字段不够确定或杂乱无章非常难按一个概念去进行抽取的数据适合用HBase，因为HBase支持动态添加列。</li><li>记录很稀疏：<br>RDBMS的行有多少列是固定的。为null的列浪费了存储空间。HBase为null的Column不会被存储，这样既节省了空间又提高了读性能。</li><li>多版本号数据：<br>依据Row key和Column key定位到的Value能够有随意数量的版本号值，因此对于须要存储变动历史记录的数据，用HBase是很方便的。比方某个用户的Address变更，用户的Address变更记录也许也是具有研究意义的。</li><li>仅要求最终一致性：<br>对于数据存储事务的要求不像金融行业和财务系统这么高，只要保证最终一致性就行。（比如HBase+elasticsearch时，可能出现数据不一致）</li><li>高可用和海量数据以及很大的瞬间写入量：<br>WAL解决高可用，支持PB级数据，put性能高<br>适用于插入比查询操作更频繁的情况。比如，对于历史记录表和日志文件。（HBase的写操作更加高效）</li><li>业务场景简单：<br>不需要太多的关系型数据库特性，列入交叉列，交叉表，事务，连接等。</li></ol><p><strong>Hbase的缺点：</strong></p><ol><li>单一RowKey固有的局限性决定了它不可能有效地支持多条件查询</li><li>不适合于大范围扫描查询</li><li>不直接支持 SQL 的语句查询</li></ol><p><a href="https://www.iteye.com/blog/forlan-2364661" target="_blank" rel="noopener">参考文章1</a></p><p><a href="https://blog.csdn.net/liaynling/article/details/81199238" target="_blank" rel="noopener">参考文章2</a></p><p><a href="https://juejin.im/post/5c31cf486fb9a04a102f6f89#heading-2" target="_blank" rel="noopener">参考文章3</a></p><h2 id="hbase的HA实现-zookeeper在其中的作用"><a href="#hbase的HA实现-zookeeper在其中的作用" class="headerlink" title="hbase的HA实现,zookeeper在其中的作用"></a>hbase的HA实现,zookeeper在其中的作用</h2><p> HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。<br>配置HBase高可用，只需要启动两个HMaster，让Zookeeper自己去选择一个Master Acitve即可</p><p>zk的在这里起到的作用就是用来管理master节点,以及帮助hbase做master选举</p><h2 id="HMaster宕机的时候-哪些操作还能正常工作"><a href="#HMaster宕机的时候-哪些操作还能正常工作" class="headerlink" title="HMaster宕机的时候,哪些操作还能正常工作"></a>HMaster宕机的时候,哪些操作还能正常工作</h2><p>对表内数据的增删查改是可以正常进行的,因为hbase client 访问数据只需要通过 zookeeper 来找到 rowkey 的具体 region 位置即可. 但是对于创建表/删除表等的操作就无法进行了,因为这时候是需要HMaster介入, 并且region的拆分,合并,迁移等操作也都无法进行了</p><h2 id="讲一下hbase的写数据的流程"><a href="#讲一下hbase的写数据的流程" class="headerlink" title="讲一下hbase的写数据的流程"></a>讲一下hbase的写数据的流程</h2><ol><li>Client先访问zookeeper，从.META.表获取相应region信息，然后从meta表获取相应region信息 </li><li>根据namespace、表名和rowkey根据meta表的数据找到写入数据对应的region信息 </li><li>找到对应的regionserver 把数据先写到WAL中，即HLog，然后写到MemStore上 </li><li>MemStore达到设置的阈值后则把数据刷成一个磁盘上的StoreFile文件。 </li><li>当多个StoreFile文件达到一定的大小后(这个可以称之为小合并，合并数据可以进行设置，必须大于等于2，小于10——hbase.hstore.compaction.max和hbase.hstore.compactionThreshold，默认为10和3)，会触发Compact合并操作，合并为一个StoreFile，（这里同时进行版本的合并和数据删除。） </li><li>当Storefile大小超过一定阈值后，会把当前的Region分割为两个（Split）【可称之为大合并，该阈值通过hbase.hregion.max.filesize设置，默认为10G】，并由Hmaster分配到相应的HRegionServer，实现负载均衡</li></ol><h2 id="讲一下hbase读数据的流程"><a href="#讲一下hbase读数据的流程" class="headerlink" title="讲一下hbase读数据的流程"></a>讲一下hbase读数据的流程</h2><ol><li><p>首先，客户端需要获知其想要读取的信息的Region的位置，这个时候，Client访问hbase上数据时并不需要Hmaster参与（HMaster仅仅维护着table和Region的元数据信息，负载很低），只需要访问zookeeper，从meta表获取相应region信息(地址和端口等)。【Client请求ZK获取.META.所在的RegionServer的地址。】</p></li><li><p>客户端会将该保存着RegionServer的位置信息的元数据表.META.进行缓存。然后在表中确定待检索rowkey所在的RegionServer信息（得到持有对应行键的.META表的服务器名）。【获取访问数据所在的RegionServer地址】</p></li><li><p>根据数据所在RegionServer的访问信息，客户端会向该RegionServer发送真正的数据读取请求。服务器端接收到该请求之后需要进行复杂的处理。</p></li><li><p>先从MemStore找数据，如果没有，再到StoreFile上读(为了读取的效率)。</p></li></ol><p><a href="https://blog.csdn.net/HaixWang/article/details/79520141#%E8%AF%BB%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88" target="_blank" rel="noopener">参考文章1</a></p><p><a href="http://hbasefly.com/2016/12/21/hbase-getorscan/?rkfcfo=fy6gy1" target="_blank" rel="noopener">参考文章2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;讲一下-Hbase-架构&quot;&gt;&lt;a href=&quot;#讲一下-Hbase-架构&quot; class=&quot;headerlink&quot; title=&quot;讲一下 Hbase 架构&quot;&gt;&lt;/a&gt;讲一下 Hbase 架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hbase架构图.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hbase主要包含HMaster/HRegionServer/Zookeeper&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="https://icocos.github.io/categories/HBase/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="HBase" scheme="https://icocos.github.io/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试之Flink</title>
    <link href="https://icocos.github.io/2020/03/05/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8BFlink/"/>
    <id>https://icocos.github.io/2020/03/05/大数据面试之Flink/</id>
    <published>2020-03-05T10:56:46.000Z</published>
    <updated>2020-04-02T15:03:03.816Z</updated>
    
    <content type="html"><![CDATA[<h2 id="讲一下flink的运行架构"><a href="#讲一下flink的运行架构" class="headerlink" title="讲一下flink的运行架构"></a>讲一下flink的运行架构</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink架构图.png" alt=""></p><p>当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的 TaskManager。由 Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程。</p><a id="more"></a><ul><li><strong>Client</strong> 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager 环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming的任务），也可以不结束并等待结果返回。</li><li><strong>JobManager</strong> 主要负责调度 Job 并协调 Task 做 checkpoint，职责上很像 Storm 的 Nimbus。从 Client 处接收到 Job 和 JAR 包等资源后，会生成优化后的执行计划，并以 Task 的单元调度到各个 TaskManager 去执行。</li><li><strong>TaskManager</strong> 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动一个 Task，Task 为线程。从 JobManager 处接收需要部署的 Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理。</li></ul><p><a href="http://wuchong.me/blog/2016/05/03/flink-internals-overview/" target="_blank" rel="noopener">参考文章1</a></p><p><a href="http://shiyanjun.cn/archives/1508.html" target="_blank" rel="noopener">参考文章2</a></p><h2 id="讲一下flink的作业执行流程"><a href="#讲一下flink的作业执行流程" class="headerlink" title="讲一下flink的作业执行流程"></a>讲一下flink的作业执行流程</h2><p> <img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flinkRuntime.png" alt=""></p><p><strong>以yarn模式Per-job方式为例概述作业提交执行流程</strong></p><ol><li><p>当执行executor() 之后,会首先在本地client 中将代码转化为可以提交的 JobGraph</p><p>如果提交为Per-Job模式,则首先需要启动AM, client会首先向资源系统申请资源, 在yarn下即为申请container开启AM, 如果是Session模式的话则不需要这个步骤</p></li><li><p>Yarn分配资源, 开启AM</p></li><li>Client将Job提交给Dispatcher</li><li>Dispatcher 会开启一个新的 JobManager线程</li><li>JM 向Flink 自己的 Resourcemanager申请slot资源来执行任务</li><li>RM 向 Yarn申请资源来启动 TaskManger (Session模式跳过此步)</li><li>Yarn 分配 Container 来启动 taskManger (Session模式跳过此步)</li><li>Flink 的 RM 向 TM 申请 slot资源来启动 task</li><li>TM 将待分配的 slot 提供给 JM</li><li>JM 提交 task, TM 会启动新的线程来执行任务,开始启动后就可以通过 shuffle模块进行 task之间的数据交换</li></ol><p><a href="https://www.bilibili.com/video/av52394455?t=343" target="_blank" rel="noopener">参考视频</a></p><h2 id="flink具体是如何实现exactly-once-语义"><a href="#flink具体是如何实现exactly-once-语义" class="headerlink" title="flink具体是如何实现exactly once 语义"></a>flink具体是如何实现exactly once 语义</h2><p>在谈到 flink 所实现的 exactly-once语义时,主要是2个层面上的,首先 flink在0.9版本以后已经实现了基于state的内部一致性语义, 在1.4版本以后也可以实现端到端 Exactly-Once语义</p><ul><li><h4 id="状态-Exactly-Once"><a href="#状态-Exactly-Once" class="headerlink" title="状态 Exactly-Once"></a>状态 Exactly-Once</h4><p>Flink 提供 exactly-once 的状态（state）投递语义，这为有状态的（stateful）计算提供了准确性保证。也就是状态是不会重复使用的,有且仅有一次消费</p></li></ul><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink故障恢复.png" alt=""></p><p>​    这里需要注意的一点是如何理解state语义的exactly-once,并不是说在flink中的所有事件均只会处理一次,而是所有的事件所影响生成的state只有作用一次.</p><p>​    在上图中, 假设每两条消息后出发一次checkPoint操作,持久化一次state. TaskManager 在 处理完 event c 之后被shutdown, 这时候当 JobManager重启task之后, TaskManager  会从 checkpoint 1 处恢复状态,重新执行流处理,也就是说 此时 event c 事件 的的确确是会被再一次处理的. 那么 这里所说的一致性语义是何意思呢? 本身,flink每处理完一条数据都会记录当前进度到 state中, 也就是说在 故障前, 处理完 event c 这件事情已经记录到了state中,但是,由于在checkPoint 2 之前, 就已经发生了宕机,那么 event c 对于state的影响并没有被记录下来,对于整个flink内部系统来说就好像没有发生过一样, 在 故障恢复后, 当触发 checkpoint 2 时, event c 的 state才最终被保存下来. <strong>所以说,可以这样理解, 进入flink 系统中的 事件 永远只会被 一次state记录并checkpoint下来,而state是永远不会发生重复被消费的, 这也就是 flink内部的一致性语义,就叫做 状态 Exactly once.</strong></p><ul><li><h4 id="端到端（end-to-end）Exactly-Once"><a href="#端到端（end-to-end）Exactly-Once" class="headerlink" title="端到端（end-to-end）Exactly-Once"></a>端到端（end-to-end）Exactly-Once</h4></li></ul><p>2017年12月份发布的Apache Flink 1.4版本，引进了一个重要的特性：TwoPhaseCommitSinkFunction.，它抽取了两阶段提交协议的公共部分，使得构建端到端Excatly-Once的Flink程序变为了可能。这些外部系统包括Kafka0.11及以上的版本，以及一些其他的数据输入（data sources）和数据接收(data sink)。它提供了一个抽象层，需要用户自己手动去实现Exactly-Once语义.</p><p>为了提供端到端Exactly-Once语义，除了Flink应用程序本身的状态，Flink写入的外部存储也需要满足这个语义。也就是说，这些外部系统必须提供提交或者回滚的方法，然后通过Flink的checkpoint来协调</p><p><a href="https://www.whitewood.me/2018/10/16/Flink-Exactly-Once-%E6%8A%95%E9%80%92%E5%AE%9E%E7%8E%B0%E6%B5%85%E6%9E%90/" target="_blank" rel="noopener">参考文章1</a></p><p><a href="https://my.oschina.net/u/992559/blog/1819948" target="_blank" rel="noopener">参考文章2</a></p><h2 id="flink-的-window-实现机制"><a href="#flink-的-window-实现机制" class="headerlink" title="flink 的 window 实现机制"></a>flink 的 window 实现机制</h2><p>Flink 中定义一个窗口主要需要以下三个组件。</p><ul><li><p><strong>Window Assigner：</strong>用来决定某个元素被分配到哪个/哪些窗口中去。</p></li><li><p><strong>Trigger：</strong>触发器。决定了一个窗口何时能够被计算或清除，每个窗口都会拥有一个自己的Trigger。</p></li><li><p><strong>Evictor：</strong>可以译为“驱逐者”。在Trigger触发之后，在窗口被处理之前，Evictor（如果有Evictor的话）会用来剔除窗口中不需要的元素，相当于一个filter。</p></li></ul><h4 id="Window-的实现"><a href="#Window-的实现" class="headerlink" title="Window 的实现"></a>Window 的实现</h4><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink中window的实现.png" alt=""></p><p>首先上图中的组件都位于一个算子（window operator）中，数据流源源不断地进入算子，每一个到达的元素都会被交给 WindowAssigner。WindowAssigner 会决定元素被放到哪个或哪些窗口（window），可能会创建新窗口。因为一个元素可以被放入多个窗口中，所以同时存在多个窗口是可能的。注意，<code>Window</code>本身只是一个ID标识符，其内部可能存储了一些元数据，如<code>TimeWindow</code>中有开始和结束时间，但是并不会存储窗口中的元素。窗口中的元素实际存储在 Key/Value State 中，key为<code>Window</code>，value为元素集合（或聚合值）。为了保证窗口的容错性，该实现依赖了 Flink 的 State 机制（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/state.html" target="_blank" rel="noopener">state 文档</a>）。</p><p>每一个窗口都拥有一个属于自己的 Trigger，Trigger上会有定时器，用来决定一个窗口何时能够被计算或清除。每当有元素加入到该窗口，或者之前注册的定时器超时了，那么Trigger都会被调用。Trigger的返回结果可以是 continue（不做任何操作），fire（处理窗口数据），purge（移除窗口和窗口中的数据），或者 fire + purge。一个Trigger的调用结果只是fire的话，那么会计算窗口并保留窗口原样，也就是说窗口中的数据仍然保留不变，等待下次Trigger fire的时候再次执行计算。一个窗口可以被重复计算多次知道它被 purge 了。在purge之前，窗口会一直占用着内存。</p><p>当Trigger fire了，窗口中的元素集合就会交给<code>Evictor</code>（如果指定了的话）。Evictor 主要用来遍历窗口中的元素列表，并决定最先进入窗口的多少个元素需要被移除。剩余的元素会交给用户指定的函数进行窗口的计算。如果没有 Evictor 的话，窗口中的所有元素会一起交给函数进行计算。</p><p>计算函数收到了窗口的元素（可能经过了 Evictor 的过滤），并计算出窗口的结果值，并发送给下游。窗口的结果值可以是一个也可以是多个。DataStream API 上可以接收不同类型的计算函数，包括预定义的<code>sum()</code>,<code>min()</code>,<code>max()</code>，还有 <code>ReduceFunction</code>，<code>FoldFunction</code>，还有<code>WindowFunction</code>。WindowFunction 是最通用的计算函数，其他的预定义的函数基本都是基于该函数实现的。</p><p>Flink 对于一些聚合类的窗口计算（如sum,min）做了优化，因为聚合类的计算不需要将窗口中的所有数据都保存下来，只需要保存一个result值就可以了。每个进入窗口的元素都会执行一次聚合函数并修改result值。这样可以大大降低内存的消耗并提升性能。但是如果用户定义了 Evictor，则不会启用对聚合窗口的优化，因为 Evictor 需要遍历窗口中的所有元素，必须要将窗口中所有元素都存下来。</p><p><a href="http://wuchong.me/blog/2016/05/25/flink-internals-window-mechanism/" target="_blank" rel="noopener">参考文章</a></p><h2 id="flink-的-window-分类"><a href="#flink-的-window-分类" class="headerlink" title="flink 的 window 分类"></a>flink 的 window 分类</h2><p><strong>flink中的窗口主要分为3大类共5种窗口</strong>:</p><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink中window分类.png" alt=""></p><ul><li><p><strong>Time Window 时间窗口</strong></p><ul><li><p><strong>Tumbing Time Window 滚动时间窗口</strong></p><p>实现统计每一分钟(或其他长度)窗口内 计算的效果</p></li><li><p><strong>Sliding Time Window 滑动时间窗口</strong></p><p>实现每过xxx时间 统计 xxx时间窗口的效果. 比如，我们可以每30秒计算一次最近一分钟用户购买的商品总数。</p></li></ul></li><li><p><strong>Count Window 计数窗口</strong></p><ul><li><p><strong>Tumbing Count Window  滚动计数窗口</strong></p><p>当我们想要每100个用户购买行为事件统计购买总数，那么每当窗口中填满100个元素了，就会对窗口进行计算，这种窗口我们称之为翻滚计数窗口（Tumbling Count Window）</p></li><li><p><strong>Sliding Count Window   滑动计数窗口</strong></p><p>和Sliding Time Window含义是类似的，例如计算每10个元素计算一次最近100个元素的总和</p></li></ul></li><li><p><strong>Session Window  会话窗口</strong></p><p>在这种用户交互事件流中，我们首先想到的是将事件聚合到会话窗口中（一段用户持续活跃的周期），由非活跃的间隙分隔开。如上图所示，就是需要计算每个用户在活跃期间总共购买的商品数量，如果用户30秒没有活动则视为会话断开（假设raw data stream是单个用户的购买行为流）</p></li></ul><h2 id="flink-的-state-是存储在哪里的"><a href="#flink-的-state-是存储在哪里的" class="headerlink" title="flink 的 state 是存储在哪里的"></a>flink 的 state 是存储在哪里的</h2><p>Apache Flink内部有四种state的存储实现，具体如下：</p><ul><li><strong>基于内存的HeapStateBackend</strong> - 在debug模式使用，不 建议在生产模式下应用；</li><li><strong>基于HDFS的FsStateBackend</strong> - 分布式文件持久化，每次读写都产生网络IO，整体性能不佳；</li><li><strong>基于RocksDB的RocksDBStateBackend</strong> - 本地文件+异步HDFS持久化；</li><li><strong>基于Niagara(Alibaba内部实现)NiagaraStateBackend</strong> - 分布式持久化- 在Alibaba生产环境应用；</li></ul><p><a href="https://juejin.im/post/5c87dbdbe51d45494c77d607" target="_blank" rel="noopener">参考文章</a></p><h2 id="flink是如何实现反压的"><a href="#flink是如何实现反压的" class="headerlink" title="flink是如何实现反压的"></a>flink是如何实现反压的</h2><p>flink的反压经历了两个发展阶段,分别是基于TCP的反压(&lt;1.5)和基于credit的反压(&gt;1.5)</p><ul><li><h4 id="基于-TCP-的反压"><a href="#基于-TCP-的反压" class="headerlink" title="基于 TCP 的反压"></a>基于 TCP 的反压</h4><p>flink中的消息发送通过RS(ResultPartition),消息接收通过IC(InputGate),两者的数据都是以 LocalBufferPool的形式来存储和提取,进一步的依托于Netty的NetworkBufferPool,之后更底层的便是依托于TCP的滑动窗口机制,当IC端的buffer池满了之后,两个task之间的滑动窗口大小便为0,此时RS端便无法再发送数据</p><p>基于TCP的反压最大的问题是会造成整个TaskManager端的反压,所有的task都会受到影响</p></li><li><h4 id="基于-Credit-的反压"><a href="#基于-Credit-的反压" class="headerlink" title="基于 Credit 的反压"></a>基于 Credit 的反压</h4><p>RS与IC之间通过backlog和credit来确定双方可以发送和接受的数据量的大小以提前感知,而不是通过TCP滑动窗口的形式来确定buffer的大小之后再进行反压</p><p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\flink基于credit的反压.png" alt=""></p></li></ul><p><a href="https://www.bilibili.com/video/av55487329" target="_blank" rel="noopener">参考视频</a></p><p><a href="https://blog.csdn.net/u010376788/article/details/92086752" target="_blank" rel="noopener">参考文章1</a></p><p><a href="https://blog.csdn.net/u010376788/article/details/95047250" target="_blank" rel="noopener">参考文章2</a></p><h2 id="flink的部署模式都有哪些"><a href="#flink的部署模式都有哪些" class="headerlink" title="flink的部署模式都有哪些"></a>flink的部署模式都有哪些</h2><p><strong>flink可以以多种方式部署,包括standlone模式/yarn/Mesos/Kubernetes/Docker/AWS/Google Compute Engine/MAPR等</strong></p><p>一般公司中主要采用 on yarn模式</p><h2 id="讲一下flink-on-yarn的部署"><a href="#讲一下flink-on-yarn的部署" class="headerlink" title="讲一下flink on yarn的部署"></a>讲一下flink on yarn的部署</h2><p>Flink作业提交有两种类型:</p><ul><li><h4 id="yarn-session"><a href="#yarn-session" class="headerlink" title="yarn session"></a>yarn session</h4><p>需要先启动集群，然后在提交作业，接着会向yarn申请一块空间后，资源永远保持不变。如果资源满了，下一个作业就无法提交，只能等到yarn中的其中一个作业执行完成后，释放了资源，那下一个作业才会正常提交.</p><ul><li><p>客户端模式</p><p>对于客户端模式而言，你可以启动多个yarn session，一个yarn session模式对应一个JobManager,并按照需求提交作业，同一个Session中可以提交多个Flink作业。如果想要停止Flink Yarn Application，需要通过yarn application -kill命令来停止.</p></li><li><p>分离式模式</p><p>对于分离式模式，并不像客户端那样可以启动多个yarn session，如果启动多个，会出现下面的session一直处在等待状态。JobManager的个数只能是一个，同一个Session中可以提交多个Flink作业。如果想要停止Flink Yarn Application，需要通过yarn application -kill命令来停止</p></li></ul></li><li><h4 id="Flink-run-Per-Job"><a href="#Flink-run-Per-Job" class="headerlink" title="Flink run(Per-Job)"></a>Flink run(Per-Job)</h4><p>直接在YARN上提交运行Flink作业(Run a Flink job on YARN)，这种方式的好处是一个任务会对应一个job,即没提交一个作业会根据自身的情况，向yarn申请资源，直到作业执行完成，并不会影响下一个作业的正常运行，除非是yarn上面没有任何资源的情况下</p></li></ul><table><thead><tr><th>Session</th><th></th></tr></thead><tbody><tr><td>共享Dispatcher和Resource Manager</td><td>Dispatcher和Resource Manager</td></tr><tr><td>共享资源(即 TaskExecutor)</td><td>按需要申请资源 (即 TaskExecutor)</td></tr><tr><td>适合规模小,执行时间短的作业</td></tr></tbody></table><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flinkOnYarn.png" alt=""></p><h2 id="flink中的时间概念-eventTime-和-processTime的区别"><a href="#flink中的时间概念-eventTime-和-processTime的区别" class="headerlink" title="flink中的时间概念 , eventTime 和 processTime的区别"></a>flink中的时间概念 , eventTime 和 processTime的区别</h2><p>Flink中有三种时间概念,分别是 Processing Time、Event Time 和 Ingestion Time</p><ul><li><h4 id="Processing-Time"><a href="#Processing-Time" class="headerlink" title="Processing Time"></a>Processing Time</h4><p>Processing Time 是指事件被处理时机器的系统时间。</p><p>当流程序在 Processing Time 上运行时，所有基于时间的操作(如时间窗口)将使用当时机器的系统时间。每小时 Processing Time 窗口将包括在系统时钟指示整个小时之间到达特定操作的所有事件</p></li><li><h4 id="Event-Time"><a href="#Event-Time" class="headerlink" title="Event Time"></a>Event Time</h4><p>Event Time 是事件发生的时间，一般就是数据本身携带的时间。这个时间通常是在事件到达 Flink 之前就确定的，并且可以从每个事件中获取到事件时间戳。在 Event Time 中，时间取决于数据，而跟其他没什么关系。Event Time 程序必须指定如何生成 Event Time 水印，这是表示 Event Time 进度的机制</p></li><li><h4 id="Ingestion-Time"><a href="#Ingestion-Time" class="headerlink" title="Ingestion Time"></a>Ingestion Time</h4><p>Ingestion Time 是事件进入 Flink 的时间。 在源操作处，每个事件将源的当前时间作为时间戳，并且基于时间的操作（如时间窗口）会利用这个时间戳</p><p>Ingestion Time 在概念上位于 Event Time 和 Processing Time 之间。 与 Processing Time 相比，它稍微贵一些，但结果更可预测。因为 Ingestion Time 使用稳定的时间戳（在源处分配一次），所以对事件的不同窗口操作将引用相同的时间戳，而在 Processing Time 中，每个窗口操作符可以将事件分配给不同的窗口（基于机器系统时间和到达延迟）</p><p>与 Event Time 相比，Ingestion Time 程序无法处理任何无序事件或延迟数据，但程序不必指定如何生成水印</p></li></ul><p><a href="https://zhuanlan.zhihu.com/p/55322400" target="_blank" rel="noopener">参考文章</a></p><h2 id="flink中的session-Window怎样使用"><a href="#flink中的session-Window怎样使用" class="headerlink" title="flink中的session Window怎样使用"></a>flink中的session Window怎样使用</h2><p>会话窗口主要是将某段时间内活跃度较高的数据聚合成一个窗口进行计算,窗口的触发条件是 Session Gap, 是指在规定的时间内如果没有数据活跃接入,则认为窗口结束,然后触发窗口结果</p><p>Session Windows窗口类型比较适合非连续性数据处理或周期性产生数据的场景,根据用户在线上某段时间内的活跃度对用户行为进行数据统计</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val sessionWindowStream = inputStream</span><br><span class="line">.keyBy(_.id)</span><br><span class="line">//使用EventTimeSessionWindow 定义 Event Time 滚动窗口</span><br><span class="line">.window(EventTimeSessionWindow.withGap(Time.milliseconds(10)))</span><br><span class="line">.process(......)</span><br></pre></td></tr></table></figure><p>Session Window 本质上没有固定的起止时间点,因此底层计算逻辑和Tumbling窗口及Sliding 窗口有一定的区别,</p><p>Session Window 为每个进入的数据都创建了一个窗口,最后再将距离窗口Session Gap 最近的窗口进行合并,然后计算窗口结果</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;讲一下flink的运行架构&quot;&gt;&lt;a href=&quot;#讲一下flink的运行架构&quot; class=&quot;headerlink&quot; title=&quot;讲一下flink的运行架构&quot;&gt;&lt;/a&gt;讲一下flink的运行架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink架构图.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的 TaskManager。由 Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://icocos.github.io/categories/Flink/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Flink" scheme="https://icocos.github.io/tags/Flink/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试之Spark</title>
    <link href="https://icocos.github.io/2020/03/04/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8BSpark/"/>
    <id>https://icocos.github.io/2020/03/04/大数据面试之Spark/</id>
    <published>2020-03-04T10:56:46.000Z</published>
    <updated>2020-04-02T15:03:41.521Z</updated>
    
    <content type="html"><![CDATA[<h2 id="讲一下spark-的运行架构"><a href="#讲一下spark-的运行架构" class="headerlink" title="讲一下spark 的运行架构"></a>讲一下spark 的运行架构</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark架构图.jpg" alt=""></p><ul><li><p><strong>Cluster Manager(Master)</strong>：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器</p></li><li><p><strong>Worker节点</strong>：从节点，负责控制计算节点，启动Executor或者Driver。</p></li><li><p><strong>Driver</strong>： 运行Application 的main()函数</p></li><li><p><strong>Executor</strong>：执行器，是为某个Application运行在worker node上的一个进程</p></li></ul><a id="more"></a><p><a href="https://juejin.im/post/5a73c8386fb9a0635e3cafaa" target="_blank" rel="noopener">参考文章</a></p><h2 id="一个spark程序的执行流程"><a href="#一个spark程序的执行流程" class="headerlink" title="一个spark程序的执行流程"></a>一个spark程序的执行流程</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark程序执行流程.jpg" alt=""></p><ul><li><strong>A -&gt;</strong> 当 Driver 进程被启动之后,首先它将发送请求到Master节点上,进行Spark应用程序的注册</li><li><strong>B -&gt;</strong> Master在接受到Spark应用程序的注册申请之后,会发送给Worker,让其进行资源的调度和分配.</li><li><strong>C -&gt;</strong> Worker 在接受Master的请求之后,会为Spark应用程序启动Executor, 来分配资源</li><li><strong>D -&gt;</strong> Executor启动分配资源好后,就会想Driver进行反注册,这是Driver已经知道哪些Executor为他服务了</li><li><strong>E -&gt;</strong> 当Driver得到注册了Executor之后,就可以开始正式执行spark应用程序了. 首先第一步,就是创建初始RDD,读取数据源,再执行之后的一系列算子. HDFS文件内容被读取到多个worker节点上,形成内存中的分布式数据集,也就是初始RDD</li><li><strong>F -&gt;</strong> Driver就会根据 Job 任务任务中的算子形成对应的task,最后提交给 Executor, 来分配给task进行计算的线程</li><li><strong>G -&gt;</strong> task就会去调用对应的任务数据来计算,并task会对调用过来的RDD的partition数据执行指定的算子操作,形成新的RDD的partition,这时一个大的循环就结束了</li><li>后续的RDD的partition数据又通过Driver形成新的一批task提交给Executor执行,循环这个操作,直到所有的算子结束</li></ul><p><a href="https://zhuanlan.zhihu.com/p/35713084" target="_blank" rel="noopener">参考文章</a></p><h2 id="spark的shuffle介绍"><a href="#spark的shuffle介绍" class="headerlink" title="spark的shuffle介绍"></a>spark的shuffle介绍</h2><p><strong>spark中的shuffle主要有3种:</strong></p><ul><li><p><strong>Hash Shuffle</strong> 2.0以后移除</p><p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\spark-shuffle-v1.png" alt=""></p><p>在map阶段(shuffle write)，每个map都会为下游stage的每个partition写一个临时文件，假如下游stage有1000个partition，那么每个map都会生成1000个临时文件，一般来说一个executor上会运行多个map task，这样下来，一个executor上会有非常多的临时文件，假如一个executor上运行M个map task，下游stage有N个partition，那么一个executor上会生成M<em>N个文件。另一方面，如果一个executor上有K个core，那么executor同时可运行K个task，这样一来，就会同时申请K</em>N个文件描述符，一旦partition数较多，势必会耗尽executor上的文件描述符，同时生成K*N个write handler也会带来大量内存的消耗。</p><p>在reduce阶段(shuffle read)，每个reduce task都会拉取所有map对应的那部分partition数据，那么executor会打开所有临时文件准备网络传输，这里又涉及到大量文件描述符，另外，如果reduce阶段有combiner操作，那么它会把网络中拉到的数据保存在一个<code>HashMap</code>中进行合并操作，如果数据量较大，很容易引发OOM操作。</p></li><li><p><strong>Sort Shuffle</strong> 1.1开始(sort shuffle也经历过优化升级,详细见参考文章1)</p><p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\spark-shuffle-v3.png" alt=""></p><p>在map阶段(shuffle write)，会按照partition id以及key对记录进行排序，将所有partition的数据写在同一个文件中，该文件中的记录首先是按照partition id排序一个一个分区的顺序排列，每个partition内部是按照key进行排序存放，map task运行期间会顺序写每个partition的数据，并通过一个索引文件记录每个partition的大小和偏移量。这样一来，每个map task一次只开两个文件描述符，一个写数据，一个写索引，大大减轻了Hash Shuffle大量文件描述符的问题，即使一个executor有K个core，那么最多一次性开K*2个文件描述符。</p><p>在reduce阶段(shuffle read)，reduce task拉取数据做combine时不再是采用<code>HashMap</code>，而是采用<code>ExternalAppendOnlyMap</code>，该数据结构在做combine时，如果内存不足，会刷写磁盘，很大程度的保证了鲁棒性，避免大数据情况下的OOM。</p></li><li><p><strong>Unsafe Shuffle</strong> 1.5开始, 1.6与Sort shuffle合并</p><p>从spark 1.5.0开始，spark开始了钨丝计划(Tungsten)，目的是优化内存和CPU的使用，进一步提升spark的性能。为此，引入Unsafe Shuffle，它的做法是将数据记录用二进制的方式存储，直接在序列化的二进制数据上sort而不是在java 对象上，这样一方面可以减少memory的使用和GC的开销，另一方面避免shuffle过程中频繁的序列化以及反序列化。在排序过程中，它提供cache-efficient sorter，使用一个8 bytes的指针，把排序转化成了一个指针数组的排序，极大的优化了排序性能.</p></li></ul><hr><p><strong>现在2.1 分为三种writer， 分为 BypassMergeSortShuffleWriter， SortShuffleWriter 和 UnsafeShuffleWriter</strong></p><h4 id="三种Writer的分类"><a href="#三种Writer的分类" class="headerlink" title="三种Writer的分类"></a>三种Writer的分类</h4><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/sparkShuffleWriter.jpg" alt=""></p><p>上面是使用哪种 writer 的判断依据， 是否开启 mapSideCombine 这个判断，是因为有些算子会在 map 端先进行一次 combine， 减少传输数据。 因为 BypassMergeSortShuffleWriter 会临时输出Reducer个（分区数目）小文件，所以分区数必须要小于一个阀值，默认是小于200</p><p>UnsafeShuffleWriter需要Serializer支持relocation，Serializer支持relocation：原始数据首先被序列化处理，并且再也不需要反序列，在其对应的元数据被排序后，需要Serializer支持relocation，在指定位置读取对应数据</p><p><a href="http://sharkdtu.com/posts/spark-shuffle.html" target="_blank" rel="noopener">参考文章1</a></p><p><a href="http://spark.coolplayer.net/?p=576" target="_blank" rel="noopener">参考文章2</a></p><h2 id="Spark的-partitioner-都有哪些"><a href="#Spark的-partitioner-都有哪些" class="headerlink" title="Spark的 partitioner 都有哪些?"></a>Spark的 partitioner 都有哪些?</h2><p><strong>Partitioner主要有两个实现类：HashPartitioner和RangePartitioner,HashPartitioner是大部分transformation的默认实现，sortBy、sortByKey使用RangePartitioner实现，也可以自定义Partitioner.</strong></p><ul><li><p><strong>HashPartitioner</strong></p><p>numPartitions方法返回传入的分区数，getPartition方法使用key的hashCode值对分区数取模得到PartitionId，写入到对应的bucket中。</p></li><li><p><strong>RangePartitioner</strong></p><p>RangePartitioner是先根据所有partition中数据的分布情况，尽可能均匀地构造出重分区的分隔符，再将数据的key值根据分隔符进行重新分区</p><ul><li>使用reservoir Sample方法对每个Partition进行分别抽样</li><li>对数据量大(大于sampleSizePerPartition)的分区进行重新抽样</li><li>由权重信息计算出分区分隔符rangeBounds</li><li>由rangeBounds计算分区数和key的所属分区</li></ul></li></ul><p><a href="https://blog.csdn.net/qq_34842671/article/details/83685179" target="_blank" rel="noopener">参考文章</a></p><h2 id="spark有哪几种join"><a href="#spark有哪几种join" class="headerlink" title="spark有哪几种join"></a>spark有哪几种join</h2><p><strong>Spark 中和 join 相关的算子有这几个</strong>：<code>join</code>、<code>fullOuterJoin</code>、<code>leftOuterJoin</code>、<code>rightOuterJoin</code></p><ul><li><p><strong>join</strong></p><p>join函数会输出两个RDD中key相同的所有项，并将它们的value联结起来，它联结的key要求在两个表中都存在，类似于SQL中的INNER JOIN。但它不满足交换律，a.join(b)与b.join(a)的结果不完全相同，值插入的顺序与调用关系有关。</p></li><li><p><strong>leftOuterJoin</strong></p><p>leftOuterJoin会保留对象的所有key，而用None填充在参数RDD other中缺失的值，因此调用顺序会使结果完全不同。如下面展示的结果，</p></li><li><p><strong>rightOuterJoin</strong></p><p>rightOuterJoin与leftOuterJoin基本一致，区别在于它的结果保留的是参数other这个RDD中所有的key。</p></li><li><p><strong>fullOuterJoin</strong></p><p>fullOuterJoin会保留两个RDD中所有的key，因此所有的值列都有可能出现缺失的情况，所有的值列都会转为Some对象。</p></li></ul><p><a href="http://www.neilron.xyz/join-in-spark/" target="_blank" rel="noopener">参考文章</a></p><h2 id="RDD有哪些特点"><a href="#RDD有哪些特点" class="headerlink" title="RDD有哪些特点"></a>RDD有哪些特点</h2><ol><li><p><strong>A list of partitions</strong><br>RDD是一个由多个partition（某个节点里的某一片连续的数据）组成的的list；将数据加载为RDD时，一般会遵循数据的本地性（一般一个hdfs里的block会加载为一个partition）。</p></li><li><p><strong>A function for computing each split</strong><br>RDD的每个partition上面都会有function，也就是函数应用，其作用是实现RDD之间partition的转换。</p></li><li><p><strong>A list of dependencies on other RDDs</strong><br>RDD会记录它的依赖 ，为了容错（重算，cache，checkpoint），也就是说在内存中的RDD操作时出错或丢失会进行重算。</p></li><li><p><strong>Optionally,a Partitioner for Key-value RDDs</strong><br>  可选项，如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，例如这里自定义的Partitioner是基于key进行分区，那则会将不同RDD里面的相同key的数据放到同一个partition里面</p></li><li><p><strong>Optionally, a list of preferred locations to compute each split on</strong></p><p>最优的位置去计算，也就是数据的本地性。</p></li></ol><h2 id="讲一下宽依赖和窄依赖"><a href="#讲一下宽依赖和窄依赖" class="headerlink" title="讲一下宽依赖和窄依赖"></a>讲一下宽依赖和窄依赖</h2><p>区别宽窄依赖的核心点是 <strong>子RDD的partition与父RDD的partition是否是1对多的关系</strong>,如果是这样的关系的话,</p><p>说明多个父rdd的partition需要经过shuffle过程汇总到一个子rdd的partition,这样就是一次宽依赖,在DAGScheduler中会产生stage的切分.</p><h2 id="Spark中的算子都有哪些"><a href="#Spark中的算子都有哪些" class="headerlink" title="Spark中的算子都有哪些"></a>Spark中的算子都有哪些</h2><p>总的来说,spark分为两大类算子:</p><ul><li><p><strong>Transformation 变换/转换算子：这种变换并不触发提交作业，完成作业中间过程处理</strong></p><p>Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算</p></li><li><p><strong>Action 行动算子：这类算子会触发 SparkContext 提交 Job 作业</strong></p><p>Action 算子会触发 Spark 提交作业（Job），并将数据输出 Spark系统</p><hr></li></ul><h4 id="1-Value数据类型的Transformation算子"><a href="#1-Value数据类型的Transformation算子" class="headerlink" title="1. Value数据类型的Transformation算子"></a>1. Value数据类型的Transformation算子</h4><ul><li><p>输入分区与输出分区一对一型</p><ul><li>map算子</li><li>flatMap算子</li><li>mapPartitions算子</li><li>glom算子</li></ul></li><li><p>输入分区与输出分区多对一型</p><ul><li>union算子</li><li>cartesian算子</li></ul></li><li><p>输入分区与输出分区多对多型</p><ul><li>grouBy算子</li></ul></li><li><p>输出分区为输入分区子集型</p><ul><li>filter算子</li><li>distinct算子</li><li>subtract算子</li><li>sample算子</li><li>takeSample算子</li></ul></li><li><p>Cache型</p><ul><li>cache算子</li><li>persist算子</li></ul></li></ul><h4 id="2-Key-Value数据类型的Transfromation算子"><a href="#2-Key-Value数据类型的Transfromation算子" class="headerlink" title="2. Key-Value数据类型的Transfromation算子"></a>2. Key-Value数据类型的Transfromation算子</h4><ul><li><p>输入分区与输出分区一对一</p><ul><li>mapValues算子</li></ul></li><li><p>对单个RDD或两个RDD聚集</p><ul><li>combineByKey算子</li><li>reduceByKey算子</li><li>partitionBy算子</li><li>Cogroup算子</li></ul></li><li><p>连接</p><ul><li>join算子</li><li>leftOutJoin 和 rightOutJoin算子</li></ul></li></ul><h4 id="3-Action算子"><a href="#3-Action算子" class="headerlink" title="3. Action算子"></a>3. Action算子</h4><ul><li><p>无输出</p><ul><li>foreach算子</li></ul></li><li><p>HDFS算子</p><ul><li>saveAsTextFile算子</li><li>saveAsObjectFile算子</li></ul></li><li><p>Scala集合和数据类型</p><ul><li>collect算子</li><li>collectAsMap算子</li><li>reduceByKeyLocally算子</li><li>lookup算子</li><li>count算子</li><li>top算子</li><li>reduce算子</li><li>fold算子</li><li>aggregate算子</li><li>countByValue</li><li>countByKey</li></ul></li></ul><p><a href="https://www.cnblogs.com/kpsmile/p/10434390.html" target="_blank" rel="noopener">参考文章</a></p><h2 id="RDD的缓存级别都有哪些"><a href="#RDD的缓存级别都有哪些" class="headerlink" title="RDD的缓存级别都有哪些"></a>RDD的缓存级别都有哪些</h2><p>NONE :什么类型都不是<br>DISK_ONLY：磁盘<br>DISK_ONLY_2：磁盘；双副本<br>MEMORY_ONLY： 内存；反序列化；把RDD作为反序列化的方式存储，假如RDD的内容存不下，剩余的分区在以后需要时会重新计算，不会刷到磁盘上。<br>MEMORY_ONLY_2：内存；反序列化；双副本<br>MEMORY_ONLY_SER：内存；序列化；这种序列化方式，每一个partition以字节数据存储，好处是能带来更好的空间存储，但CPU耗费高<br>MEMORY_ONLY_SER_2 : 内存；序列化；双副本<br>MEMORY_AND_DISK：内存 + 磁盘；反序列化；双副本；RDD以反序列化的方式存内存，假如RDD的内容存不下，剩余的会存到磁盘<br>MEMORY_AND_DISK_2 : 内存 + 磁盘；反序列化；双副本<br>MEMORY_AND_DISK_SER：内存 + 磁盘；序列化<br>MEMORY_AND_DISK_SER_2：内存 + 磁盘；序列化；双副本</p><h2 id="RDD懒加载是什么意思"><a href="#RDD懒加载是什么意思" class="headerlink" title="RDD懒加载是什么意思"></a>RDD懒加载是什么意思</h2><p>Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Acion 操作的时候才会真正触发运算,这也就是懒加载.</p><h2 id="讲一下spark的几种部署方式"><a href="#讲一下spark的几种部署方式" class="headerlink" title="讲一下spark的几种部署方式"></a>讲一下spark的几种部署方式</h2><p><strong>目前,除了local模式为本地调试模式以为, Spark支持三种分布式部署方式，分别是standalone、spark on mesos和 spark on YARN</strong></p><ul><li><p><strong>Standalone模式</strong></p><p>即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。从一定程度上说，该模式是其他两种的基础。目前Spark在standalone模式下是没有任何单点故障问题的，这是借助zookeeper实现的，思想类似于Hbase master单点故障解决方案。将Spark standalone与MapReduce比较，会发现它们两个在架构上是完全一致的： </p><ul><li>都是由master/slaves服务组成的，且起初master均存在单点故障，后来均通过zookeeper解决（Apache MRv1的JobTracker仍存在单点问题，但CDH版本得到了解决）； </li><li>各个节点上的资源被抽象成粗粒度的slot，有多少slot就能同时运行多少task。不同的是，MapReduce将slot分为map slot和reduce slot，它们分别只能供Map Task和Reduce Task使用，而不能共享，这是MapReduce资源利率低效的原因之一，而Spark则更优化一些，它不区分slot类型，只有一种slot，可以供各种类型的Task使用，这种方式可以提高资源利用率，但是不够灵活，不能为不同类型的Task定制slot资源。总之，这两种方式各有优缺点。 </li></ul></li><li><p><strong>Spark On YARN模式</strong></p><p><strong>spark on yarn 的支持两种模式：</strong> </p><ul><li>yarn-cluster：适用于生产环境； </li><li>yarn-client：适用于交互、调试，希望立即看到app的输出 </li></ul><p>yarn-cluster和yarn-client的区别在于yarn appMaster，每个yarn app实例有一个appMaster进程，是为app启动的第一个container；负责从ResourceManager请求资源，获取到资源后，告诉NodeManager为其启动container。yarn-cluster和yarn-client模式内部实现还是有很大的区别。如果你需要用于生产环境，那么请选择yarn-cluster；而如果你仅仅是Debug程序，可以选择yarn-client。</p></li><li><p><strong>Spark On Mesos模式</strong></p><p>Spark运行在Mesos上会比运行在YARN上更加灵活，更加自然。目前在Spark On Mesos环境中，用户可选择两种调度模式之一运行自己的应用程序</p><ul><li><p>粗粒度模式（Coarse-grained Mode）：每个应用程序的运行环境由一个Dirver和若干个Executor组成，其中，每个Executor占用若干资源，内部可运行多个Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。</p></li><li><p>细粒度模式（Fine-grained Mode）：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个Task运行完之后可以马上释放对应的资源。</p></li></ul><h2 id="spark-on-yarn-模式下的-cluster模式和-client模式有什么区别"><a href="#spark-on-yarn-模式下的-cluster模式和-client模式有什么区别" class="headerlink" title="spark on yarn 模式下的 cluster模式和 client模式有什么区别"></a>spark on yarn 模式下的 cluster模式和 client模式有什么区别</h2></li></ul><ol><li>yarn-cluster 适用于生产环境。而 yarn-client 适用于交互和调试，也就是希望快速地看到 application 的输出.</li><li>yarn-cluster 和 yarn-client 模式的区别其实就是 <strong>Application Master 进程</strong>的区别，yarn-cluster 模式下，driver 运行在 AM(Application Master)中，它负责向 YARN 申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉 Client，作业会继续在 YARN 上运行。然而 yarn-cluster 模式不适合运行交互类型的作业。而 yarn-client 模式下，Application Master 仅仅向 YARN 请求 executor，Client 会和请求的container 通信来调度他们工作，也就是说 Client 不能离开。</li></ol><h2 id="spark运行原理-从提交一个jar到最后返回结果-整个过程"><a href="#spark运行原理-从提交一个jar到最后返回结果-整个过程" class="headerlink" title="spark运行原理,从提交一个jar到最后返回结果,整个过程"></a>spark运行原理,从提交一个jar到最后返回结果,整个过程</h2><ol><li><code>spark-submit</code> 提交代码，执行 <code>new SparkContext()</code>，在 SparkContext 里构造 <code>DAGScheduler</code> 和 <code>TaskScheduler</code>。</li><li>TaskScheduler 会通过后台的一个进程，连接 Master，向 Master 注册 Application。</li><li>Master 接收到 Application 请求后，会使用相应的资源调度算法，在 Worker 上为这个 Application 启动多个 Executer。</li><li>Executor 启动后，会自己反向注册到 TaskScheduler 中。 所有 Executor 都注册到 Driver 上之后，SparkContext 结束初始化，接下来往下执行我们自己的代码。</li><li>每执行到一个 Action，就会创建一个 Job。Job 会提交给 DAGScheduler。</li><li>DAGScheduler 会将 Job划分为多个 stage，然后每个 stage 创建一个 TaskSet。</li><li>TaskScheduler 会把每一个 TaskSet 里的 Task，提交到 Executor 上执行。</li><li>Executor 上有线程池，每接收到一个 Task，就用 TaskRunner 封装，然后从线程池里取出一个线程执行这个 task。(TaskRunner 将我们编写的代码，拷贝，反序列化，执行 Task，每个 Task 执行 RDD 里的一个 partition)</li></ol><h2 id="spark的stage是如何划分的"><a href="#spark的stage是如何划分的" class="headerlink" title="spark的stage是如何划分的"></a>spark的stage是如何划分的</h2><p><strong>stage的划分依据就是看是否产生了shuflle(即宽依赖),遇到一个shuffle操作就划分为前后两个stage.</strong></p><p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\stageDivide.jpg" alt=""></p><h2 id="spark2-0为什么放弃了akka-而用netty"><a href="#spark2-0为什么放弃了akka-而用netty" class="headerlink" title="spark2.0为什么放弃了akka 而用netty"></a>spark2.0为什么放弃了akka 而用netty</h2><ol><li>很多Spark用户也使用Akka，但是由于Akka不同版本之间无法互相通信，这就要求用户必须使用跟Spark完全一样的Akka版本，导致用户无法升级Akka。</li><li>Spark的Akka配置是针对Spark自身来调优的，可能跟用户自己代码中的Akka配置冲突。</li><li>Spark用的Akka特性很少，这部分特性很容易自己实现。同时，这部分代码量相比Akka来说少很多，debug比较容易。如果遇到什么bug，也可以自己马上fix，不需要等Akka上游发布新版本。而且，Spark升级Akka本身又因为第一点会强制要求用户升级他们使用的Akka，对于某些用户来说是不现实的。</li></ol><p><a href="https://www.zhihu.com/question/61638635" target="_blank" rel="noopener">参考文章</a></p><h2 id="spark的各种HA-master-worker-executor的ha"><a href="#spark的各种HA-master-worker-executor的ha" class="headerlink" title="spark的各种HA,  master/worker/executor的ha"></a>spark的各种HA,  master/worker/executor的ha</h2><ul><li><h4 id="Master异常"><a href="#Master异常" class="headerlink" title="Master异常"></a>Master异常</h4><p>spark可以在集群运行时启动一个或多个standby Master,当 Master 出现异常时,会根据规则启动某个standby master接管,在standlone模式下有如下几种配置</p><ul><li><p>ZOOKEEPER</p><p>集群数据持久化到zk中,当master出现异常时,zk通过选举机制选出新的master,新的master接管是需要从zk获取持久化信息</p></li><li><p>FILESYSTEM</p><p>集群元数据信息持久化到本地文件系统, 当master出现异常时,只需要在该机器上重新启动master,启动后新的master获取持久化信息并根据这些信息恢复集群状态</p></li><li><p>CUSTOM</p><p>自定义恢复方式,对 standloneRecoveryModeFactory 抽象类 进行实现并把该类配置到系统中,当master出现异常时,会根据用户自定义行为恢复集群</p></li><li><p>None</p><p>不持久化集群的元数据, 当 master出现异常时, 新启动的Master 不进行恢复集群状态,而是直接接管集群</p></li></ul></li><li><h4 id="Worker异常"><a href="#Worker异常" class="headerlink" title="Worker异常"></a>Worker异常</h4><p>Worker 以定时发送心跳给 Master, 让 Master 知道 Worker 的实时状态,当worker出现超时时,Master 调用 timeOutDeadWorker 方法进行处理,在处理时根据 Worker 运行的是 Executor 和 Driver 分别进行处理</p><ul><li>如果是Executor, Master先把该 Worker 上运行的Executor 发送信息ExecutorUpdate给对应的Driver,告知Executor已经丢失,同时把这些Executor从其应用程序列表删除, 另外, 相关Executor的异常也需要处理</li><li>如果是Driver, 则判断是否设置重新启动,如果需要,则调用Master.shedule方法进行调度,分配合适节点重启Driver, 如果不需要重启, 则删除该应用程序</li></ul></li><li><h4 id="Executor异常"><a href="#Executor异常" class="headerlink" title="Executor异常"></a>Executor异常</h4><ol><li>Executor发生异常时由ExecutorRunner捕获该异常并发送ExecutorStateChanged信息给Worker</li><li>Worker接收到消息时, 在Worker的 handleExecutorStateChanged 方法中, 根据Executor状态进行信息更新,同时把Executor状态发送给Master</li><li>Master在接受Executor状态变化消息之后,如果发现其是异常退出,会尝试可用的Worker节点去启动Executor</li></ol></li></ul><h2 id="spark的内存管理机制"><a href="#spark的内存管理机制" class="headerlink" title="spark的内存管理机制"></a>spark的内存管理机制</h2><p><strong>spark的内存结构分为3大块:storage/execution/系统自留</strong></p><ul><li><p><strong>storage 内存</strong>：用于缓存 RDD、展开 partition、存放 Direct Task Result、存放广播变量。在 Spark Streaming receiver 模式中，也用来存放每个 batch 的 blocks</p></li><li><p><strong>execution 内存</strong>：用于 shuffle、join、sort、aggregation 中的缓存、buffer</p></li><li><p><strong>系统自留</strong>:</p><ul><li><p>在 spark 运行过程中使用：比如序列化及反序列化使用的内存，各个对象、元数据、临时变量使用的内存，函数调用使用的堆栈等</p></li><li><p>作为误差缓冲：由于 storage 和 execution 中有很多内存的使用是估算的，存在误差。当 storage 或 execution 内存使用超出其最大限制时，有这样一个安全的误差缓冲在可以大大减小 OOM 的概率</p></li></ul></li></ul><hr><h4 id="1-6版本以前的问题"><a href="#1-6版本以前的问题" class="headerlink" title="1.6版本以前的问题"></a>1.6版本以前的问题</h4><ul><li>旧方案最大的问题是 storage 和 execution 的内存大小都是固定的，不可改变，即使 execution 有大量的空闲内存且 storage 内存不足，storage 也无法使用 execution 的内存，只能进行 spill，反之亦然。所以，在很多情况下存在资源浪费</li><li>旧方案中，只有 execution 内存支持 off heap，storage 内存不支持 off heap</li></ul><h4 id="新方案的改进"><a href="#新方案的改进" class="headerlink" title="新方案的改进"></a>新方案的改进</h4><ul><li>新方案 storage 和 execution 内存可以互相借用，当一方内存不足可以向另一方借用内存，提高了整体的资源利用率</li><li>新方案中 execution 内存和 storage 内存均支持 off heap</li></ul><h2 id="spark中的广播变量"><a href="#spark中的广播变量" class="headerlink" title="spark中的广播变量"></a>spark中的广播变量</h2><p><a href="https://www.jianshu.com/p/6ef7f0a44fbf" target="_blank" rel="noopener">图片来源</a> /<a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/7-Broadcast.md" target="_blank" rel="noopener">文字来源</a></p><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark中的广播变量.png" alt=""></p><p><strong>顾名思义，broadcast 就是将数据从一个节点发送到其他各个节点上去。这样的场景很多，比如 driver 上有一张表，其他节点上运行的 task 需要 lookup 这张表，那么 driver 可以先把这张表 copy 到这些节点，这样 task 就可以在本地查表了。如何实现一个可靠高效的 broadcast 机制是一个有挑战性的问题。先看看 Spark 官网上的一段话：</strong></p><p>Broadcast variables allow the programmer to keep a <strong>read-only</strong> variable cached on each <strong>machine</strong> rather than shipping a copy of it with <strong>tasks</strong>. They can be used, for example, to give every node a copy of a <strong>large input dataset</strong> in an efficient manner. Spark also attempts to distribute broadcast variables using <strong>efficient</strong> broadcast algorithms to reduce communication cost.</p><h3 id="问题：为什么只能-broadcast-只读的变量？"><a href="#问题：为什么只能-broadcast-只读的变量？" class="headerlink" title="问题：为什么只能 broadcast 只读的变量？"></a>问题：为什么只能 broadcast 只读的变量？</h3><p>这就涉及一致性的问题，如果变量可以被更新，那么一旦变量被某个节点更新，其他节点要不要一块更新？如果多个节点同时在更新，更新顺序是什么？怎么做同步？还会涉及 fault-tolerance 的问题。为了避免维护数据一致性问题，Spark 目前只支持 broadcast 只读变量。</p><h3 id="问题：broadcast-到节点而不是-broadcast-到每个-task？"><a href="#问题：broadcast-到节点而不是-broadcast-到每个-task？" class="headerlink" title="问题：broadcast 到节点而不是 broadcast 到每个 task？"></a>问题：broadcast 到节点而不是 broadcast 到每个 task？</h3><p>因为每个 task 是一个线程，而且同在一个进程运行 tasks 都属于同一个 application。因此每个节点（executor）上放一份就可以被所有 task 共享。</p><h3 id="问题：-具体怎么用-broadcast？"><a href="#问题：-具体怎么用-broadcast？" class="headerlink" title="问题： 具体怎么用 broadcast？"></a>问题： 具体怎么用 broadcast？</h3><p>driver program 例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val data = List(1, 2, 3, 4, 5, 6)</span><br><span class="line">val bdata = sc.broadcast(data)</span><br><span class="line"></span><br><span class="line">val rdd = sc.parallelize(1 to 6, 2)</span><br><span class="line">val observedSizes = rdd.map(_ =&gt; bdata.value.size)</span><br></pre></td></tr></table></figure><p>driver 使用 <code>sc.broadcast()</code> 声明要 broadcast 的 data，bdata 的类型是 Broadcast。</p><p>当 <code>rdd.transformation(func)</code> 需要用 bdata 时，直接在 func 中调用，比如上面的例子中的 map() 就使用了 bdata.value.size。</p><h3 id="问题：怎么实现-broadcast？"><a href="#问题：怎么实现-broadcast？" class="headerlink" title="问题：怎么实现 broadcast？"></a>问题：怎么实现 broadcast？</h3><p>broadcast 的实现机制很有意思：</p><h4 id="1-分发-task-的时候先分发-bdata-的元信息"><a href="#1-分发-task-的时候先分发-bdata-的元信息" class="headerlink" title="1. 分发 task 的时候先分发 bdata 的元信息"></a>1. 分发 task 的时候先分发 bdata 的元信息</h4><p>Driver 先建一个本地文件夹用以存放需要 broadcast 的 data，并启动一个可以访问该文件夹的 HttpServer。当调用<code>val bdata = sc.broadcast(data)</code>时就把 data 写入文件夹，同时写入 driver 自己的 blockManger 中（StorageLevel 为内存＋磁盘），获得一个 blockId，类型为 BroadcastBlockId。当调用<code>rdd.transformation(func)</code>时，如果 func 用到了 bdata，那么 driver submitTask() 的时候会将 bdata 一同 func 进行序列化得到 serialized task，<strong>注意序列化的时候不会序列化 bdata 中包含的 data。</strong>上一章讲到 serialized task 从 driverActor 传递到 executor 时使用 Akka 的传消息机制，消息不能太大，而实际的 data 可能很大，所以这时候还不能 broadcast data。</p><blockquote><p>driver 为什么会同时将 data 放到磁盘和 blockManager 里面？放到磁盘是为了让 HttpServer 访问到，放到 blockManager 是为了让 driver program 自身使用 bdata 时方便（其实我觉得不放到 blockManger 里面也行）。</p></blockquote><p><strong>那么什么时候传送真正的 data？</strong>在 executor 反序列化 task 的时候，会同时反序列化 task 中的 bdata 对象，这时候会调用 bdata 的 readObject() 方法。该方法先去本地 blockManager 那里询问 bdata 的 data 在不在 blockManager 里面，如果不在就使用下面的两种 fetch 方式之一去将 data fetch 过来。得到 data 后，将其存放到 blockManager 里面，这样后面运行的 task 如果需要 bdata 就不需要再去 fetch data 了。如果在，就直接拿来用了。</p><p>下面探讨 broadcast data 时候的两种实现方式：</p><h4 id="2-HttpBroadcast"><a href="#2-HttpBroadcast" class="headerlink" title="2. HttpBroadcast"></a>2. HttpBroadcast</h4><p>顾名思义，HttpBroadcast 就是每个 executor 通过的 http 协议连接 driver 并从 driver 那里 fetch data。</p><p>Driver 先准备好要 broadcast 的 data，调用<code>sc.broadcast(data)</code>后会调用工厂方法建立一个 HttpBroadcast 对象。该对象做的第一件事就是将 data 存到 driver 的 blockManager 里面，StorageLevel 为内存＋磁盘，blockId 类型为 BroadcastBlockId。</p><p>同时 driver 也会将 broadcast 的 data 写到本地磁盘，例如写入后得到 <code>/var/folders/87/grpn1_fn4xq5wdqmxk31v0l00000gp/T/spark-6233b09c-3c72-4a4d-832b-6c0791d0eb9c/broadcast_0</code>， 这个文件夹作为 HttpServer 的文件目录。</p><blockquote><p>Driver 和 executor 启动的时候，都会生成 broadcastManager 对象，调用 HttpBroadcast.initialize()，driver 会在本地建立一个临时目录用来存放 broadcast 的 data，并启动可以访问该目录的 httpServer。</p></blockquote><p><strong>Fetch data：</strong>在 executor 反序列化 task 的时候，会同时反序列化 task 中的 bdata 对象，这时候会调用 bdata 的 readObject() 方法。该方法先去本地 blockManager 那里询问 bdata 的 data 在不在 blockManager 里面，<strong>如果不在就使用 http 协议连接 driver 上的 httpServer，将 data fetch 过来。</strong>得到 data 后，将其存放到 blockManager 里面，这样后面运行的 task 如果需要 bdata 就不需要再去 fetch data 了。如果在，就直接拿来用了。</p><p>HttpBroadcast 最大的问题就是 <strong>driver 所在的节点可能会出现网络拥堵</strong>，因为 worker 上的 executor 都会去 driver 那里 fetch 数据。</p><h4 id="3-TorrentBroadcast"><a href="#3-TorrentBroadcast" class="headerlink" title="3. TorrentBroadcast"></a>3. TorrentBroadcast</h4><p>为了解决 HttpBroadast 中 driver 单点网络瓶颈的问题，Spark 又设计了一种 broadcast 的方法称为 TorrentBroadcast，<strong>这个类似于大家常用的 BitTorrent 技术。</strong>基本思想就是将 data 分块成 data blocks，然后假设有 executor fetch 到了一些 data blocks，那么这个 executor 就可以被当作 data server 了，随着 fetch 的 executor 越来越多，有更多的 data server 加入，data 就很快能传播到全部的 executor 那里去了。</p><p>HttpBroadcast 是通过传统的 http 协议和 httpServer 去传 data，在 TorrentBroadcast 里面使用在上一章介绍的 blockManager.getRemote() =&gt; NIO ConnectionManager 传数据的方法来传递，读取数据的过程与读取 cached rdd 的方式类似，可以参阅 <a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md" target="_blank" rel="noopener">CacheAndCheckpoint</a> 中的最后一张图。</p><p>下面讨论 TorrentBroadcast 的一些细节：</p><p><a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/PNGfigures/TorrentBroadcast.png" target="_blank" rel="noopener"><img src="https://github.com/JerryLead/SparkInternals/raw/master/markdown/PNGfigures/TorrentBroadcast.png" alt="TorrentBroadcast"></a></p><h4 id="driver-端："><a href="#driver-端：" class="headerlink" title="driver 端："></a>driver 端：</h4><p>Driver 先把 data 序列化到 byteArray，然后切割成 BLOCK_SIZE（由 <code>spark.broadcast.blockSize = 4MB</code> 设置）大小的 data block，每个 data block 被 TorrentBlock 对象持有。切割完 byteArray 后，会将其回收，因此内存消耗虽然可以达到 2 * Size(data)，但这是暂时的。</p><p>完成分块切割后，就将分块信息（称为 meta 信息）存放到 driver 自己的 blockManager 里面，StorageLevel 为内存＋磁盘，同时会通知 driver 自己的 blockManagerMaster 说 meta 信息已经存放好。<strong>通知 blockManagerMaster 这一步很重要，因为 blockManagerMaster 可以被 driver 和所有 executor 访问到，信息被存放到 blockManagerMaster 就变成了全局信息。</strong></p><p>之后将每个分块 data block 存放到 driver 的 blockManager 里面，StorageLevel 为内存＋磁盘。存放后仍然通知 blockManagerMaster 说 blocks 已经存放好。到这一步，driver 的任务已经完成。</p><h4 id="Executor-端："><a href="#Executor-端：" class="headerlink" title="Executor 端："></a>Executor 端：</h4><p>executor 收到 serialized task 后，先反序列化 task，这时候会反序列化 serialized task 中包含的 bdata 类型是 TorrentBroadcast，也就是去调用 TorrentBroadcast.readObject()。这个方法首先得到 bdata 对象，<strong>然后发现 bdata 里面没有包含实际的 data。怎么办？</strong>先询问所在的 executor 里的 blockManager 是会否包含 data（通过查询 data 的 broadcastId），包含就直接从本地 blockManager 读取 data。否则，就通过本地 blockManager 去连接 driver 的 blockManagerMaster 获取 data 分块的 meta 信息，获取信息后，就开始了 BT 过程。</p><p><strong>BT 过程：</strong>task 先在本地开一个数组用于存放将要 fetch 过来的 data blocks <code>arrayOfBlocks = new Array[TorrentBlock](totalBlocks)</code>，TorrentBlock 是对 data block 的包装。然后打乱要 fetch 的 data blocks 的顺序，比如如果 data block 共有 5 个，那么打乱后的 fetch 顺序可能是 3-1-2-4-5。然后按照打乱后的顺序去 fetch 一个个 data block。fetch 的过程就是通过 “本地 blockManager －本地 connectionManager－driver/executor 的 connectionManager－driver/executor 的 blockManager－data” 得到 data，这个过程与 fetch cached rdd 类似。<strong>每 fetch 到一个 block 就将其存放到 executor 的 blockManager 里面，同时通知 driver 上的 blockManagerMaster 说该 data block 多了一个存储地址。</strong>这一步通知非常重要，意味着 blockManagerMaster 知道 data block 现在在 cluster 中有多份，下一个不同节点上的 task 再去 fetch 这个 data block 的时候，可以有两个选择了，而且会随机选择一个去 fetch。这个过程持续下去就是 BT 协议，随着下载的客户端越来越多，data block 服务器也越来越多，就变成 p2p下载了。关于 BT 协议，Wikipedia 上有一个<a href="http://zh.wikipedia.org/wiki/BitTorrent_(%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">动画</a>)。</p><p>整个 fetch 过程结束后，task 会开一个大 Array[Byte]，大小为 data 的总大小，然后将 data block 都 copy 到这个 Array，然后对 Array 中 bytes 进行反序列化得到原始的 data，这个过程就是 driver 序列化 data 的反过程。</p><p>最后将 data 存放到 task 所在 executor 的 blockManager 里面，StorageLevel 为内存＋磁盘。显然，这时候 data 在 blockManager 里存了两份，不过等全部 executor 都 fetch 结束，存储 data blocks 那份可以删掉了。</p><h3 id="问题：broadcast-RDD-会怎样"><a href="#问题：broadcast-RDD-会怎样" class="headerlink" title="问题：broadcast RDD 会怎样?"></a>问题：broadcast RDD 会怎样?</h3><p><a href="http://weibo.com/u/1410938285" target="_blank" rel="noopener">@Andrew-Xia</a> 回答道：不会怎样，就是这个rdd在每个executor中实例化一份。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>公共数据的 broadcast 是很实用的功能，在 Hadoop 中使用 DistributedCache，比如常用的<code>-libjars</code>就是使用 DistributedCache 来将 task 依赖的 jars 分发到每个 task 的工作目录。不过分发前 DistributedCache 要先将文件上传到 HDFS。这种方式的主要问题是<strong>资源浪费</strong>，如果某个节点上要运行来自同一 job 的 4 个 mapper，那么公共数据会在该节点上存在 4 份（每个 task 的工作目录会有一份）。但是通过 HDFS 进行 broadcast 的好处在于<strong>单点瓶颈不明显</strong>，因为公共 data 首先被分成多个 block，然后不同的 block 存放在不同的节点。这样，只要所有的 task 不是同时去同一个节点 fetch 同一个 block，网络拥塞不会很严重。</p><p>对于 Spark 来讲，broadcast 时考虑的不仅是如何将公共 data 分发下去的问题，还要考虑如何让同一节点上的 task 共享 data。</p><p>对于第一个问题，Spark 设计了两种 broadcast 的方式，传统存在单点瓶颈问题的 HttpBroadcast，和类似 BT 方式的 TorrentBroadcast。HttpBroadcast 使用传统的 client-server 形式的 HttpServer 来传递真正的 data，而 TorrentBroadcast 使用 blockManager 自带的 NIO 通信方式来传递 data。TorrentBroadcast 存在的问题是<strong>慢启动</strong>和<strong>占内存</strong>，慢启动指的是刚开始 data 只在 driver 上有，要等 executors fetch 很多轮 data block 后，data server 才会变得可观，后面的 fetch 速度才会变快。executor 所占内存的在 fetch 完 data blocks 后进行反序列化时需要将近两倍 data size 的内存消耗。不管哪一种方式，driver 在分块时会有两倍 data size 的内存消耗。</p><p>对于第二个问题，每个 executor 都包含一个 blockManager 用来管理存放在 executor 里的数据，将公共数据存放在 blockManager 中（StorageLevel 为内存＋磁盘），可以保证在 executor 执行的 tasks 能够共享 data。</p><p>其实 Spark 之前还尝试了一种称为 TreeBroadcast 的机制，详情可以见技术报告 <a href="http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf" target="_blank" rel="noopener">Performance and Scalability of Broadcast in Spark</a>。</p><p>更深入点，broadcast 可以用多播协议来做，不过多播使用 UDP，不是可靠的，仍然需要应用层的设计一些可靠性保障机制。</p><h2 id="什么是数据倾斜-怎样去处理数据倾斜"><a href="#什么是数据倾斜-怎样去处理数据倾斜" class="headerlink" title="什么是数据倾斜,怎样去处理数据倾斜"></a>什么是数据倾斜,怎样去处理数据倾斜</h2><p>数据倾斜是一种很常见的问题（依据二八定律），简单来说，比方WordCount中某个Key对应的数据量非常大的话，就会产生数据倾斜，导致两个后果：</p><ul><li>OOM（单或少数的节点）；</li><li>拖慢整个Job执行时间（其他已经完成的节点都在等这个还在做的节点）</li></ul><h4 id="数据倾斜主要分为两类-聚合倾斜-和-join倾斜"><a href="#数据倾斜主要分为两类-聚合倾斜-和-join倾斜" class="headerlink" title="数据倾斜主要分为两类: 聚合倾斜 和 join倾斜"></a>数据倾斜主要分为两类: 聚合倾斜 和 join倾斜</h4><ul><li><p><strong>聚合倾斜</strong></p><ul><li><p><strong>双重聚合（局部聚合+全局聚合）</strong></p><p><strong>场景</strong>: 对RDD进行reduceByKey等聚合类shuffle算子，SparkSQL的groupBy做分组聚合这两种情况<br> 思路：首先通过map给每个key打上n以内的随机数的前缀并进行局部聚合，即(hello, 1) (hello, 1) (hello, 1) (hello, 1)变为(1_hello, 1) (1_hello, 1) (2_hello, 1)，并进行reduceByKey的局部聚合，然后再次map将key的前缀随机数去掉再次进行全局聚合；<br> <strong>原理</strong>: 对原本相同的key进行随机数附加，变成不同key，让原本一个task处理的数据分摊到多个task做局部聚合，规避单task数据过量。之后再去随机前缀进行全局聚合；<br> 优点：效果非常好（对聚合类Shuffle操作的倾斜问题）；<br> 缺点：范围窄（仅适用于聚合类的Shuffle操作，join类的Shuffle还需其它方案）</p></li></ul></li><li><p><strong>join倾斜</strong></p><ul><li><p><strong>将reduce join转为map join</strong></p><p><strong>场景</strong>: 对RDD或Spark SQL使用join类操作或语句，且join操作的RDD或表比较小（百兆或1,2G）； 思路：使用broadcast和map类算子实现join的功能替代原本的join，彻底规避shuffle。对较小RDD直接collect到内存，并创建broadcast变量；并对另外一个RDD执行map类算子，在该算子的函数中，从broadcast变量（collect出的较小RDD）与当前RDD中的每条数据依次比对key，相同的key执行你需要方式的join；</p><p><strong>原理</strong>: 若RDD较小，可采用广播小的RDD，并对大的RDD进行map，来实现与join同样的效果。简而言之，用broadcast-map代替join，规避join带来的shuffle（无Shuffle无倾斜）； 优点：效果很好（对join操作导致的倾斜），根治； </p><p><strong>缺点</strong>：适用场景小（大表+小表），广播（driver和executor节点都会驻留小表数据）小表也耗内存</p></li><li><p><strong>采样倾斜key并分拆join操作</strong></p><p><strong>场景</strong>: 两个较大的（无法采用方案五）RDD/Hive表进行join时，且一个RDD/Hive表中少数key数据量过大，另一个RDD/Hive表的key分布较均匀（RDD中两者之一有一个更倾斜）；<br><strong>思路</strong>:</p><ol><li>对更倾斜rdd1进行采样（RDD.sample）并统计出数据量最大的几个key；</li><li>对这几个倾斜的key从原本rdd1中拆出形成一个单独的rdd1_1，并打上0~n的随机数前缀，被拆分的原rdd1的另一部分（不包含倾斜key）又形成一个新rdd1_2；</li><li>对rdd2过滤出rdd1倾斜的key，得到rdd2_1，并将其中每条数据扩n倍，对每条数据按顺序附加0~n的前缀，被拆分出key的rdd2也独立形成另一个rdd2_2； 【个人认为，这里扩了n倍，最后union完还需要将每个倾斜key对应的value减去(n-1)】</li><li>将加了随机前缀的rdd1_1和rdd2_1进行join（此时原本倾斜的key被打散n份并被分散到更多的task中进行join）； 【个人认为，这里应该做两次join，两次join中间有一个map去前缀】</li><li>另外两个普通的RDD（rdd1_2、rdd2_2）照常join；</li><li>最后将两次join的结果用union结合得到最终的join结果。 原理：对join导致的倾斜是因为某几个key，可将原本RDD中的倾斜key拆分出原RDD得到新RDD，并以加随机前缀的方式打散n份做join，将倾斜key对应的大量数据分摊到更多task上来规避倾斜；</li></ol><p><strong>优点</strong>: 前提是join导致的倾斜（某几个key倾斜），避免占用过多内存（只需对少数倾斜key扩容n倍）；<br><strong>缺点</strong>: 对过多倾斜key不适用。</p></li><li><p><strong>用随机前缀和扩容RDD进行join</strong></p><p><strong>场景</strong>: RDD中有大量key导致倾斜； 思路：与方案六类似。</p><ol><li>查看RDD/Hive表中数据分布并找到造成倾斜的RDD/表；</li><li>对倾斜RDD中的每条数据打上n以内的随机数前缀；</li><li>对另外一个正常RDD的每条数据扩容n倍，扩容出的每条数据依次打上0到n的前缀；</li><li>对处理后的两个RDD进行join。</li></ol><p><strong>原理</strong>: 与方案六只有唯一不同在于这里对不倾斜RDD中所有数据进行扩大n倍，而不是找出倾斜key进行扩容；<br><strong>优点</strong>: 对join类的数据倾斜都可处理，效果非常显著；<br><strong>缺点</strong>: 缓解，扩容需要大内存</p></li></ul></li></ul><p><a href="https://juejin.im/post/5ccd5cc7f265da03474e1249#heading-9" target="_blank" rel="noopener">参考文章1</a></p><p><a href="https://blog.csdn.net/qq_35394891/article/details/82260907" target="_blank" rel="noopener">参考文章2</a></p><h2 id="分析一下一段spark代码中哪些部分在Driver端执行-哪些部分在Worker端执行"><a href="#分析一下一段spark代码中哪些部分在Driver端执行-哪些部分在Worker端执行" class="headerlink" title="分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行"></a>分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行</h2><p>Driver Program是用户编写的提交给Spark集群执行的application，它包含两部分</p><ul><li><strong>作为驱动</strong>： Driver与Master、Worker协作完成application进程的启动、DAG划分、计算任务封装、计算任务分发到各个计算节点(Worker)、计算资源的分配等。</li><li><strong>计算逻辑本身</strong>，当计算任务在Worker执行时，执行计算逻辑完成application的计算任务</li></ul><p>一般来说transformation算子均是在worker上执行的,其他类型的代码在driver端执行</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;讲一下spark-的运行架构&quot;&gt;&lt;a href=&quot;#讲一下spark-的运行架构&quot; class=&quot;headerlink&quot; title=&quot;讲一下spark 的运行架构&quot;&gt;&lt;/a&gt;讲一下spark 的运行架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark架构图.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Cluster Manager(Master)&lt;/strong&gt;：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Worker节点&lt;/strong&gt;：从节点，负责控制计算节点，启动Executor或者Driver。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Driver&lt;/strong&gt;： 运行Application 的main()函数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Executor&lt;/strong&gt;：执行器，是为某个Application运行在worker node上的一个进程&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://icocos.github.io/categories/Spark/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Spark" scheme="https://icocos.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试之Hive</title>
    <link href="https://icocos.github.io/2020/03/02/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8BHive/"/>
    <id>https://icocos.github.io/2020/03/02/大数据面试之Hive/</id>
    <published>2020-03-02T10:56:46.000Z</published>
    <updated>2020-04-02T15:03:54.488Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hive-内部表和外部表的区别"><a href="#hive-内部表和外部表的区别" class="headerlink" title="hive 内部表和外部表的区别"></a>hive 内部表和外部表的区别</h2><ul><li>建表时带有external关键字为外部表，否则为内部表</li><li>内部表和外部表建表时都可以自己指定location</li><li>删除表时，外部表不会删除对应的数据，只会删除元数据信息，内部表则会删除</li><li>其他用法是一样的</li></ul><a id="more"></a><h2 id="hive四种排序方式的区别"><a href="#hive四种排序方式的区别" class="headerlink" title="hive四种排序方式的区别"></a>hive四种排序方式的区别</h2><ul><li><p><strong>order by</strong> </p><pre><code>order by 是要对输出的结果进行全局排序，这就意味着**只有一个reducer**才能实现（多个reducer无法保证全局有序）但是当数据量过大的时候，效率就很低。如果在严格模式下（hive.mapred.mode=strict）,则必须配合limit使用</code></pre></li><li><p><strong>sort by</strong></p><pre><code>sort by 不是全局排序，只是在进入到reducer之前完成排序，只保证了每个reducer中数据按照指定字段的有序性，是局部排序。配置mapred.reduce.tasks=[nums]可以对输出的数据执行归并排序。可以配合limit使用，提高性能</code></pre></li><li><p><strong>distribute by</strong> </p><pre><code>distribute by 指的是按照指定的字段划分到不同的输出reduce文件中，和sort by一起使用时需要注意，</code></pre><p>distribute by必须放在前面</p></li><li><p><strong>cluster by</strong></p><p>cluster by 可以看做是一个特殊的distribute by+sort by，它具备二者的功能，但是只能实现倒序排序的方式,不能指定排序规则为asc 或者desc</p></li></ul><p><a href="https://blog.csdn.net/high2011/article/details/78012317" target="_blank" rel="noopener">参考文章</a></p><h2 id="hive的metastore的三种模式"><a href="#hive的metastore的三种模式" class="headerlink" title="hive的metastore的三种模式"></a>hive的metastore的三种模式</h2><ul><li><p><strong>内嵌Derby方式</strong></p><p>这个是Hive默认的启动模式，一般用于单元测试，这种存储方式有一个缺点：在同一时间只能有一个进程连接使用数据库。</p></li><li><p><strong>Local方式</strong></p><p>本地MySQL</p></li><li><p><strong>Remote方式</strong></p><p>远程MySQL,一般常用此种方式</p></li></ul><p><a href="https://blog.csdn.net/baolibin528/article/details/46710025" target="_blank" rel="noopener">参考文章</a></p><h2 id="hive中join都有哪些"><a href="#hive中join都有哪些" class="headerlink" title="hive中join都有哪些"></a>hive中join都有哪些</h2><p>Hive中除了支持和传统数据库中一样的内关联（JOIN）、左关联（LEFT JOIN）、右关联（RIGHT JOIN）、全关联（FULL JOIN），还支持左半关联（LEFT SEMI JOIN）</p><ul><li><p><strong>内关联（JOIN）</strong></p><p>只返回能关联上的结果。</p></li><li><p><strong>左外关联（LEFT [OUTER] JOIN）</strong></p><p>以LEFT [OUTER] JOIN关键字前面的表作为主表，和其他表进行关联，返回记录和主表的记录数一致，关联不上的字段置为NULL。</p></li><li><p><strong>右外关联（RIGHT [OUTER] JOIN）</strong></p><p>和左外关联相反，以RIGTH [OUTER] JOIN关键词后面的表作为主表，和前面的表做关联，返回记录数和主表一致，关联不上的字段为NULL。</p></li><li><p><strong>全外关联（FULL [OUTER] JOIN）</strong></p><p>以两个表的记录为基准，返回两个表的记录去重之和，关联不上的字段为NULL。</p></li><li><p><strong>LEFT SEMI JOIN</strong></p><p>以LEFT SEMI JOIN关键字前面的表为主表，返回主表的KEY也在副表中的记录</p></li><li><p><strong>笛卡尔积关联（CROSS JOIN）</strong></p><p>返回两个表的笛卡尔积结果，不需要指定关联键。</p></li></ul><p><a href="http://lxw1234.com/archives/2015/06/315.htm" target="_blank" rel="noopener">参考文章</a></p><h2 id="Impala-和-hive-的查询有哪些区别"><a href="#Impala-和-hive-的查询有哪些区别" class="headerlink" title="Impala 和 hive 的查询有哪些区别"></a>Impala 和 hive 的查询有哪些区别</h2><p><strong>Impala是基于Hive的大数据实时分析查询引擎</strong>，直接使用Hive的元数据库Metadata,意味着impala元数据都存储在Hive的metastore中。并且impala兼容Hive的sql解析，实现了Hive的SQL语义的子集，功能还在不断的完善中。</p><h4 id="Impala相对于Hive所使用的优化技术"><a href="#Impala相对于Hive所使用的优化技术" class="headerlink" title="Impala相对于Hive所使用的优化技术"></a>Impala相对于Hive所使用的优化技术</h4><ul><li>1、没有使用 MapReduce进行并行计算，虽然MapReduce是非常好的并行计算框架，但它更多的面向批处理模式，而不是面向交互式的SQL执行。与 MapReduce相比：Impala把整个查询分成一执行计划树，而不是一连串的MapReduce任务，在分发执行计划后，Impala使用拉式获取 数据的方式获取结果，把结果数据组成按执行树流式传递汇集，减少的了把中间结果写入磁盘的步骤，再从磁盘读取数据的开销。Impala使用服务的方式避免 每次执行查询都需要启动的开销，即相比Hive没了MapReduce启动时间。</li><li>2、使用LLVM产生运行代码，针对特定查询生成特定代码，同时使用Inline的方式减少函数调用的开销，加快执行效率。</li><li>3、充分利用可用的硬件指令（SSE4.2）。</li><li>4、更好的IO调度，Impala知道数据块所在的磁盘位置能够更好的利用多磁盘的优势，同时Impala支持直接数据块读取和本地代码计算checksum。</li><li>5、通过选择合适的数据存储格式可以得到最好的性能（Impala支持多种存储格式）。</li><li>6、最大使用内存，中间结果不写磁盘，及时通过网络以stream的方式传递。</li></ul><p><a href="https://cloud.tencent.com/developer/article/1175527" target="_blank" rel="noopener">参考文章</a></p><h2 id="Hive中大表join小表的优化方法"><a href="#Hive中大表join小表的优化方法" class="headerlink" title="Hive中大表join小表的优化方法"></a>Hive中大表join小表的优化方法</h2><p>在小表和大表进行join时，将<strong>小表放在前边</strong>，效率会高，hive会将小表进行缓存</p><h2 id="Hive-Sql-是怎样解析成MR-job的"><a href="#Hive-Sql-是怎样解析成MR-job的" class="headerlink" title="Hive Sql 是怎样解析成MR job的?"></a>Hive Sql 是怎样解析成MR job的?</h2><p><strong>主要分为6个阶段:</strong></p><ol><li><p><strong>Hive使用Antlr实现语法解析</strong>.根据Antlr制定的SQL语法解析规则,完成SQL语句的词法/语法解析,将SQL转为抽象语法树AST.</p></li><li><p><strong>遍历AST,生成基本查询单元QueryBlock</strong>.QueryBlock是一条SQL最基本的组成单元，包括三个部分：输入源，计算过程，输出.</p></li><li><strong>遍历QueryBlock,生成OperatorTree</strong>.Hive最终生成的MapReduce任务，Map阶段和Reduce阶段均由OperatorTree组成。Operator就是在Map阶段或者Reduce阶段完成单一特定的操作。QueryBlock生成Operator Tree就是遍历上一个过程中生成的QB和QBParseInfo对象的保存语法的属性.</li><li><strong>优化OperatorTree.</strong>大部分逻辑层优化器通过变换OperatorTree，合并操作符，达到减少MapReduce Job，减少shuffle数据量的目的</li><li><p><strong>OperatorTree生成MapReduce Job</strong>.遍历OperatorTree,翻译成MR任务.</p><ul><li>对输出表生成MoveTask</li><li>从OperatorTree的其中一个根节点向下深度优先遍历</li><li>ReduceSinkOperator标示Map/Reduce的界限，多个Job间的界限</li><li>遍历其他根节点，遇过碰到JoinOperator合并MapReduceTask</li><li>生成StatTask更新元数据</li><li>剪断Map与Reduce间的Operator的关系</li></ul></li><li><p><strong>优化任务.</strong> 使用物理优化器对MR任务进行优化,生成最终执行任务</p></li></ol><p><a href="https://www.cnblogs.com/Dhouse/p/7132476.html" target="_blank" rel="noopener">参考文章</a></p><h2 id="Hive-UDF简单介绍"><a href="#Hive-UDF简单介绍" class="headerlink" title="Hive UDF简单介绍"></a>Hive UDF简单介绍</h2><p>在Hive中，用户可以自定义一些函数，用于扩展HiveQL的功能，而这类函数叫做UDF（用户自定义函数）。UDF分为两大类：UDAF（用户自定义聚合函数）和UDTF（用户自定义表生成函数）。</p><p><strong>Hive有两个不同的接口编写UDF程序。一个是基础的UDF接口，一个是复杂的GenericUDF接口。</strong></p><ol><li>org.apache.hadoop.hive.ql. exec.UDF 基础UDF的函数读取和返回基本类型，即Hadoop和Hive的基本类型。如，Text、IntWritable、LongWritable、DoubleWritable等。</li><li>org.apache.hadoop.hive.ql.udf.generic.GenericUDF 复杂的GenericUDF可以处理Map、List、Set类型。</li></ol><p><a href="http://www.voidcn.com/article/p-suceexsl-vb.html" target="_blank" rel="noopener">参考文章</a></p><h2 id="Hive-SQL-按照学生科目取每个科目的TopN"><a href="#Hive-SQL-按照学生科目取每个科目的TopN" class="headerlink" title="Hive SQL : 按照学生科目取每个科目的TopN"></a>Hive SQL : 按照学生科目取每个科目的TopN</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">id,name,subject,score</span><br><span class="line">1,小明,语文,87</span><br><span class="line">2,张三,语文,27</span><br><span class="line">3,王五,语文,69</span><br><span class="line">4,李四,语文,99</span><br><span class="line">5,小明,数学,86</span><br><span class="line">6,马六,数学,33</span><br><span class="line">7,李四,数学,44</span><br><span class="line">8,小红,数学,50</span><br></pre></td></tr></table></figure><p><strong>按照各个科目的成绩排名 取 Top3</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select a.* from</span><br><span class="line">(select id,name,subject,score,row_number() over(partition by subject order by score desc) rank from student) a</span><br><span class="line">where a.rank &lt;= 3</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/WYpersist/article/details/80318305" target="_blank" rel="noopener">参考文章</a></p><h2 id="Hive-SQL-获取每个用户的前1-4次的数据"><a href="#Hive-SQL-获取每个用户的前1-4次的数据" class="headerlink" title="Hive SQL: 获取每个用户的前1/4次的数据"></a>Hive SQL: 获取每个用户的前1/4次的数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cookieId  createTime    pv</span><br><span class="line">--------------------------</span><br><span class="line">cookie1 2015-04-10      1</span><br><span class="line">cookie1 2015-04-11      5</span><br><span class="line">cookie1 2015-04-12      7</span><br><span class="line">cookie1 2015-04-13      3</span><br><span class="line">cookie1 2015-04-14      2</span><br><span class="line">cookie1 2015-04-15      4</span><br><span class="line">cookie1 2015-04-16      4</span><br><span class="line">cookie2 2015-04-10      2</span><br><span class="line">cookie2 2015-04-11      3</span><br><span class="line">cookie2 2015-04-12      5</span><br><span class="line">cookie2 2015-04-13      6</span><br><span class="line">cookie2 2015-04-14      3</span><br><span class="line">cookie2 2015-04-15      9</span><br><span class="line">cookie2 2015-04-16      7</span><br></pre></td></tr></table></figure><p>获取每个用户前1/4次的访问记录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT a.* from </span><br><span class="line">(SELECT cookieid,createtime,pv,NTILE(4)</span><br><span class="line">OVER(PARTITION BY cookieId ORDER BY createtime) AS rn</span><br><span class="line">from table ) a</span><br><span class="line">WHERE a.rn = 1</span><br></pre></td></tr></table></figure><p>NTILE(n)，用于将分组数据按照顺序切分成n片，返回当前切片值</p><p><a href="http://lxw1234.com/archives/2015/04/181.htm" target="_blank" rel="noopener">参考文章</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;hive-内部表和外部表的区别&quot;&gt;&lt;a href=&quot;#hive-内部表和外部表的区别&quot; class=&quot;headerlink&quot; title=&quot;hive 内部表和外部表的区别&quot;&gt;&lt;/a&gt;hive 内部表和外部表的区别&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;建表时带有external关键字为外部表，否则为内部表&lt;/li&gt;
&lt;li&gt;内部表和外部表建表时都可以自己指定location&lt;/li&gt;
&lt;li&gt;删除表时，外部表不会删除对应的数据，只会删除元数据信息，内部表则会删除&lt;/li&gt;
&lt;li&gt;其他用法是一样的&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://icocos.github.io/categories/Hive/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Hive" scheme="https://icocos.github.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试之Hadoop</title>
    <link href="https://icocos.github.io/2020/03/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E4%B9%8BHadoop/"/>
    <id>https://icocos.github.io/2020/03/01/大数据面试之Hadoop/</id>
    <published>2020-03-01T10:56:46.000Z</published>
    <updated>2020-04-02T15:04:09.712Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h2><h3 id="1-HDFS-1-0-架构"><a href="#1-HDFS-1-0-架构" class="headerlink" title="1. HDFS 1.0 架构"></a>1. HDFS 1.0 架构</h3><p>HDFS 采用的是 Master/Slave 架构，一个 HDFS 集群包含一个单独的 NameNode 和多个 DataNode 节点</p><a id="more"></a><h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><p>NameNode 负责管理整个分布式系统的元数据，主要包括：</p><ul><li>目录树结构；</li><li>文件到数据库 Block 的映射关系；</li></ul><ul><li>Block 副本及其存储位置等管理数据；</li><li>DataNode 的状态监控，两者通过段时间间隔的心跳来传递管理信息和数据信息，通过这种方式的信息传递，NameNode 可以获知每个 DataNode 保存的 Block 信息、DataNode 的健康状况、命令 DataNode 启动停止等（如果发现某个 DataNode 节点故障，NameNode 会将其负责的 block 在其他 DataNode 上进行备份）。</li></ul><p>这些数据保存在内存中，同时在磁盘保存两个元数据管理文件：fsimage 和 editlog。</p><ul><li>fsimage：是内存命名空间元数据在外存的镜像文件；</li><li>editlog：则是各种元数据操作的 write-ahead-log 文件，在体现到内存数据变化前首先会将操作记入 editlog 中，以防止数据丢失。</li></ul><p>这两个文件相结合可以构造完整的内存数据。</p><h4 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h4><p>Secondary NameNode 并不是 NameNode 的热备机，而是定期从 NameNode 拉取 fsimage 和 editlog 文件，并对两个文件进行合并，形成新的 fsimage 文件并传回 NameNode，这样做的目的是减轻 NameNod 的工作压力，本质上 SNN 是一个提供检查点功能服务的服务点。</p><h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><p>负责数据块的实际存储和读写工作，Block 默认是64MB（HDFS2.0改成了128MB），当客户端上传一个大文件时，HDFS 会自动将其切割成固定大小的 Block，为了保证数据可用性，每个 Block 会以多备份的形式存储，默认是3份。</p><hr><h3 id="2-HDFS-2-0-的-HA-实现"><a href="#2-HDFS-2-0-的-HA-实现" class="headerlink" title="2. HDFS 2.0 的 HA 实现"></a>2. HDFS 2.0 的 HA 实现</h3><p><img src="D:\Note\big-data-interview\BigData-Interview\pictures\hdfs-ha.png" alt="2.0架构图"></p><ul><li><p><strong>Active NameNode 和 Standby NameNode</strong>：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务；</p></li><li><p><strong>ZKFailoverController</strong>（主备切换控制器，FC）：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换（当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换）；</p></li><li><p><strong>Zookeeper 集群</strong>：为主备切换控制器提供主备选举支持；</p></li><li><p><strong>共享存储系统</strong>：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在<strong>确认元数据完全同步之后才能继续对外提供服务</strong>。</p></li><li><p><strong>DataNode 节点</strong>：因为主 NameNode 和备 NameNode 需要共享 HDFS 的数据块和 DataNode 之间的映射关系，为了使故障切换能够快速进行，DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</p></li></ul><p><a href="http://matt33.com/2018/07/15/hdfs-architecture-learn/#HDFS-2-0-%E7%9A%84-HA-%E5%AE%9E%E7%8E%B0" target="_blank" rel="noopener">-&gt;参考文章链接</a></p><h2 id="Yarn架构"><a href="#Yarn架构" class="headerlink" title="Yarn架构"></a>Yarn架构</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/yarn.gif" alt=""></p><h3 id="1-ResourceManager（RM）"><a href="#1-ResourceManager（RM）" class="headerlink" title="1. ResourceManager（RM）"></a>1. ResourceManager（RM）</h3><p>RM 是一个全局的资源管理器，负责整个系统的资源管理和分配，它主要有两个组件构成：</p><ol><li>调度器：Scheduler；</li><li>应用程序管理器：Applications Manager，ASM。</li></ol><h4 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h4><p>调度器根据容量、队列等限制条件（如某个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。要注意的是，该调度器是一个纯调度器，它不再从事任何与应用程序有关的工作，比如不负责重新启动（因应用程序失败或者硬件故障导致的失败），这些均交由应用程序相关的 ApplicationMaster 完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念 <strong>资源容器(Resource Container，也即 Container)</strong>，Container 是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 提供了多种直接可用的调度器，比如 Fair Scheduler 和 Capacity Schedule 等。</p><h4 id="应用程序管理器"><a href="#应用程序管理器" class="headerlink" title="应用程序管理器"></a>应用程序管理器</h4><p>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以 AM、监控 AM 运行状态并在失败时重新启动它等。</p><h3 id="2-NodeManager（NM）"><a href="#2-NodeManager（NM）" class="headerlink" title="2. NodeManager（NM）"></a>2. NodeManager（NM）</h3><p>NM 是每个节点上运行的资源和任务管理器，一方面，它会定时向 RM 汇报本节点上的资源使用情况和各个 Container 的运行状态；另一方面，它接收并处理来自 AM 的 Container 启动/停止等各种请求。</p><h3 id="3-ApplicationMaster（AM）"><a href="#3-ApplicationMaster（AM）" class="headerlink" title="3. ApplicationMaster（AM）"></a>3. ApplicationMaster（AM）</h3><p>提交的每个作业都会包含一个 AM，主要功能包括：</p><ol><li>与 RM 协商以获取资源（用 container 表示）；</li><li>将得到的任务进一步分配给内部的任务；</li><li>与 NM 通信以启动/停止任务；</li><li>监控所有任务的运行状态，当任务有失败时，重新为任务申请资源并重启任务。</li></ol><p>MapReduce 就是原生支持 ON YARN 的一种框架，可以在 YARN 上运行 MapReduce 作业。有很多分布式应用都开发了对应的应用程序框架，用于在 YARN 上运行任务，例如 Spark，Storm、Flink 等。</p><h3 id="4-Container"><a href="#4-Container" class="headerlink" title="4. Container"></a>4. Container</h3><p>Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当 AM 向 RM 申请资源时，RM 为 AM 返回的资源便是用 Container 表示的。 YARN 会为每个任务分配一个 Container 且该任务只能使用该 Container 中描述的资源。</p><h2 id="MapReduce过程"><a href="#MapReduce过程" class="headerlink" title="MapReduce过程"></a>MapReduce过程</h2><p>MapReduce分为两个阶段: <strong>Map</strong> 和  <strong>Ruduce</strong>.</p><p><strong>Map阶段:</strong></p><ol><li><strong>input</strong>. 在进行map计算之前，mapreduce会根据输入文件计算输入分片（input split），每个输入分片（input split）针对一个map任务</li><li><strong>map</strong>. 就是程序员编写好的map函数了，因此map函数效率相对好控制，而且一般map操作都是本地化操作也就是在数据存储节点上进行</li><li><strong>Partition</strong>. 需要计算每一个map的结果需要发到哪个reduce端,partition数等于reducer数.默认采用HashPartition.</li><li><p><strong>spill</strong>.此阶段分为sort和combine.首先分区过得数据会经过排序之后写入环形内存缓冲区.在达到阈值之后守护线程将数据溢出分区文件.</p><ul><li><strong>sort</strong>. 在写入环形缓冲区前,对数据排序.&lt;key,value,partition&gt;格式排序</li><li><strong>combine</strong>(可选). 在溢出文件之前,提前开始combine,相当于本地化的reduce操作</li></ul></li><li><p><strong>merge.</strong> spill结果会有很多个文件,但最终输出只有一个,故有一个merge操作会合并所有的本地文件,并且该文件会有一个对应的索引文件.</p></li></ol><p><strong>Reduce阶段:</strong></p><ol><li><strong>copy</strong>. 拉取数据,reduce启动数据copy线程(默认5个),通过Http请求对应节点的map task输出文件,copy的数据也会先放到内部缓冲区.之后再溢写,类似map端操作.</li><li><strong>merge</strong>. 合并多个copy的多个map端的数据.在一个reduce端先将多个map端的数据溢写到本地磁盘,之后再将多个文件合并成一个文件.  数据经过 <strong>内存-&gt;磁盘 , 磁盘-&gt;磁盘</strong>的过程.</li><li><strong>output</strong>.merge阶段最后会生成一个文件,将此文件转移到内存中,shuffle阶段结束</li><li><strong>reduce</strong>. 开始执行reduce任务,最后结果保留在hdfs上.</li></ol><h2 id="Yarn-调度MapReduce过程"><a href="#Yarn-调度MapReduce过程" class="headerlink" title="Yarn 调度MapReduce过程"></a>Yarn 调度MapReduce过程</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/picturees/yarn调度mr过程.jpg" alt=""></p><ol><li>Mr程序提交到客户端所在的节点（MapReduce）</li><li>yarnrunner向Resourcemanager申请一个application。</li><li>rm将该应用程序的资源路径返回给yarnrunner</li><li>该程序将运行所需资源提交到HDFS上</li><li>程序资源提交完毕后，申请运行mrAppMaster</li><li>RM将用户的请求初始化成一个task</li><li>其中一个NodeManager领取到task任务。</li><li>该NodeManager创建容器Container，并产生MRAppmaster</li><li>Container从HDFS上拷贝资源到本地</li><li>MRAppmaster向RM申请运行maptask容器</li><li>RM将运行maptask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器.</li><li>MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动maptask，maptask对数据分区排序。</li><li>MRAppmaster向RM申请2个容器，运行reduce task。</li><li>reduce task向maptask获取相应分区的数据。</li><li>程序运行完毕后，MR会向RM注销自己。</li></ol><p><a href="https://blog.csdn.net/qq_26442553/article/details/78699759" target="_blank" rel="noopener">参考文章</a></p><h2 id="hdfs写流程"><a href="#hdfs写流程" class="headerlink" title="hdfs写流程"></a>hdfs写流程</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hdfs写流程.png" alt=""></p><ol><li>Client 调用 DistributedFileSystem 对象的 <code>create</code> 方法，创建一个文件输出流（FSDataOutputStream）对象；</li><li>通过 DistributedFileSystem 对象与集群的 NameNode 进行一次 RPC 远程调用，在 HDFS 的 Namespace 中创建一个文件条目（Entry），此时该条目没有任何的 Block，NameNode 会返回该数据每个块需要拷贝的 DataNode 地址信息；</li><li>通过 FSDataOutputStream 对象，开始向 DataNode 写入数据，数据首先被写入 FSDataOutputStream 对象内部的数据队列中，数据队列由 DataStreamer 使用，它通过选择合适的 DataNode 列表来存储副本，从而要求 NameNode 分配新的 block；</li><li>DataStreamer 将数据包以流式传输的方式传输到分配的第一个 DataNode 中，该数据流将数据包存储到第一个 DataNode 中并将其转发到第二个 DataNode 中，接着第二个 DataNode 节点会将数据包转发到第三个 DataNode 节点；</li><li>DataNode 确认数据传输完成，最后由第一个 DataNode 通知 client 数据写入成功；</li><li>完成向文件写入数据，Client 在文件输出流（FSDataOutputStream）对象上调用 <code>close</code> 方法，完成文件写入；</li><li>调用 DistributedFileSystem 对象的 complete 方法，通知 NameNode 文件写入成功，NameNode 会将相关结果记录到 editlog 中。</li></ol><h2 id="hdfs读流程"><a href="#hdfs读流程" class="headerlink" title="hdfs读流程"></a>hdfs读流程</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hdfs读流程.png" alt=""></p><ol><li>Client 通过 DistributedFileSystem 对象与集群的 NameNode 进行一次 RPC 远程调用，获取文件 block 位置信息；</li><li>NameNode 返回存储的每个块的 DataNode 列表；</li><li>Client 将连接到列表中最近的 DataNode；</li><li>Client 开始从 DataNode 并行读取数据；</li><li>一旦 Client 获得了所有必须的 block，它就会将这些 block 组合起来形成一个文件。</li></ol><h2 id="hdfs创建一个文件的流程"><a href="#hdfs创建一个文件的流程" class="headerlink" title="hdfs创建一个文件的流程"></a>hdfs创建一个文件的流程</h2><ol><li>客户端通过ClientProtocol协议向RpcServer发起创建文件的RPC请求。</li><li>FSNamesystem封装了各种HDFS操作的实现细节，RpcServer调用FSNamesystem中的相关方法以创建目录。</li><li>进一步的，FSDirectory封装了各种目录树操作的实现细节，FSNamesystem调用FSDirectory中的相关方法在目录树中创建目标文件，并通过日志系统备份文件系统的修改。</li><li>最后，RpcServer将RPC响应返回给客户端。</li></ol><p><a href="https://monkeysayhi.github.io/2018/02/07/%E6%BA%90%E7%A0%81%7CHDFS%E4%B9%8BNameNode%EF%BC%9A%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%EF%BC%881%EF%BC%89/" target="_blank" rel="noopener">参考文章</a></p><h2 id="hadoop1-x-和hadoop-2-x-的区别"><a href="#hadoop1-x-和hadoop-2-x-的区别" class="headerlink" title="hadoop1.x 和hadoop 2.x 的区别"></a>hadoop1.x 和hadoop 2.x 的区别</h2><ol><li><p><strong>资源调度方式的改变</strong></p><p>在1.x, 使用Jobtracker负责任务调度和资源管理,单点负担过重,在2.x中,新增了yarn作为集群的调度工具.在yarn中,使用ResourceManager进行 资源管理, 单独开启一个Container作为ApplicationMaster来进行任务管理.</p></li><li><p><strong>HA模式</strong></p><p>在1.x中没有HA模式,集群中只有一个NameNode,而在2.x中可以启用HA模式,存在一个Active NameNode 和Standby NameNode.</p></li><li><p><strong>HDFS Federation</strong></p><p>Hadoop 2.0中对HDFS进行了改进，使NameNode可以横向扩展成多个，每个NameNode分管一部分目录，进而产生了HDFS Federation，该机制的引入不仅增强了HDFS的扩展性，也使HDFS具备了隔离性</p></li></ol><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hadoop1.jpg" alt=""></p><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hadoop2.jpg" alt=""></p><h2 id="hadoop1-x的缺点"><a href="#hadoop1-x的缺点" class="headerlink" title="hadoop1.x的缺点"></a>hadoop1.x的缺点</h2><ol><li>JobTracker存在单点故障的隐患</li><li>任务调度和资源管理全部是JobTracker来完成,单点负担过重</li><li>TaskTracker以Map/Reduce数量表示资源太过简单</li><li>TaskTracker 分Map Slot 和 Reduce Slot, 如果任务只需要map任务可能会造成资源浪费</li></ol><h2 id="hadoop-HA介绍"><a href="#hadoop-HA介绍" class="headerlink" title="hadoop HA介绍"></a>hadoop HA介绍</h2><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hdfs-ha.png" alt=""></p><ol><li><strong>Active NameNode 和 Standby NameNode</strong>：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务；</li><li><strong>ZKFailoverController（主备切换控制器，FC）</strong>：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换（当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换）；</li><li><strong>Zookeeper 集群</strong>：为主备切换控制器提供主备选举支持；</li><li><strong>共享存储系统</strong>：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和备 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在<strong>确认元数据完全同步之后才能继续对外提供服务</strong>。</li><li><strong>DataNode 节点</strong>：因为主 NameNode 和备 NameNode 需要共享 HDFS 的数据块和 DataNode 之间的映射关系，为了使故障切换能够快速进行，DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</li></ol><h2 id="hadoop的常用配置文件有哪些"><a href="#hadoop的常用配置文件有哪些" class="headerlink" title="hadoop的常用配置文件有哪些"></a>hadoop的常用配置文件有哪些</h2><ul><li><p><strong>hadoop-env.sh</strong>: 用于定义hadoop运行环境相关的配置信息，比如配置JAVA_HOME环境变量、为hadoop的JVM指定特定的选项、指定日志文件所在的目录路径以及master和slave文件的位置等；</p></li><li><p><strong>core-site.xml</strong>: 用于定义系统级别的参数，如HDFS URL、Hadoop的临时目录以及用于rack-aware集群中的配置文件的配置等，此中的参数定义会覆盖core-default.xml文件中的默认配置；</p></li><li><p><strong>hdfs-site.xml</strong>: HDFS的相关设定，如文件副本的个数、块大小及是否使用强制权限等，此中的参数定义会覆盖hdfs-default.xml文件中的默认配置；</p></li><li><p><strong>mapred-site.xml</strong>：HDFS的相关设定，如reduce任务的默认个数、任务所能够使用内存的默认上下限等，此中的参数定义会覆盖mapred-default.xml文件中的默认配置；</p></li></ul><h2 id="小文件过多会有什么危害-如何避免"><a href="#小文件过多会有什么危害-如何避免" class="headerlink" title="小文件过多会有什么危害,如何避免?"></a>小文件过多会有什么危害,如何避免?</h2><p>Hadoop上大量HDFS元数据信息存储在NameNode内存中,因此过多的小文件必定会压垮NameNode的内存.</p><p>每个元数据对象约占150byte，所以如果有1千万个小文件，每个文件占用一个block，则NameNode大约需要2G空间。如果存储1亿个文件，则NameNode需要20G空间.</p><p>显而易见的解决这个问题的方法就是合并小文件,可以选择在客户端上传时执行一定的策略先合并,或者是使用Hadoop的CombineFileInputFormat&lt;K,V&gt;实现小文件的合并</p><p><a href="https://blog.csdn.net/luofazha2012/article/details/80904791" target="_blank" rel="noopener">参考文章</a></p><h2 id="启动hadoop集群会分别启动哪些进程-各自的作用"><a href="#启动hadoop集群会分别启动哪些进程-各自的作用" class="headerlink" title="启动hadoop集群会分别启动哪些进程,各自的作用"></a>启动hadoop集群会分别启动哪些进程,各自的作用</h2><ul><li><p><strong>NameNode：</strong></p><ul><li>维护文件系统树及整棵树内所有的文件和目录。这些信息永久保存在本地磁盘的两个文件中：命名空间镜像文件、编辑日志文件</li><li>记录每个文件中各个块所在的数据节点信息，这些信息在内存中保存，每次启动系统时重建这些信息</li><li>负责响应客户端的   数据块位置请求  。也就是客户端想存数据，应该往哪些节点的哪些块存；客户端想取数据，应该到哪些节点取</li><li>接受记录在数据存取过程中，datanode节点报告过来的故障、损坏信息</li></ul></li><li><p><strong>SecondaryNameNode(非HA模式)：</strong></p><ul><li>实现namenode容错的一种机制。定期合并编辑日志与命名空间镜像，当namenode挂掉时，可通过一定步骤进行上顶。(<strong>注意 并不是NameNode的备用节点</strong>)</li></ul></li><li><strong>DataNode：</strong><ul><li>根据需要存取并检索数据块</li><li>定期向namenode发送其存储的数据块列表</li></ul></li><li><strong>ResourceManager：</strong><ul><li>负责Job的调度,将一个任务与一个NodeManager相匹配。也就是将一个MapReduce之类的任务分配给一个从节点的NodeManager来执行。</li></ul></li><li><p><strong>NodeManager：</strong></p><ul><li>运行ResourceManager分配的任务，同时将任务进度向application master报告</li></ul></li><li><p><strong>JournalNode(HA下启用):</strong></p><ul><li>高可用情况下存放namenode的editlog文件</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;HDFS架构&quot;&gt;&lt;a href=&quot;#HDFS架构&quot; class=&quot;headerlink&quot; title=&quot;HDFS架构&quot;&gt;&lt;/a&gt;HDFS架构&lt;/h2&gt;&lt;h3 id=&quot;1-HDFS-1-0-架构&quot;&gt;&lt;a href=&quot;#1-HDFS-1-0-架构&quot; class=&quot;headerlink&quot; title=&quot;1. HDFS 1.0 架构&quot;&gt;&lt;/a&gt;1. HDFS 1.0 架构&lt;/h3&gt;&lt;p&gt;HDFS 采用的是 Master/Slave 架构，一个 HDFS 集群包含一个单独的 NameNode 和多个 DataNode 节点&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://icocos.github.io/categories/Hadoop/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Hadoop" scheme="https://icocos.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>大数据面试题全套汇总+答案</title>
    <link href="https://icocos.github.io/2020/02/29/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E9%A2%98%E5%85%A8%E5%A5%97%E6%B1%87%E6%80%BB+%E7%AD%94%E6%A1%88/"/>
    <id>https://icocos.github.io/2020/02/29/大数据面试题全套汇总+答案/</id>
    <published>2020-02-29T10:56:46.000Z</published>
    <updated>2020-04-02T15:14:30.585Z</updated>
    
    <content type="html"><![CDATA[<h4 id="大数据面试题全套汇总-答案"><a href="#大数据面试题全套汇总-答案" class="headerlink" title="大数据面试题全套汇总+答案"></a>大数据面试题全套汇总+答案</h4><hr><table><br>    <tr><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hadoop.jpg"></th><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hive.jpg"></th><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark.jpg"></th><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink.png"></th><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hbase.png"></th><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/kafka.png"></th><br>     <th><img width="50px" src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/zookeeper.jpg"></th><br>    </tr><br><tr><br>  <td align="center"><a href="#一hadoop">Hadoop</a></td><br>  <td align="center"><a href="#二hive">Hive</a></td><br>  <td align="center"><a href="#三spark">Spark</a></td><br>  <td align="center"><a href="#四flink">Flink</a></td><br>  <td align="center"><a href="#五hbase">HBase</a></td><br>  <td align="center"><a href="#六kafka">Kafka</a></td><br>  <td align="center"><a href="#七zookeeper">Zookeeper</a></td><br></tr><br>    </table><a id="more"></a><h2 id="一、Hadoop"><a href="#一、Hadoop" class="headerlink" title="一、Hadoop"></a>一、Hadoop</h2><ol><li>HDFS架构 </li><li>Yarn架构 </li><li>MapReduce过程 </li><li>Yarn 调度MapReduce </li><li>hdfs写流程 </li><li>hdfs读流程</li><li>hdfs创建一个文件的流程 </li><li>hadoop1.x 和hadoop 2.x 的区别 </li><li>hadoop1.x的缺点 </li><li>hadoop HA介绍 </li><li>hadoop的常用配置文件有哪些,自己实际改过哪些? </li><li>小文件过多会有什么危害,如何避免? </li><li>启动hadoop集群会分别启动哪些进程,各自的作用 </li></ol><h2 id="二、Hive"><a href="#二、Hive" class="headerlink" title="二、Hive"></a>二、Hive</h2><ol><li>hive 内部表和外部表的区别</li><li>hive中 sort by / order by / cluster by / distribute by 的区别</li><li>hive的metastore的三种模式</li><li>hive 中 join都有哪些</li><li>Impala 和 hive 的查询有哪些区别 </li><li>Hive中大表join小表的优化方法 </li><li>Hive Sql 是怎样解析成MR job的? </li><li>Hive UDF简单介绍 </li><li>SQL题: 按照学生科目分组, 取每个科目的TopN </li><li>SQL题: 获取每个用户的前1/4次的数据 </li></ol><h2 id="三、Spark"><a href="#三、Spark" class="headerlink" title="三、Spark"></a>三、Spark</h2><ol><li>讲一下spark 的运行架构 </li><li>一个spark程序的执行流程 </li><li>spark的shuffle介绍 </li><li>Spark的 partitioner 都有哪些? </li><li>spark 有哪几种join </li><li>RDD有哪些特点 </li><li>讲一下宽依赖和窄依赖 </li><li>Spark中的算子都有哪些 </li><li>RDD的缓存级别都有哪些 </li><li>RDD 懒加载是什么意思 </li><li>讲一下spark的几种部署方式 </li><li>spark on yarn 模式下的 cluster模式和 client模式有什么区别 </li><li>spark运行原理,从提交一个jar到最后返回结果,整个过程 </li><li>spark的stage是如何划分的 </li><li>spark的rpc: spark2.0为什么放弃了akka 而用netty? </li><li>spark的各种HA,  master/worker/executor/driver/task的ha </li><li>spark的内存管理机制,spark 1.6前后分析对比, spark2.0 做出来哪些优化 </li><li>讲一下spark 中的广播变量 </li><li>什么是数据倾斜,怎样去处理数据倾斜 </li><li>分析一下一段spark代码中哪些部分在Driver端执行,哪些部分在Worker端执行 </li></ol><h2 id="四、Flink"><a href="#四、Flink" class="headerlink" title="四、Flink"></a>四、Flink</h2><ol><li>讲一下flink的运行架构 </li><li>讲一下flink的作业执行流程 </li><li>flink具体是如何实现exactly once 语义 </li><li>flink 的 window 实现机制 </li><li>flink的window分类 </li><li>flink 的 state 是存储在哪里的 </li><li>flink是如何实现反压的 </li><li>flink的部署模式都有哪些 </li><li>讲一下flink on yarn的部署 </li><li>flink中的时间概念 , eventTime 和 processTime的区别 </li><li>flink中的session Window怎样使用 </li></ol><h2 id="五、HBase"><a href="#五、HBase" class="headerlink" title="五、HBase"></a>五、HBase</h2><ol><li>讲一下 Hbase 架构 </li><li>hbase 如何设计 rowkey </li><li>讲一下hbase的存储结构,这样的存储结构有什么优缺点 </li><li>hbase的HA实现,zookeeper在其中的作用 </li><li>HMaster宕机的时候,哪些操作还能正常工作 </li><li>讲一下hbase的写数据的流程 </li><li>讲一下hbase读数据的流程 </li></ol><h2 id="六、Kafka"><a href="#六、Kafka" class="headerlink" title="六、Kafka"></a>六、Kafka</h2><ol><li>讲一下 kafka 的架构 </li><li>kafka 与其他消息组件对比? </li><li>kafka 实现高吞吐的原理 </li><li>kafka怎样保证不重复消费 </li><li>kafka怎样保证不丢失消息 </li><li>kafka 与 spark streaming 集成,如何保证 exactly once 语义 </li><li>ack 有哪几种, 生产中怎样选择? </li><li>如何通过 offset 寻找数据 </li><li>如何清理过期数据 </li><li>1条message中包含哪些信息 </li><li>讲一下zookeeper在kafka中的作用 </li><li>kafka 可以脱离 zookeeper 单独使用吗 </li><li>kafka有几种数据保留策略 </li><li>kafka同时设置了7天和10G清除数据,到第5天的时候消息到达了10G,这个时候kafka如何处理? </li></ol><h2 id="七、Zookeeper"><a href="#七、Zookeeper" class="headerlink" title="七、Zookeeper"></a>七、Zookeeper</h2><ol><li>zookeeper是什么,都有哪些功能 </li><li>zk 有几种部署模式 </li><li>zk 是怎样保证主从节点的状态同步</li><li>说一下 zk 的通知机制</li><li>zk 的分布式锁实现方式</li><li>zk 采用的哪种分布式一致性协议? 还有哪些分布式一致性协议</li><li>讲一下leader 选举过程</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;大数据面试题全套汇总-答案&quot;&gt;&lt;a href=&quot;#大数据面试题全套汇总-答案&quot; class=&quot;headerlink&quot; title=&quot;大数据面试题全套汇总+答案&quot;&gt;&lt;/a&gt;大数据面试题全套汇总+答案&lt;/h4&gt;&lt;hr&gt;
&lt;table&gt;&lt;br&gt;    &lt;tr&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hadoop.jpg&quot;&gt;&lt;/th&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hive.jpg&quot;&gt;&lt;/th&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/spark.jpg&quot;&gt;&lt;/th&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/flink.png&quot;&gt;&lt;/th&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/hbase.png&quot;&gt;&lt;/th&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/kafka.png&quot;&gt;&lt;/th&gt;&lt;br&gt;     &lt;th&gt;&lt;img width=&quot;50px&quot; src=&quot;https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2020/bd_Interview/pictures/zookeeper.jpg&quot;&gt;&lt;/th&gt;&lt;br&gt;    &lt;/tr&gt;&lt;br&gt;&lt;tr&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#一hadoop&quot;&gt;Hadoop&lt;/a&gt;&lt;/td&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#二hive&quot;&gt;Hive&lt;/a&gt;&lt;/td&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#三spark&quot;&gt;Spark&lt;/a&gt;&lt;/td&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#四flink&quot;&gt;Flink&lt;/a&gt;&lt;/td&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#五hbase&quot;&gt;HBase&lt;/a&gt;&lt;/td&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#六kafka&quot;&gt;Kafka&lt;/a&gt;&lt;/td&gt;&lt;br&gt;  &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;#七zookeeper&quot;&gt;Zookeeper&lt;/a&gt;&lt;/td&gt;&lt;br&gt;&lt;/tr&gt;&lt;br&gt;    &lt;/table&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://icocos.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="https://icocos.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="面试" scheme="https://icocos.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>架构篇——MySQL高可用集群(PXC)详解</title>
    <link href="https://icocos.github.io/2019/06/11/%E6%9E%B6%E6%9E%84%E7%AF%87%E2%80%94%E2%80%94MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4-PXC-%E8%AF%A6%E8%A7%A3/"/>
    <id>https://icocos.github.io/2019/06/11/架构篇——MySQL高可用集群-PXC-详解/</id>
    <published>2019-06-11T09:56:41.000Z</published>
    <updated>2019-05-22T09:04:41.409Z</updated>
    
    <content type="html"><![CDATA[<h5 id="在介绍PXC之前，先来看一个相关的技术：MyCat"><a href="#在介绍PXC之前，先来看一个相关的技术：MyCat" class="headerlink" title="在介绍PXC之前，先来看一个相关的技术：MyCat"></a>在介绍PXC之前，先来看一个相关的技术：MyCat</h5><h3 id="MyCat简介"><a href="#MyCat简介" class="headerlink" title="MyCat简介"></a>MyCat简介</h3><p>MyCat是阿里开源的分布式数据库分库分表中间件</p><blockquote><p>MyCat是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信</p></blockquote><h4 id="MyCat功能"><a href="#MyCat功能" class="headerlink" title="MyCat功能:"></a>MyCat功能:</h4><ul><li>数据库读写分离(写操作在主,读操作在从数据库)</li><li>读的负载均衡(一主多从)</li><li>垂直拆分(将表分开为多个数据库)</li><li>水平拆分(对表取模拆分)</li></ul><a id="more"></a><blockquote><p>MyCAT是mysql中间件，前身是阿里大名鼎鼎的Cobar，Cobar在开源了一段时间后，不了了之。于是MyCAT扛起了这面大旗，在大数据时代，其重要性愈发彰显。这篇文章主要是MyCAT的入门部署。</p></blockquote><ul><li>更多相关可以参考这里：<a href="https://www.jianshu.com/p/c6e29d724fca" target="_blank" rel="noopener">https://www.jianshu.com/p/c6e29d724fca</a></li></ul><p>下面是MyCat结合PXC的架构图</p><p><img src="https://raw.githubusercontent.com/iCocos/icocos_hexo_images/master/2019/phps/pxc.png"></p><h3 id="PXC简介"><a href="#PXC简介" class="headerlink" title="PXC简介"></a>PXC简介</h3><p>PXC是percona公司的percona  xtraDB  cluster，简称PXC。它是基于Galera协议的高可用集群方案。可以实现多个节点间的数据同步复制以及读写，并且可保障数据库的服务高可用及数据强一致性。</p><blockquote><p>PXC就属于一套近乎完美的MySQL高可用集群架构方案；</p></blockquote><h5 id="主要特点是：-读写强一致性-牺牲性能"><a href="#主要特点是：-读写强一致性-牺牲性能" class="headerlink" title="主要特点是： 读写强一致性(牺牲性能)"></a>主要特点是： 读写强一致性(牺牲性能)</h5><h5 id="PXC特性"><a href="#PXC特性" class="headerlink" title="PXC特性"></a>PXC特性</h5><ul><li>1）同步复制，事务要么在所有节点提交或不提交。</li><li>2）多主复制，可以在任意节点进行写操作。</li><li>3）在从服务器上并行应用事件，真正意义上的并行复制。</li><li>4）节点自动配置，数据一致性，不再是异步复制。</li></ul><p>PXC最大的优势：强一致性、无同步延迟</p><ul><li><p>优点总结：</p><ul><li>服务高可用</li><li>可以达到时时同步(并发复制)，无延迟现象发生</li><li>完全兼容MySQL</li><li>对于集群中新节点的加入(自动部署)，维护起来很简单</li><li>数据的强一致性</li><li>多个可同时读写节点，可实现写扩展，不过最好事先进行分库分表，让各个节点分别写不同的表或者库，避免让galera解决数据冲突；</li></ul></li><li><p>不足之处总结：</p><ul><li>只支持Innodb存储引擎</li><li>存在多节点update更新问题，也就是写放大问题</li><li>在线DDL语句，锁表问题</li><li>sst针对新节点加入的传输代价过高的问题</li><li>所有表都要有主键；</li><li>不支持LOCK TABLE等显式锁操作；</li><li>锁冲突、死锁问题相对更多；</li><li>不支持XA；</li></ul></li></ul><p>事实上，采用PXC的主要目的是解决数据的一致性问题，高可用是顺带实现的。因为PXC存在写扩大以及短板效应，并发效率会有较大损失，类似semi sync replication机制。</p><pre><code>网络说明基于Galere协议的高可用方案：pxc+ Galera是Codership提供的多主数据同步复制机制，可以实现多个节点间的数据同步复制以及读写，并且+ 可保障数据库的服务高可用及数据一致性。+ 基于Galera的高可用方案主要有MariaDB Galera Cluster和Percona XtraDB Cluster（简称PXC），目前PXC用的会比较多一些。+ mariadb的集群原理跟PXC一样,maridb-cluster其实就是PXC，两者原理是一样的。</code></pre><h3 id="PXC原理"><a href="#PXC原理" class="headerlink" title="PXC原理"></a>PXC原理</h3><p>Percona XtraDB Cluster（简称PXC集群）提供了MySQL高可用的一种实现方法。</p><ul><li>1）集群是有节点组成的，推荐配置至少3个节点，但是也可以运行在2个节点上。</li><li>2）每个节点都是普通的mysql/percona服务器，可以将现有的数据库服务器组成集群，反之，也可以将集群拆分成单独的服务器。</li><li>3）每个节点都包含完整的数据副本。</li></ul><p>PXC集群主要由两部分组成：Percona Server with XtraDB和Write Set Replication patches（使用了Galera library，一个通用的用于事务型应用的同步、多主复制插件）。</p><p>PXC会使用大概是4个端口号</p><ul><li>3306 数据库对外服务的端口号</li><li>4444 请求SST SST: 指数据一个镜象传输 xtrabackup , rsync ,mysqldump </li><li>4567 : 组成员之间进行沟通的一个端口号</li><li>4568 : 传输IST用的。相对于SST来说的一个增量。</li></ul><blockquote><p>注：安装PXC过程中， iptables 禁掉 ，selinux 也禁掉</p></blockquote><h3 id="PXC的操作流程："><a href="#PXC的操作流程：" class="headerlink" title="PXC的操作流程："></a>PXC的操作流程：</h3><ul><li>首先客户端先发起一个事务，该事务先在本地执行，执行完成之后就要发起对事务的提交操作了。</li><li>在提交之前需要将产生的复制写集广播出去，然后获取到一个全局的事务ID号，一并传送到另一个节点上面。</li><li>通过合并数据之后，发现没有冲突数据，执行apply_cd和commit_cb动作，否则就需要取消此次事务的操作。</li><li>当前server节点通过验证之后，执行提交操作，并返回OK，如果验证没通过，则执行回滚。</li><li>在生产中至少要有3个节点的集群环境，如果其中一个节点没有验证通过，出现了数据冲突，那么此时采取的方式就是讲出现不一致的节点踢出集群环境，而且它自己会执行shutdown命令，自动关机。</li></ul><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>部署环境： CentOS7.X</p><h5 id="1、执行-命令-vi-etc-selinux-config"><a href="#1、执行-命令-vi-etc-selinux-config" class="headerlink" title="1、执行 命令   vi /etc/selinux/config"></a>1、执行 命令   vi /etc/selinux/config</h5><pre><code>SELINUX=disabled   #修改该项为disabled</code></pre><h5 id="2、执行命令-setenforce-0"><a href="#2、执行命令-setenforce-0" class="headerlink" title="2、执行命令   setenforce 0"></a>2、执行命令   setenforce 0</h5><h5 id="3、查看防火墙是否开启-systemctl-status-firewalld"><a href="#3、查看防火墙是否开启-systemctl-status-firewalld" class="headerlink" title="3、查看防火墙是否开启     systemctl status firewalld"></a>3、查看防火墙是否开启     systemctl status firewalld</h5><p>如果防火墙是开启状态，则开放端口 3306 、4444、4567、4568</p><pre><code>firewall-cmd --add-port=3306/tcp --permanent     #开放了3306端口</code></pre><p>开放完4个端口后，重新加载防火墙规则</p><pre><code>firewall-cmd --reload</code></pre><h5 id="4、安装Persona仓库"><a href="#4、安装Persona仓库" class="headerlink" title="4、安装Persona仓库"></a>4、安装Persona仓库</h5><pre><code>yum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm</code></pre><h5 id="5、安装PXC（保证服务器没有装MySQL）卸载MySQL-参考链接：https-blog-csdn-net-tjcyjd-article-details-52189182"><a href="#5、安装PXC（保证服务器没有装MySQL）卸载MySQL-参考链接：https-blog-csdn-net-tjcyjd-article-details-52189182" class="headerlink" title="5、安装PXC（保证服务器没有装MySQL）卸载MySQL 参考链接：https://blog.csdn.net/tjcyjd/article/details/52189182"></a>5、安装PXC（保证服务器没有装MySQL）卸载MySQL 参考链接：<a href="https://blog.csdn.net/tjcyjd/article/details/52189182" target="_blank" rel="noopener">https://blog.csdn.net/tjcyjd/article/details/52189182</a></h5><pre><code>yum install Percona-XtraDB-Cluster-57</code></pre><h5 id="6、开启PXC服务"><a href="#6、开启PXC服务" class="headerlink" title="6、开启PXC服务"></a>6、开启PXC服务</h5><pre><code>service mysql start</code></pre><h5 id="7、查看安装数据库的临时密码并记住"><a href="#7、查看安装数据库的临时密码并记住" class="headerlink" title="7、查看安装数据库的临时密码并记住"></a>7、查看安装数据库的临时密码并记住</h5><pre><code>grep &apos;temporary password&apos; /var/log/mysqld.log</code></pre><h5 id="8、登录MySQL数据库"><a href="#8、登录MySQL数据库" class="headerlink" title="8、登录MySQL数据库"></a>8、登录MySQL数据库</h5><pre><code>mysql -u root -p</code></pre><p>输入临时密码, 登录成功后修改密码</p><pre><code>ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;你的密码&apos;;</code></pre><h5 id="9、停止MySQL服务"><a href="#9、停止MySQL服务" class="headerlink" title="9、停止MySQL服务"></a>9、停止MySQL服务</h5><pre><code>service mysql stop   （某些版本使用mysqld）</code></pre><h5 id="10、配置节点"><a href="#10、配置节点" class="headerlink" title="10、配置节点"></a>10、配置节点</h5><pre><code>vi  /etc/percona-xtradb-cluster.conf.d/wsrep.cnf</code></pre><p>修改配置文件</p><pre><code># Cluster connection URL contains IPs of nodes#If no IP is found, this implies that a new cluster needs to be created,#in order to do that you need to bootstrap this node#集群中节点的IP地址（本机填最后）wsrep_cluster_address=gcomm://ip地址,IP地址,IP地址（用,号隔开）# In order for Galera to work correctly binlog format should be ROWbinlog_format=ROW# MyISAM storage engine has only experimental supportdefault_storage_engine=InnoDB# Slave thread to usewsrep_slave_threads= 8wsrep_log_conflicts# This changes how InnoDB autoincrement locks are managed and is a requirement for Galerainnodb_autoinc_lock_mode=2# Node IP address#当前节点IPwsrep_node_address=IP地址# Cluster name#集群名称wsrep_cluster_name=pxc-cluster#If wsrep_node_name is not specified,  then system hostname will be used#当前节点名称wsrep_node_name=pxc-cluster-node-1#pxc_strict_mode allowed values: DISABLED,PERMISSIVE,ENFORCING,MASTER#不使用实验功能pxc_strict_mode=ENFORCING# SST method#状态快照传输（sst）方法，官方建议wsrep_sst_method=xtrabackup-v2#Authentication for SST method#用户凭证（mysql的用户名和密码）wsrep_sst_auth=&quot;用户名:密码&quot;</code></pre><p>剩下的节点修改当前节点名、当前节点IP、集群中的节点IP，其他相同</p><blockquote><p>注：1—10步骤  每个节点都要配置一次</p></blockquote><h5 id="11、初始化集群节点"><a href="#11、初始化集群节点" class="headerlink" title="11、初始化集群节点"></a>11、初始化集群节点</h5><p>其中一个节点使用 systemctl start <a href="mailto:mysql@bootstrap.service" target="_blank" rel="noopener">mysql@bootstrap.service</a> 启动</p><h6 id="登录mysql"><a href="#登录mysql" class="headerlink" title="登录mysql"></a>登录mysql</h6><pre><code>mysql -u root -p</code></pre><p>开启 wsrep_causal_reads</p><pre><code>set wsrep_causal_reads =1;</code></pre><h5 id="12、创建配置文件中对应的用户"><a href="#12、创建配置文件中对应的用户" class="headerlink" title="12、创建配置文件中对应的用户"></a>12、创建配置文件中对应的用户</h5><blockquote><p>所有节点的IP都要创建</p></blockquote><p>创建用户：    </p><pre><code>CREATE USER &apos;用户名&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;密码&apos;;  </code></pre><p>刷新权限：   </p><pre><code>GRANT all privileges ON *.* TO &apos;用户名&apos;@&apos;localhost&apos; ;FLUSH PRIVILEGES;</code></pre><p>创建用户：</p><pre><code>CREATE USER &apos;用户名&apos;@&apos;当前需要访问数据库的IP地址&apos; IDENTIFIED BY &apos;密码&apos;;  </code></pre><p>刷新权限：</p><pre><code>GRANT all privileges ON *.* TO &apos;用户名&apos;@&apos;当前节点IP地址&apos; ;FLUSH PRIVILEGES;</code></pre><h5 id="13、其他节点使用-service-mysql-start-启动-，登录mysql，配置wsrep-causal-reds，set-wsrep-causal-reads-1"><a href="#13、其他节点使用-service-mysql-start-启动-，登录mysql，配置wsrep-causal-reds，set-wsrep-causal-reads-1" class="headerlink" title="13、其他节点使用   service mysql start  启动 ，登录mysql，配置wsrep_causal_reds，set wsrep_causal_reads =1;"></a>13、其他节点使用   service mysql start  启动 ，登录mysql，配置wsrep_causal_reds，set wsrep_causal_reads =1;</h5><h5 id="14、其他节点启动成功后在引导节点（使用-systemctl-start-mysql-bootstrap-service-命令启动的节点）"><a href="#14、其他节点启动成功后在引导节点（使用-systemctl-start-mysql-bootstrap-service-命令启动的节点）" class="headerlink" title="14、其他节点启动成功后在引导节点（使用 systemctl start mysql@bootstrap.service 命令启动的节点）"></a>14、其他节点启动成功后在引导节点（使用 systemctl start <a href="mailto:mysql@bootstrap.service" target="_blank" rel="noopener">mysql@bootstrap.service</a> 命令启动的节点）</h5><p>验证集群：</p><pre><code>show status like &apos;wsrep%&apos;;  </code></pre><h5 id="15、节点数据同步验证"><a href="#15、节点数据同步验证" class="headerlink" title="15、节点数据同步验证"></a>15、节点数据同步验证</h5><p>在当前节点创建一个数据库 </p><pre><code>CREATE DATABASE percona;</code></pre><p>启动其他节点的数据库服务，进去后会发现新建的数据库，同理 其他节点创建的数据  当前节点也能看到</p><p>注意：服务的启动和停止要对应</p><pre><code>service mysql stop   ------&gt;  启动时用service mysql start</code></pre><p>或者 </p><pre><code>systemctl stop mysql@bootstrap.service   -----&gt;  启用是用 systemctl start mysql@bootstrap.service </code></pre><ul><li>更多相关实战配置可以参考这里：<a href="https://www.jianshu.com/p/0b7c050dfab6" target="_blank" rel="noopener">https://www.jianshu.com/p/0b7c050dfab6</a></li></ul><h5 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h5><ul><li>带你玩转Mysql高可用方案–PXC<ul><li><a href="https://blog.csdn.net/zisefeizhu/article/details/81873466" target="_blank" rel="noopener">https://blog.csdn.net/zisefeizhu/article/details/81873466</a></li></ul></li><li><p>Docker搭建PXC集群</p><ul><li><a href="https://blog.csdn.net/weixin_41141219/article/details/82767832" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41141219/article/details/82767832</a></li></ul></li><li><p>MySQL高可用方案－PXC环境部署记录: 详细教程</p><ul><li><a href="http://www.cnblogs.com/kevingrace/p/5685371.html" target="_blank" rel="noopener">http://www.cnblogs.com/kevingrace/p/5685371.html</a></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;在介绍PXC之前，先来看一个相关的技术：MyCat&quot;&gt;&lt;a href=&quot;#在介绍PXC之前，先来看一个相关的技术：MyCat&quot; class=&quot;headerlink&quot; title=&quot;在介绍PXC之前，先来看一个相关的技术：MyCat&quot;&gt;&lt;/a&gt;在介绍PXC之前，先来看一个相关的技术：MyCat&lt;/h5&gt;&lt;h3 id=&quot;MyCat简介&quot;&gt;&lt;a href=&quot;#MyCat简介&quot; class=&quot;headerlink&quot; title=&quot;MyCat简介&quot;&gt;&lt;/a&gt;MyCat简介&lt;/h3&gt;&lt;p&gt;MyCat是阿里开源的分布式数据库分库分表中间件&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MyCat是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;MyCat功能&quot;&gt;&lt;a href=&quot;#MyCat功能&quot; class=&quot;headerlink&quot; title=&quot;MyCat功能:&quot;&gt;&lt;/a&gt;MyCat功能:&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;数据库读写分离(写操作在主,读操作在从数据库)&lt;/li&gt;
&lt;li&gt;读的负载均衡(一主多从)&lt;/li&gt;
&lt;li&gt;垂直拆分(将表分开为多个数据库)&lt;/li&gt;
&lt;li&gt;水平拆分(对表取模拆分)&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="MySQL" scheme="https://icocos.github.io/tags/MySQL/"/>
    
      <category term="PXC集群" scheme="https://icocos.github.io/tags/PXC%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>架构篇——MySQL主从复制(Master-Slave)详解</title>
    <link href="https://icocos.github.io/2019/06/09/%E6%9E%B6%E6%9E%84%E7%AF%87%E2%80%94%E2%80%94MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-Master-Slave-%E8%AF%A6%E8%A7%A3/"/>
    <id>https://icocos.github.io/2019/06/09/架构篇——MySQL主从复制-Master-Slave-详解/</id>
    <published>2019-06-09T09:55:42.000Z</published>
    <updated>2019-05-22T09:04:36.347Z</updated>
    
    <content type="html"><![CDATA[<h3 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h3><p>Mysql主从又叫Replication、AB复制(不同于PXC)。简单讲就是A与B两台机器做主从后，在A上写数据，另外一台B也会跟着写数据，实现数据实时同步</p><blockquote><p>mysql主从是基于binlog，主上需开启binlog才能进行主从</p></blockquote><h5 id="主从过程大概有3个步骤"><a href="#主从过程大概有3个步骤" class="headerlink" title="主从过程大概有3个步骤"></a>主从过程大概有3个步骤</h5><ul><li>主将更改操作记录到binlog里</li><li>从将主的binlog事件（sql语句） 同步本机上并记录在relaylog里</li><li>从根据relaylog里面的sql语句按顺序执行</li></ul><a id="more"></a><h4 id="主从作用"><a href="#主从作用" class="headerlink" title="主从作用"></a>主从作用</h4><pre><code>实时灾备，用于故障切换读写分离，提供查询服务备份，避免影响业务</code></pre><h4 id="主从形式"><a href="#主从形式" class="headerlink" title="主从形式"></a>主从形式</h4><ul><li>一主一从</li><li>主主复制</li><li>一主多从—扩展系统读取的性能，因为读是在从库读取的</li><li>多主一从—5.7版本开始支持</li><li>联级复制</li></ul><p>MySQL数据库自身提供的主从复制功能可以方便的实现数据的多处自动备份，实现数据库的拓展。多个数据备份不仅可以加强数据的安全性，通过实现读写分离还能进一步提升数据库的负载性能。</p><h3 id="原理："><a href="#原理：" class="headerlink" title="原理："></a>原理：</h3><blockquote><p>MySQL之间数据复制的基础是二进制日志文件（binary log file）。一台MySQL数据库一旦启用二进制日志后，其作为master，它的数据库中所有操作都会以“事件”的方式记录在二进制日志中，其他数据库作为slave通过一个I/O线程与主服务器保持通信，并监控master的二进制日志文件的变化，如果发现master二进制日志文件发生变化，则会把变化复制到自己的中继日志中，然后slave的一个SQL线程会把相关的“事件”执行到自己的数据库中，以此实现从数据库和主数据库的一致性，也就实现了主从复制。</p></blockquote><ul><li>主库将所有的写操作记录在binlog日志中，并生成log dump线程，将binlog日志传给从库的I/O线程</li><li>从库生成两个线程，一个是I/O线程，另一个是SQL线程</li><li>I/O线程去请求主库的binlog日志，并将binlog日志中的文件写入relay log（中继日志）中</li><li>SQL线程会读取relay loy中的内容，并解析成具体的操作，来实现主从的操作一致，达到最终数据一致的目的</li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>实现MySQL主从复制需要进行的配置：</p><ul><li><p>主服务器：</p><ul><li>开启二进制日志</li><li>配置唯一的server-id</li><li>获得master二进制日志文件名及位置</li><li>创建一个用于slave和master通信的用户账号</li></ul></li><li><p>从服务器：</p><ul><li>配置唯一的server-id</li><li>使用master分配的用户账号读取master二进制日志</li><li>启用slave服务</li></ul></li></ul><h4 id="具体实现过程如下："><a href="#具体实现过程如下：" class="headerlink" title="具体实现过程如下："></a>具体实现过程如下：</h4><p>主从复制配置步骤：</p><ul><li>确保从数据库与主数据库里的数据一致</li><li>在主数据库里创建一个同步账户授权给从数据库使用</li><li>配合主数据库（修改配置文件）</li><li>配置从数据库（修改配置文件）</li></ul><h5 id="一、准备工作："><a href="#一、准备工作：" class="headerlink" title="一、准备工作："></a>一、准备工作：</h5><ol><li>主从数据库版本最好一致</li><li>主从数据库内数据保持一致</li></ol><p>搭建两台MYSQL服务器，一台作为主服务器，一台作为从服务器，主服务器进行写操作，从服务器进行读操作</p><pre><code>+ 主数据库：192.168.0.1 /Linux-MySQL+ 从数据库：192.168.0.2 /Linux-MySQL</code></pre><h5 id="二、主数据库master修改："><a href="#二、主数据库master修改：" class="headerlink" title="二、主数据库master修改："></a>二、主数据库master修改：</h5><p>1.修改mysql配置</p><p>找到主数据库的配置文件my.cnf(或者my.ini)，我的在/etc/mysql/my.cnf,在[mysqld]部分插入如下两行：</p><pre><code>[mysqld]log-bin=mysql-bin #开启二进制日志server-id=1 #设置server-id</code></pre><p>2.重启mysql，创建用于同步的用户账号</p><p>打开mysql会话shell</p><pre><code>mysql -hlocalhost -uname -ppassword</code></pre><p>创建用户：用户：rel1密码：slavepass</p><p>3.授权</p><p>主服务器授权从服务器特定账号登录</p><pre><code>mysql&gt; CREATE USER &apos;repl&apos;@&apos;192.168.0.2&apos; IDENTIFIED BY &apos;slavepass&apos;;#创建用户mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;repl&apos;@&apos;192.168.0.2&apos;;#分配权限mysql&gt;flush privileges;   #刷新权限</code></pre><p>4.查看master状态，记录二进制文件名(mysql-bin.000003)和位置(73)：</p><pre><code>mysql &gt; SHOW MASTER STATUS;+------------------+----------+--------------+------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000003 | 73       | test         | manual,mysql     |+------------------+----------+--------------+------------------+</code></pre><h5 id="三、从服务器slave修改："><a href="#三、从服务器slave修改：" class="headerlink" title="三、从服务器slave修改："></a>三、从服务器slave修改：</h5><p>1.修改mysql配置</p><p>同样找到my.cnf配置文件，添加server-id</p><pre><code>[mysqld]server-id=2 #设置server-id，必须唯一</code></pre><p>2.重启mysql，打开mysql会话，执行同步SQL语句(需要主服务器主机名，登陆凭据，二进制文件的名称和位置)：<br>复制代码</p><pre><code>mysql&gt; CHANGE MASTER TO    -&gt;     MASTER_HOST=&apos;192.168.0.1&apos;,    -&gt;     MASTER_USER=&apos;rep1&apos;,    -&gt;     MASTER_PASSWORD=&apos;slavepass&apos;,    -&gt;     MASTER_LOG_FILE=&apos;mysql-bin.000003&apos;,    -&gt;     MASTER_LOG_POS=73;</code></pre><p>3.启动slave同步进程：</p><pre><code>mysql&gt;start slave;</code></pre><p>4.查看slave状态：</p><pre><code>mysql&gt; show slave status\G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.0.1                  Master_User: rep1                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000013          Read_Master_Log_Pos: 11662               Relay_Log_File: mysqld-relay-bin.000022                Relay_Log_Pos: 11765        Relay_Master_Log_File: mysql-bin.000013             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB:           Replicate_Ignore_DB:         ...</code></pre><p>当Slave_IO_Running和Slave_SQL_Running都为YES的时候就表示主从同步设置成功了。</p><p>接下来就可以进行一些验证了，比如在主master数据库的test数据库的一张表中插入一条数据，在slave的test库的相同数据表中查看是否有新增的数据即可验证主从复制功能是否有效，还可以关闭slave（mysql&gt;stop slave;）,然后再修改master，看slave是否也相应修改（停止slave后，master的修改不会同步到slave），就可以完成主从复制功能的验证了。</p><p>还可以用到的其他相关参数：</p><blockquote><p>master开启二进制日志后默认记录所有库所有表的操作，可以通过配置来指定只记录指定的数据库甚至指定的表的操作，具体在mysql配置文件的[mysqld]可添加修改如下选项：</p></blockquote><pre><code># 不同步哪些数据库  binlog-ignore-db = mysql  binlog-ignore-db = test  binlog-ignore-db = information_schema  # 只同步哪些数据库，除此之外，其他不同步  binlog-do-db = game  </code></pre><blockquote><p>如之前查看master状态时就可以看到只记录了test库，忽略了manual和mysql库。</p></blockquote><h3 id="操作流程汇总"><a href="#操作流程汇总" class="headerlink" title="操作流程汇总"></a>操作流程汇总</h3><h5 id="关闭防火墙以SELINUX"><a href="#关闭防火墙以SELINUX" class="headerlink" title="关闭防火墙以SELINUX"></a>关闭防火墙以SELINUX</h5><pre><code>[root@icocos ~]# systemctl stop firewalld[root@icocos ~]# systemctl disable firewalld[root@icocos ~]#  sed -ri &apos;s/(SELINUX=).*/\1disabled/g&apos; /etc/selinux/config[root@icocos ~]# setenforce 0</code></pre><h5 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h5><pre><code>安装依赖包[root@icocos ~]# yum -y install ncurses-devel openssl-devel openssl cmake mariadb-devel</code></pre><h5 id="创建用户和组"><a href="#创建用户和组" class="headerlink" title="创建用户和组"></a>创建用户和组</h5><pre><code>[root@icocos ~]# groupadd -r -g 306 mysql[root@icocos ~]# useradd -M -s /sbin/nologin -g 306 -u 306 mysql</code></pre><h5 id="下载二进制格式的mysql软件包"><a href="#下载二进制格式的mysql软件包" class="headerlink" title="下载二进制格式的mysql软件包"></a>下载二进制格式的mysql软件包</h5><pre><code>[root@icocos ~]# cd /usr/src/[root@icocos src]#wget https://downloads.mysql.com/archives/get/file/mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz</code></pre><h5 id="解压软件至-usr-local"><a href="#解压软件至-usr-local" class="headerlink" title="解压软件至/usr/local/"></a>解压软件至/usr/local/</h5><pre><code>[root@icocos src]# lsdebug  kernels  mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz[root@icocos src]# tar xf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz -C /usr/local/[root@icocos src]#  ls  /usr/local/bin  etc  games  include  lib  lib64  libexec  mysql-5.7.22-linux-glibc2.12-x86_64  sbin  share  src[root@icocos src]#  cd  /usr/local/[root@icocos local]# ln -sv mysql-5.7.22-linux-glibc2.12-x86_64/ mysql&quot;mysql&quot; -&gt; &quot;mysql-5.7.22-linux-glibc2.12-x86_64/&quot;[root@icocos local]# ll总用量 0drwxr-xr-x. 2 root root   6 11月  5 2016 bindrwxr-xr-x. 2 root root   6 11月  5 2016 etcdrwxr-xr-x. 2 root root   6 11月  5 2016 gamesdrwxr-xr-x. 2 root root   6 11月  5 2016 includedrwxr-xr-x. 2 root root   6 11月  5 2016 libdrwxr-xr-x. 2 root root   6 11月  5 2016 lib64drwxr-xr-x. 2 root root   6 11月  5 2016 libexeclrwxrwxrwx. 1 root root  36 9月   7 22:20 mysql -&gt; mysql-5.7.22-linux-glibc2.12-x86_64/drwxr-xr-x. 9 root root 129 9月   7 22:19 mysql-5.7.22-linux-glibc2.12-x86_64drwxr-xr-x. 2 root root   6 11月  5 2016 sbindrwxr-xr-x. 5 root root  49 9月   3 23:02 sharedrwxr-xr-x. 2 root root   6 11月  5 2016 src</code></pre><h5 id="修改目录-usr-locaal-mysql的属主属组"><a href="#修改目录-usr-locaal-mysql的属主属组" class="headerlink" title="修改目录/usr/locaal/mysql的属主属组"></a>修改目录/usr/locaal/mysql的属主属组</h5><pre><code>[root@icocos local]# chown -R mysql.mysql /usr/local/mysql[root@icocos local]#  ll /usr/local/mysql -dlrwxrwxrwx. 1 mysql mysql 36 9月   7 22:20 /usr/local/mysql -&gt; mysql-5.7.22-linux-glibc2.12-x86_64/</code></pre><h5 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h5><pre><code>[root@icocos local]# ls /usr/local/mysqlbin  COPYING  docs  include  lib  man  README  share  support-files[root@icocos local]# cd[root@icocos ~]# echo &apos;export PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh[root@icocos ~]# . /etc/profile.d/mysql.sh[root@icocos ~]# echo $PATH/usr/local/mysql/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</code></pre><h5 id="建立数据存放目录"><a href="#建立数据存放目录" class="headerlink" title="建立数据存放目录"></a>建立数据存放目录</h5><pre><code>[root@icocos ~]# cd /usr/local/mysql[root@icocos mysql]# mkdir /opt/data[root@icocos mysql]#  chown -R mysql.mysql /opt/data/[root@icocos mysql]#  ll /opt/总用量 0drwxr-xr-x. 2 mysql mysql 6 9月   7 22:25 data</code></pre><h5 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h5><pre><code>[root@icocos mysql]# /usr/local/mysql/bin/mysqld --initialize --user=mysql --datadir=/opt/data///这个命令的最后会生成一个临时密码，此处密码是1EbNA-k*BtKo</code></pre><h5 id="配置mysql"><a href="#配置mysql" class="headerlink" title="配置mysql"></a>配置mysql</h5><pre><code>[root@icocos ~]# ln -sv /usr/local/mysql/include/ /usr/local/include/mysql&quot;/usr/local/include/mysql&quot; -&gt; &quot;/usr/local/mysql/include/&quot;[root@icocos ~]# echo &apos;/usr/local/mysql/lib&apos; &gt; /etc/ld.so.conf.d/mysql.conf[root@icocos ~]#  ldconfig -v</code></pre><h5 id="生成配置文件"><a href="#生成配置文件" class="headerlink" title="生成配置文件"></a>生成配置文件</h5><pre><code>[root@icocos ~]# cat &gt; /etc/my.cnf &lt;&lt;EOF&gt; [mysqld]&gt; basedir = /usr/local/mysql&gt; datadir = /opt/data&gt; socket = /tmp/mysql.sock&gt; port = 3306&gt; pid-file = /opt/data/mysql.pid&gt; user = mysql&gt; skip-name-resolve&gt; EOF</code></pre><h5 id="配置服务启动脚本"><a href="#配置服务启动脚本" class="headerlink" title="配置服务启动脚本"></a>配置服务启动脚本</h5><pre><code>[root@icocos ~]# cp -a /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld[root@icocos ~]#  sed -ri &apos;s#^(basedir=).*#\1/usr/local/mysql#g&apos; /etc/init.d/mysqld[root@icocos ~]# sed -ri &apos;s#^(datadir=).*#\1/opt/data#g&apos; /etc/init.d/mysqld</code></pre><h5 id="启动mysql"><a href="#启动mysql" class="headerlink" title="启动mysql"></a>启动mysql</h5><pre><code>[root@icocos ~]#  service mysqld startStarting MySQL.Logging to &apos;/opt/data/icocos.err&apos;... SUCCESS![root@icocos ~]#  ps -ef|grep mysqlroot       4897      1  0 22:38 pts/2    00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safe --datadir=/opt/data --pid-file=/opt/data/mysql.pidmysql      5075   4897  6 22:38 pts/2    00:00:01 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/opt/data --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=icocos.err --pid-file=/opt/data/mysql.pid --socket=/tmp/mysql.sock --port=3306root       5109   4668  0 22:38 pts/2    00:00:00 grep --color=auto mysql[root@icocos ~]# ss -antlState       Recv-Q Send-Q                     Local Address:Port                                    Peer Address:Port              LISTEN      0      128                                    *:22                                                 *:*                  LISTEN      0      100                            127.0.0.1:25                                                 *:*                  LISTEN      0      128                                   :::22                                                :::*                  LISTEN      0      100                                  ::1:25                                                :::*                  LISTEN      0      80                                    :::3306                                              :::*                  </code></pre><h5 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h5><p>使用临时密码修改</p><pre><code>[root@icocos ~]# mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.22Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; set password = password(&apos;123456&apos;);Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; quitBye</code></pre><h5 id="mysql主从配置"><a href="#mysql主从配置" class="headerlink" title="mysql主从配置"></a>mysql主从配置</h5><p>确保从数据库与主数据库的数据一样先在主数据库创建所需要同步的库和表</p><pre><code>[root@icocos ~]# mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. AlOracle is a registered trademark of Oracle Corporation andaffiliates. Other names may be trademarks of their respectowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the currmysql&gt; create database yan;Query OK, 1 row affected (0.00 sec)mysql&gt; create database lisi;Query OK, 1 row affected (0.00 sec)mysql&gt; create database wangwu;Query OK, 1 row affected (0.00 sec)mysql&gt; use yan;Database changedmysql&gt; create table tom (id int not null,name varchar(100)not null ,age tinyint);Query OK, 0 rows affected (11.83 sec)mysql&gt; insert tom (id,name,age) values(1,&apos;zhangshan&apos;,20),(2,&apos;wangwu&apos;,7),(3,&apos;lisi&apos;,23);Query OK, 3 rows affected (0.07 sec)Records: 3  Duplicates: 0  Warnings: 0mysql&gt; select * from tom;+----+-----------+------+| id | name      | age  |+----+-----------+------+|  1 | zhangshan |   20 ||  2 | wangwu    |    7 ||  3 | lisi      |   23 |+----+-----------+------+3 rows in set (0.00 sec)</code></pre><h5 id="备份主库"><a href="#备份主库" class="headerlink" title="备份主库"></a>备份主库</h5><p>备份主库时需要另开一个终端，给数据库上读锁，避免在备份期间有其他人在写入导致数据同步的不一致</p><pre><code>[root@icocos ~]# mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 5Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; flush tables with read lock;Query OK, 0 rows affected (0.76 sec)</code></pre><p>此锁表的终端必须在备份完成以后才能退出（退出锁表失效）</p><h5 id="备份主库并将备份文件传送到从库"><a href="#备份主库并将备份文件传送到从库" class="headerlink" title="备份主库并将备份文件传送到从库"></a>备份主库并将备份文件传送到从库</h5><pre><code>[root@icocos ~]# mysqldump -uroot -p123456 --all-databases &gt; /opt/all-20180907.sqlmysqldump: [Warning] Using a password on the command line interface can be insecure.[root@icocos ~]# ls /opt/all-20180907.sql  data[root@icocos ~]# scp /opt/all-20180907.sql root@192.168.0.2:/opt/The authenticity of host &apos;192.168.0.2 (192.168.0.2)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:7mLj77SFk7sPkhjpMPfdK3nZ98hOuyP4OKzjXeijSJ0.ECDSA key fingerprint is MD5:a0:1b:eb:7f:f0:b6:7b:73:97:91:4c:f3:b1:89:d8:ea.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;192.168.0.2&apos; (ECDSA) to the list of known hosts.root@192.168.0.2&apos;s password:all-20180907.sql       100%  784KB 783.3KB/s   00:01    </code></pre><h5 id="解除主库的锁表状态，直接退出交互式界面即可"><a href="#解除主库的锁表状态，直接退出交互式界面即可" class="headerlink" title="解除主库的锁表状态，直接退出交互式界面即可"></a>解除主库的锁表状态，直接退出交互式界面即可</h5><pre><code>mysql&gt; quitBye</code></pre><h5 id="在从库上恢复主库的备份并查看是否与主库的数据保持一致"><a href="#在从库上恢复主库的备份并查看是否与主库的数据保持一致" class="headerlink" title="在从库上恢复主库的备份并查看是否与主库的数据保持一致"></a>在从库上恢复主库的备份并查看是否与主库的数据保持一致</h5><pre><code>[root@icocos ~]# mysql -uroot -p123456 &lt; /opt/all-20180907.sqlmysql: [Warning] Using a password on the command line interface can be insecure.[root@icocos ~]# mysql -uroot -p123456mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || lisi               || mysql              || performance_schema || sys                || wangwu             || yan                |+--------------------+7 rows in set (0.18 sec)mysql&gt; use yan;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from tom;+----+-----------+------+| id | name      | age  |+----+-----------+------+|  1 | zhangshan |   20 ||  2 | wangwu    |    7 ||  3 | lisi      |   23 |+----+-----------+------+3 rows in set (0.06 sec)</code></pre><h5 id="在主数据库创建一个同步账户授权给从数据使用"><a href="#在主数据库创建一个同步账户授权给从数据使用" class="headerlink" title="在主数据库创建一个同步账户授权给从数据使用"></a>在主数据库创建一个同步账户授权给从数据使用</h5><pre><code>[root@icocos ~]# mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.22 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.mysql&gt; create user &apos;repl&apos;@&apos;192.168.0.2&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected (5.50 sec)mysql&gt; grant replication slave on *.* to &apos;repl&apos;@&apos;192.168.0.2&apos;;Query OK, 0 rows affected (0.04 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.09 sec)</code></pre><h5 id="配置主数据库编辑配置文件"><a href="#配置主数据库编辑配置文件" class="headerlink" title="配置主数据库编辑配置文件"></a>配置主数据库编辑配置文件</h5><pre><code>[root@icocos ~]# vim /etc/my.cnf[root@icocos ~]# cat /etc/my.cnf[mysqld]basedir = /usr/local/mysqldatadir = /opt/datasocket = /tmp/mysql.sockport = 3306pid-file = /opt/data/mysql.piduser = mysqlskip-name-resolve//添加以下内容log-bin=mysql-bin //启用binlog日志server-id=1 //主数据库服务器唯一标识符 主的必须必从大log-error=/opt/data/mysql.log</code></pre><h5 id="重启mysql服务"><a href="#重启mysql服务" class="headerlink" title="重启mysql服务"></a>重启mysql服务</h5><pre><code>[root@icocos ~]# service mysqld restartShutting down MySQL..... SUCCESS!Starting MySQL.Logging to &apos;/opt/data/mysql.log&apos;................................ SUCCESS![root@icocos ~]# ss -antlState       Recv-Q Send-Q Local Address:Port               Peer Address:Port              LISTEN      0      128     *:22                  *:*                  LISTEN      0      100    127.0.0.1:25                  *:*                  LISTEN      0      128    :::22                 :::*                  LISTEN      0      100       ::1:25                 :::*                  LISTEN      0      80     :::3306               :::*</code></pre><h5 id="查看主库的状态"><a href="#查看主库的状态" class="headerlink" title="查看主库的状态"></a>查看主库的状态</h5><pre><code>mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 |      154 |              |                  |                   |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec)</code></pre><h5 id="配置从数据库"><a href="#配置从数据库" class="headerlink" title="配置从数据库"></a>配置从数据库</h5><p>编辑配置文件</p><pre><code>[root@icocos ~]# cat /etc/my.cnf[mysqld]basedir = /usr/local/mysqldatadir = /opt/datasocket = /tmp/mysql.sockport = 3306pid-file = /opt/data/mysql.piduser = mysqlskip-name-resolve//添加以下内容：server-id=2 //设置从库的唯一标识符 从的必须比主小relay-log=mysql-relay-bin //启用中继日志relay logerror-log=/opt/data/mysql.log</code></pre><h5 id="重启从库的mysql服务"><a href="#重启从库的mysql服务" class="headerlink" title="重启从库的mysql服务"></a>重启从库的mysql服务</h5><pre><code>[root@icocos ~]# service mysqld restartShutting down MySQL.. SUCCESS!Starting MySQL.. SUCCESS![root@icocos ~]# ss -antlState       Recv-Q Send-Q Local Address:Port               Peer Address:Port              LISTEN      0      128     *:22                  *:*                  LISTEN      0      100    127.0.0.1:25                  *:*                  LISTEN      0      128    :::22                 :::*                  LISTEN      0      100       ::1:25                 :::*                  LISTEN      0      80     :::3306               :::*                  </code></pre><h5 id="配置并启动主从复制"><a href="#配置并启动主从复制" class="headerlink" title="配置并启动主从复制"></a>配置并启动主从复制</h5><pre><code>mysql&gt; change master to    -&gt; master_host=&apos;192.168.0.1&apos;,    -&gt; master_user=&apos;repl&apos;,    -&gt; master_password=&apos;123456&apos;,    -&gt; master_log_file=&apos;mysql-bin.000001&apos;,    -&gt; master_log_pos=154;Query OK, 0 rows affected, 2 warnings (0.28 sec)</code></pre><h5 id="查看从服务器状态"><a href="#查看从服务器状态" class="headerlink" title="查看从服务器状态"></a>查看从服务器状态</h5><pre><code>mysql&gt; show slave status\G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.0.1                  Master_User: repl                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000001          Read_Master_Log_Pos: 154               Relay_Log_File: mysql-relay-bin.000003                Relay_Log_Pos: 320        Relay_Master_Log_File: mysql-bin.000001             Slave_IO_Running: Yes                                     //此处必须是yes            Slave_SQL_Running: Yes                                    //此处必须是yes                     Replicate_Do_DB:          Replicate_Ignore_DB:           Replicate_Do_Table:       Replicate_Ignore_Table:      Replicate_Wild_Do_Table:  Replicate_Wild_Ignore_Table:                   Last_Errno: 0                   Last_Error:                 Skip_Counter: 0          Exec_Master_Log_Pos: 154              Relay_Log_Space: 527              Until_Condition: None               Until_Log_File:                Until_Log_Pos: 0           Master_SSL_Allowed: No           Master_SSL_CA_File:           Master_SSL_CA_Path:              Master_SSL_Cert:            Master_SSL_Cipher:               Master_SSL_Key:        Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No                Last_IO_Errno: 0                Last_IO_Error:               Last_SQL_Errno: 0               Last_SQL_Error:  Replicate_Ignore_Server_Ids:             Master_Server_Id: 1                  Master_UUID: 5abf1791-b2af-11e8-b6ad-000c2980fbb4             Master_Info_File: /opt/data/master.info                    SQL_Delay: 0          SQL_Remaining_Delay: NULL      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates           Master_Retry_Count: 86400                  Master_Bind:      Last_IO_Error_Timestamp:     Last_SQL_Error_Timestamp:               Master_SSL_Crl:           Master_SSL_Crlpath:           Retrieved_Gtid_Set:            Executed_Gtid_Set:                Auto_Position: 0         Replicate_Rewrite_DB:                 Channel_Name:           Master_TLS_Version:1 row in set (0.00 sec)ERROR:No query specified</code></pre><h5 id="测试验证在主服务器的yan库的tom表插入数据"><a href="#测试验证在主服务器的yan库的tom表插入数据" class="headerlink" title="测试验证在主服务器的yan库的tom表插入数据:"></a>测试验证在主服务器的yan库的tom表插入数据:</h5><pre><code>mysql&gt; use yan;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from tom;+----+-----------+------+| id | name      | age  |+----+-----------+------+|  1 | zhangshan |   20 ||  2 | wangwu    |    7 ||  3 | lisi      |   23 |+----+-----------+------+3 rows in set (0.09 sec)mysql&gt; insert tom(id,name,age) value (4,&quot;yyl&quot;,18);Query OK, 1 row affected (0.14 sec)mysql&gt; select * from tom;+----+-----------+------+| id | name      | age  |+----+-----------+------+|  1 | zhangshan |   20 ||  2 | wangwu    |    7 ||  3 | lisi      |   23 ||  4 | yyl       |   18 |+----+-----------+------+4 rows in set (0.00 sec)</code></pre><h5 id="在从数据库查看是否数据同步"><a href="#在从数据库查看是否数据同步" class="headerlink" title="在从数据库查看是否数据同步"></a>在从数据库查看是否数据同步</h5><pre><code>mysql&gt; use yan;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from tom;+----+-----------+------+| id | name      | age  |+----+-----------+------+|  1 | zhangshan |   20 ||  2 | wangwu    |    7 ||  3 | lisi      |   23 ||  4 | yyl       |   18 |+----+-----------+------+4 rows in set (0.00 sec)</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;主从&quot;&gt;&lt;a href=&quot;#主从&quot; class=&quot;headerlink&quot; title=&quot;主从&quot;&gt;&lt;/a&gt;主从&lt;/h3&gt;&lt;p&gt;Mysql主从又叫Replication、AB复制(不同于PXC)。简单讲就是A与B两台机器做主从后，在A上写数据，另外一台B也会跟着写数据，实现数据实时同步&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mysql主从是基于binlog，主上需开启binlog才能进行主从&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;主从过程大概有3个步骤&quot;&gt;&lt;a href=&quot;#主从过程大概有3个步骤&quot; class=&quot;headerlink&quot; title=&quot;主从过程大概有3个步骤&quot;&gt;&lt;/a&gt;主从过程大概有3个步骤&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;主将更改操作记录到binlog里&lt;/li&gt;
&lt;li&gt;从将主的binlog事件（sql语句） 同步本机上并记录在relaylog里&lt;/li&gt;
&lt;li&gt;从根据relaylog里面的sql语句按顺序执行&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="MySQL" scheme="https://icocos.github.io/tags/MySQL/"/>
    
      <category term="主从复制" scheme="https://icocos.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>MySQL锁机制和PHP锁机制</title>
    <link href="https://icocos.github.io/2019/06/06/MySQL%E9%94%81%E6%9C%BA%E5%88%B6%E5%92%8CPHP%E9%94%81%E6%9C%BA%E5%88%B6/"/>
    <id>https://icocos.github.io/2019/06/06/MySQL锁机制和PHP锁机制/</id>
    <published>2019-06-06T10:47:41.000Z</published>
    <updated>2019-05-27T02:39:08.392Z</updated>
    
    <content type="html"><![CDATA[<h3 id="PHP中的文件锁-（锁的是文件，不是表）"><a href="#PHP中的文件锁-（锁的是文件，不是表）" class="headerlink" title="PHP中的文件锁 （锁的是文件，不是表）"></a>PHP中的文件锁 （锁的是文件，不是表）</h3><p>文件锁的文件与表有什么关系？：一点关系也没有，与令牌相似，谁拿到谁操作。所以表根本没锁。<br>测试时，有个文件就行，叫什么名无所谓</p><p>bool flock ( int handle, int operation [, int &amp;wouldblock] );<br>flock() 操作的 handle 必须是一个已经打开的文件指针。operation 可以是以下值之一：</p><ul><li>要取得共享锁定（读取程序），将 operation 设为 LOCK_SH（PHP 4.0.1 以前的版本设置为 1）</li><li>要取得独占锁定（写入程序），将 operation 设为 LOCK_EX（PHP 4.0.1 以前的版本中设置为 2）</li><li>要释放锁定（无论共享或独占），将 operation 设为 LOCK_UN（PHP 4.0.1 以前的版本中设置为 3）</li><li>如果你不希望 flock() 在锁定时堵塞，则给 operation 加上 LOCK_NB（PHP 4.0.1 以前的版本中设置为4）</li></ul><a id="more"></a><h4 id="建两个文件"><a href="#建两个文件" class="headerlink" title="建两个文件"></a>建两个文件</h4><!--more--><h5 id="1-a-php"><a href="#1-a-php" class="headerlink" title="(1) a.php"></a>(1) a.php</h5><pre><code>$file = &quot;temp.txt&quot;;   $fp = fopen($file , &apos;w&apos;);   if(flock($fp , LOCK_EX)){        fwrite($fp , &quot;abc\n&quot;);        sleep(10);        fwrite($fp , &quot;123\n&quot;);       flock($fp , LOCK_UN);   }   fclose($fp);  </code></pre><h5 id="2-b-php"><a href="#2-b-php" class="headerlink" title="(2) b.php"></a>(2) b.php</h5><pre><code>$file = &quot;temp.txt&quot;;   $fp = fopen($file , &apos;r&apos;);   echo fread($fp , 100);   fclose($fp);  </code></pre><p>运行 a.php 后，马上运行 b.php ，可以看到输出：</p><pre><code>abc</code></pre><p>等 a.php 运行完后运行 b.php ，可以看到输出：</p><pre><code>abc123</code></pre><p>显然，当 a.php 写文件时数据太大，导致时间比较长时，这时 b.php 读取数据不完整</p><p>修改 b.php 为：</p><pre><code>$file = &quot;temp.txt&quot;;   $fp = fopen($file , &apos;r&apos;);   if(flock($fp , LOCK_EX)){       echo fread($fp , 100);       flock($fp , LOCK_UN);   } else{       echo &quot;Lock file failed...\n&quot;;   }   fclose($fp);  </code></pre><p>运行 a.php 后，马上运行 b.php ，可以发现 b.php 会等到 a.php 运行完成后(即 10 秒后)才显示：</p><pre><code>abc123</code></pre><p>读取数据完整，但时间过长，他要等待写锁释放。</p><p>修改 b.php 为：</p><pre><code>$file = &quot;temp.txt&quot;;   $fp = fopen($file , &apos;r&apos;);   if(flock($fp , LOCK_SH | LOCK_NB)){       echo fread($fp , 100);       flock($fp , LOCK_UN);   } else{       echo &quot;Lock file failed...\n&quot;;   }   fclose($fp);  </code></pre><p>运行 a.php 后，马上运行 b.php ，可以看到输出：<br>    Lock file failed…</p><p>证明可以返回锁文件失败状态，而不是向上面一样要等很久。</p><h5 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h5><blockquote><p>建议作文件缓存时，选好相关的锁，不然可能导致读取数据不完整，或重复写入数据。<br>file_get_contents 好像选择不了锁，不知道他默认用的什么锁，反正和不锁得到的输出一样，是不完整的数据。</p></blockquote><p>我是要做文件缓存，所以只需要知道是否有写锁存在即可，有的话就查数据库就可以了。<br>测试环境：Linux(Ubuntu 6) , PHP 5.1.2 , Apache 2</p><h5 id="再转："><a href="#再转：" class="headerlink" title="再转："></a>再转：</h5><p>文件锁有两种：共享锁和排他锁，也就是读锁(LOCK_SH)和写锁(LOCK_EX)<br>文件的锁一般这么使用：</p><pre><code>$fp = fopen(&quot;filename&quot;, &quot;a&quot;);   flock($fp, LOCK_SH) or die(&quot;lock error&quot;)   $str = fread($fp, 1024);   flock($fp, LOCK_UN);   fclose($fp);  </code></pre><blockquote><p>注意fwrite之后，文件立即就被更新了，而不是等fwrite然后fclose之后文件才会更新，这个可以通过在fwrite之后fclose之前读取这个文件进行检查 </p></blockquote><p>但是什么时候使用lock_ex什么时候使用lock_sh呢？ </p><h5 id="读的时候："><a href="#读的时候：" class="headerlink" title="读的时候："></a>读的时候：</h5><p>如果不想出现dirty数据，那么最好使用lock_sh共享锁。可以考虑以下三种情况： </p><ol><li>如果读的时候没有加共享锁，那么其他程序要写的话（不管这个写是加锁还是不加锁）都会立即写成功。如果正好读了一半，然后被其他程序给写了，那么读的后一半就有可能跟前一半对不上（前一半是修改前的，后一半是修改后的） </li><li>如果读的时候加上了共享锁（因为只是读，没有必要使用排他锁），这个时候，其他程序开始写，这个写程序没有使用锁，那么写程序会直接修改这个文件，也会导致前面一样的问题 </li><li>最理想的情况是，读的时候加锁(lock_sh),写的时候也进行加锁(lock_ex),这样写程序会等着读程序完成之后才进行操作，而不会出现贸然操作的情况 </li></ol><h5 id="写的时候："><a href="#写的时候：" class="headerlink" title="写的时候："></a>写的时候：</h5><p>如果多个写程序不加锁同时对文件进行操作，那么最后的数据有可能一部分是a程序写的，一部分是b程序写的<br>如果写的时候加锁了，这个时候有其他的程序来读，那么他会读到什么东西呢？ </p><ol><li>如果读程序没有申请共享锁，那么他会读到dirty的数据。比如写程序要写a,b,c三部分，写完a,这时候读读到的是a，继续写b，这时候读读到的是ab，然后写c，这时候读到的是abc. </li><li>如果读程序在之前申请了共享锁，那么读程序会等写程序将abc写完并释放锁之后才进行读。</li></ol><h5 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h5><p>项目中应该只使用PHP中的文件锁，尽量避免锁表，因为如果表被锁定了，那么整个网站中所有和这个表相关的功能都被拖慢了（例如：前台很多用户一直下订单，商品表mysql锁表，其他与商品表相关的操作一直处于阻塞状态【读不出来商品表】，因为一个功能把整个网站速度拖慢）。</p><blockquote><p> 比如在一个O2O外卖项目中，中午12-2点，晚上6点都是订单高并发时，这种情况下，MySQL锁显然是不考虑的，用户体验太差。其实根据实际的需求，外卖可以不用设计库存量的，当然除了秒杀活动模块还是需要php文件锁的。</p></blockquote><p>应用场景：</p><ol><li>高并发下单时，减库存量时要加锁</li><li>高并发抢单、抢票时要使用</li></ol><p>MySQL锁示例代码：</p><pre><code>&lt;?php /**模拟秒杀活动-- 商品100件CREATE TABLE a(    id int comment &apos;模拟100件活动商品的数量&apos;);INSERT INTO a VALUES(100);模仿：以10的并发量访问这个脚本！    使用apache自带的ab.exe软件 */ error_reporting(0); mysql_connect(&apos;localhost&apos;,&apos;root&apos;,&apos;admin123&apos;); mysql_select_db(&apos;test&apos;); # mysql 锁 mysql_query(&apos;LOCK TABLE a WRITE&apos;);// 只有一个客户端可以锁定表，其他客户端阻塞在这 $rs = mysql_query(&apos;SELECT id FROM a&apos;); $id = mysql_result($rs, 0, 0); if($id &gt; 0) {     --$id;     mysql_query(&apos;UPDATE a SET id=&apos;.$id); } # mysql 解锁 mysql_query(&apos;UNLOCK TABLES&apos;);</code></pre><p>PHP文件锁示例代码：</p><pre><code>&lt;?php /**模拟秒杀活动-- 商品100件CREATE TABLE a(    id int comment &apos;模拟100件活动商品的数量&apos;);INSERT INTO a VALUES(100);模仿：以10的并发量访问这个脚本！    使用apache自带的ab.exe软件 */ error_reporting(0); mysql_connect(&apos;localhost&apos;,&apos;root&apos;,&apos;admin123&apos;); mysql_select_db(&apos;test&apos;); # php中的文件锁 $fp = fopen(&apos;./a.lock&apos;, &apos;r&apos;); // php的文件锁和表没关系，随便一个文件即可 flock($fp, LOCK_EX);// 排他锁 $rs = mysql_query(&apos;SELECT id FROM a&apos;); $id = mysql_result($rs, 0, 0); if($id &gt; 0) {     --$id;     mysql_query(&apos;UPDATE a SET id=&apos;.$id); } # php的文件锁，释放锁 flock($fp, LOCK_UN); fclose($fp);</code></pre><h3 id="MYSQL中的锁："><a href="#MYSQL中的锁：" class="headerlink" title="MYSQL中的锁："></a>MYSQL中的锁：</h3><p>语法 ：<br>LOCK TABLE 表名1 READ|WRITE, 表名2 READ|WRITE ……………… 【锁表】<br>UNLOCK TABLES  【释放表】</p><ul><li>Read:读锁|共享锁 ： 所有的客户端只能读这个表不能写这个表</li><li>Write:写锁|排它锁： 所有当前锁定客户端可以操作这个表，其他客户端只能阻塞</li></ul><blockquote><p>注意：在锁表的过程中只能操作被锁定的表，如果要操作其他表，必须把所有要操作的表都锁定起来！</p></blockquote><h5 id="1-表级锁定（table-level）"><a href="#1-表级锁定（table-level）" class="headerlink" title="1.表级锁定（table-level）"></a>1.表级锁定（table-level）</h5><p>表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并大度大打折扣。使用表级锁定的主要是MyISAM等一些非事务性存储引擎。</p><h5 id="2-行级锁定（row-level）"><a href="#2-行级锁定（row-level）" class="headerlink" title="2.行级锁定（row-level）"></a>2.行级锁定（row-level）</h5><p>行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。<br>虽然能够在并发处理能力上面有较大的优势，但是行级锁定也因此带来了不少弊端。由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。使用行级锁定的主要是InnoDB存储引擎。</p><h5 id="3-页级锁定（page-level）"><a href="#3-页级锁定（page-level）" class="headerlink" title="3.页级锁定（page-level）"></a>3.页级锁定（page-level）</h5><p>页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。<br>在数据库实现资源锁定的过程中，随着锁定资源颗粒度的减小，锁定相同数据量的数据所需要消耗的内存数量是越来越多的，实现算法也会越来越复杂。不过，随着锁定资源颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。</p><h5 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h5><ul><li>表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；  </li><li>行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高；    </li><li>页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。  </li></ul><p>适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。</p><h3 id="二、表级锁定"><a href="#二、表级锁定" class="headerlink" title="二、表级锁定"></a>二、表级锁定</h3><p>在mysql中，MyISAM引擎使用的锁定机制完全是mysql的表级锁定，下面将以MYISAM引擎作为示例</p><h5 id="1-MySQL表级锁的模式"><a href="#1-MySQL表级锁的模式" class="headerlink" title="1.MySQL表级锁的模式"></a>1.MySQL表级锁的模式</h5><blockquote><p>MySQL的表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。  </p></blockquote><ul><li>兼容性：  <ul><li>对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；  </li><li>对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；  </li><li>MyISAM表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。</li></ul></li></ul><h5 id="2-加锁"><a href="#2-加锁" class="headerlink" title="2.加锁"></a>2.加锁</h5><blockquote><p>MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用LOCK TABLE命令给MyISAM表显式加锁。</p></blockquote><h5 id="3-MyISAM锁的优化"><a href="#3-MyISAM锁的优化" class="headerlink" title="3.MyISAM锁的优化"></a>3.MyISAM锁的优化</h5><blockquote><p>对于MyISAM存储引擎，虽然使用表级锁定在锁定实现的过程中比实现行级锁定或者页级锁所带来的附加成本都要小，锁定本身所消耗的资源也是最少。但是由于锁定的颗粒度比较到，所以造成锁定资源的争用情况也会比其他的锁定级别都要多，从而在较大程度上会降低并发处理能力。所以，在优化MyISAM存储引擎锁定问题的时候，最关键的就是如何让其提高并发度。由于锁定级别是不可能改变的了，所以我们首先需要尽可能让锁定的时间变短，然后就是让可能并发进行的操作尽可能的并发。</p></blockquote><ul><li>（1）查询表锁争用情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show status like &apos;table%&apos;;</span><br><span class="line">+----------------------------+---------+</span><br><span class="line">| Variable_name              | Value   |</span><br><span class="line">+----------------------------+---------+</span><br><span class="line">| Table_locks_immediate      | 100     |</span><br><span class="line">| Table_locks_waited         | 11      |</span><br><span class="line">+----------------------------+---------+</span><br></pre></td></tr></table></figure><p>这里有两个状态变量记录MySQL内部表级锁定的情况，两个变量说明如下：</p><ul><li>Table_locks_immediate：产生表级锁定的次数;  </li><li>Table_locks_waited：出现表级锁定争用而发生等待的次数；</li></ul><p>两个状态值都是从系统启动后开始记录，出现一次对应的事件则数量加1。如果这里的Table_locks_waited状态值比较高，那么说明系统中表级锁定争用现象比较严重，就需要进一步分析为什么会有较多的锁定资源争用了</p><ul><li>（2）缩短锁定时间</li></ul><p>如何让锁定时间尽可能的短呢？唯一的办法就是让我们的Query执行时间尽可能的短。</p><pre><code>+ a)尽两减少大的复杂Query，将复杂Query分拆成几个小的Query分布进行；  + b)尽可能的建立足够高效的索引，让数据检索更迅速；  + c)尽量让MyISAM存储引擎的表只存放必要的信息，控制字段类型；  + d)利用合适的机会优化MyISAM表数据文件</code></pre><ul><li>(3)分离并行的操作</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;PHP中的文件锁-（锁的是文件，不是表）&quot;&gt;&lt;a href=&quot;#PHP中的文件锁-（锁的是文件，不是表）&quot; class=&quot;headerlink&quot; title=&quot;PHP中的文件锁 （锁的是文件，不是表）&quot;&gt;&lt;/a&gt;PHP中的文件锁 （锁的是文件，不是表）&lt;/h3&gt;&lt;p&gt;文件锁的文件与表有什么关系？：一点关系也没有，与令牌相似，谁拿到谁操作。所以表根本没锁。&lt;br&gt;测试时，有个文件就行，叫什么名无所谓&lt;/p&gt;
&lt;p&gt;bool flock ( int handle, int operation [, int &amp;amp;wouldblock] );&lt;br&gt;flock() 操作的 handle 必须是一个已经打开的文件指针。operation 可以是以下值之一：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;要取得共享锁定（读取程序），将 operation 设为 LOCK_SH（PHP 4.0.1 以前的版本设置为 1）&lt;/li&gt;
&lt;li&gt;要取得独占锁定（写入程序），将 operation 设为 LOCK_EX（PHP 4.0.1 以前的版本中设置为 2）&lt;/li&gt;
&lt;li&gt;要释放锁定（无论共享或独占），将 operation 设为 LOCK_UN（PHP 4.0.1 以前的版本中设置为 3）&lt;/li&gt;
&lt;li&gt;如果你不希望 flock() 在锁定时堵塞，则给 operation 加上 LOCK_NB（PHP 4.0.1 以前的版本中设置为4）&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>MySQL两种存储引擎- MyISAM和InnoDB 简单总结</title>
    <link href="https://icocos.github.io/2019/05/03/MySQL%E4%B8%A4%E7%A7%8D%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E-%20MyISAM%E5%92%8CInnoDB%20%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93/"/>
    <id>https://icocos.github.io/2019/05/03/MySQL两种存储引擎- MyISAM和InnoDB 简单总结/</id>
    <published>2019-05-03T10:47:41.000Z</published>
    <updated>2019-05-22T09:17:26.545Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。</p></li><li><p>InnoDB，是MySQL的数据库引擎之一，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。</p></li></ul><a id="more"></a><p>MyISAM和InnoDB两者之间有着明显区别，简单梳理如下:</p><h5 id="1-事务支持"><a href="#1-事务支持" class="headerlink" title="1) 事务支持"></a>1) 事务支持</h5><p>MyISAM不支持事务，而InnoDB支持。InnoDB的AUTOCOMMIT默认是打开的，即每条SQL语句会默认被封装成一个事务，自动提交，这样会影响速度，所以最好是把多条SQL语句显示放在begin和commit之间，组成一个事务去提交。</p><p>MyISAM是非事务安全型的，而InnoDB是事务安全型的，默认开启自动提交，宜合并事务，一同提交，减小数据库多次提交导致的开销，大大提高性能。</p><h5 id="2-存储结构"><a href="#2-存储结构" class="headerlink" title="2) 存储结构"></a>2) 存储结构</h5><p>MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。</p><p>InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。</p><h5 id="3-存储空间"><a href="#3-存储空间" class="headerlink" title="3) 存储空间"></a>3) 存储空间</h5><p>MyISAM：可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。</p><p>InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。</p><h5 id="4-可移植性、备份及恢复"><a href="#4-可移植性、备份及恢复" class="headerlink" title="4) 可移植性、备份及恢复"></a>4) 可移植性、备份及恢复</h5><p>MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。</p><p>InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。</p><h5 id="5-事务支持"><a href="#5-事务支持" class="headerlink" title="5) 事务支持"></a>5) 事务支持</h5><p>MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。</p><p>InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。</p><h5 id="6-AUTO-INCREMENT"><a href="#6-AUTO-INCREMENT" class="headerlink" title="6) AUTO_INCREMENT"></a>6) AUTO_INCREMENT</h5><p>MyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。</p><p>InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。</p><h5 id="7-表锁差异"><a href="#7-表锁差异" class="headerlink" title="7) 表锁差异"></a>7) 表锁差异</h5><p>MyISAM：只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。</p><p>InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。</p><p>MyISAM锁的粒度是表级，而InnoDB支持行级锁定。简单来说就是, InnoDB支持数据行锁定，而MyISAM不支持行锁定，只支持锁定整个表。即MyISAM同一个表上的读锁和写锁是互斥的，MyISAM并发读写时如果等待队列中既有读请求又有写请求，默认写请求的优先级高，即使读请求先到，所以MyISAM不适合于有大量查询和修改并存的情况，那样查询进程会长时间阻塞。因为MyISAM是锁表，所以某项读操作比较耗时会使其他写进程饿死。</p><h5 id="8-全文索引"><a href="#8-全文索引" class="headerlink" title="8) 全文索引"></a>8) 全文索引</h5><p>MyISAM：支持(FULLTEXT类型的)全文索引</p><p>InnoDB：不支持(FULLTEXT类型的)全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。</p><p>全文索引是指对char、varchar和text中的每个词（停用词除外）建立倒排序索引。MyISAM的全文索引其实没啥用，因为它不支持中文分词，必须由使用者分词后加入空格再写到数据表里，而且少于4个汉字的词会和停用词一样被忽略掉。</p><blockquote><p>另外，MyIsam索引和数据分离，InnoDB在一起，MyIsam天生非聚簇索引，最多有一个unique的性质，InnoDB的数据文件本身就是主键索引文件，这样的索引被称为“聚簇索引”</p></blockquote><h5 id="9-表主键"><a href="#9-表主键" class="headerlink" title="9) 表主键"></a>9) 表主键</h5><p>MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。</p><p>InnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。InnoDB的主键范围更大，最大是MyISAM的2倍。</p><h5 id="10-表的具体行数"><a href="#10-表的具体行数" class="headerlink" title="10) 表的具体行数"></a>10) 表的具体行数</h5><p>MyISAM：保存有表的总行数，如果select count(*) from table;会直接取出出该值。</p><p>InnoDB：没有保存表的总行数(只能遍历)，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。</p><h5 id="11-CURD操作"><a href="#11-CURD操作" class="headerlink" title="11) CURD操作"></a>11) CURD操作</h5><p>MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。</p><p>InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。</p><h5 id="12-外键"><a href="#12-外键" class="headerlink" title="12) 外键"></a>12) 外键</h5><p>MyISAM：不支持</p><p>InnoDB：支持</p><h5 id="13-查询效率"><a href="#13-查询效率" class="headerlink" title="13) 查询效率"></a>13) 查询效率</h5><p>没有where的count(<em>)使用MyISAM要比InnoDB快得多。因为MyISAM内置了一个计数器，count(</em>)时它直接从计数器中读，而InnoDB必须扫描全表。所以在InnoDB上执行count(<em>)时一般要伴随where，且where中要包含主键以外的索引列。为什么这里特别强调“主键以外”？因为InnoDB中primary index是和raw data存放在一起的，而secondary index则是单独存放，然后有个指针指向primary key。所以只是count(</em>)的话使用secondary index扫描更快，而primary key则主要在扫描索引同时要返回raw data时的作用较大。MyISAM相对简单，所以在效率上要优于InnoDB，小型应用可以考虑使用MyISAM。</p><p>通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储 过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。</p><h3 id="MyISAM和InnoDB两者的应用场景："><a href="#MyISAM和InnoDB两者的应用场景：" class="headerlink" title="MyISAM和InnoDB两者的应用场景："></a>MyISAM和InnoDB两者的应用场景：</h3><ul><li><p>1) MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择。</p></li><li><p>2) InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。</p></li></ul><p>但是实际场景中，针对具体问题需要具体分析，一般而言可以遵循以下几个问题：</p><ul><li>数据库是否有外键？</li><li>是否需要事务支持？</li><li>是否需要全文索引？</li><li>数据库经常使用什么样的查询模式？在写多读少的应用中还是Innodb插入性能更稳定，在并发情况下也能基本，如果是对读取速度要求比较快的应用还是选MyISAM。</li><li>数据库的数据有多大？ 大尺寸倾向于innodb，因为事务日志，故障恢复。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;InnoDB，是MySQL的数据库引擎之一，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>MySQL索引优化策略与笔记</title>
    <link href="https://icocos.github.io/2019/04/29/MySQL%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5%E4%B8%8E%E7%AC%94%E8%AE%B0/"/>
    <id>https://icocos.github.io/2019/04/29/MySQL索引优化策略与笔记/</id>
    <published>2019-04-29T10:47:41.000Z</published>
    <updated>2019-05-27T02:33:41.460Z</updated>
    
    <content type="html"><![CDATA[<p>面试知识，数据库索引优化</p><h4 id="什么问题？"><a href="#什么问题？" class="headerlink" title="什么问题？"></a>什么问题？</h4><pre><code>索引有什么代价？哪些场景下你需要建索引？或者有时候反过来问，哪些场景下不推荐建索引。建好索引之后，怎么才能最高效地利用索引？或者反过来问，请说出一个无法有效利用已建索引的案例。</code></pre><h4 id="索引的好处？"><a href="#索引的好处？" class="headerlink" title="索引的好处？"></a>索引的好处？</h4><blockquote><p>快速查询数据。</p></blockquote><a id="more"></a><h4 id="代价是什么？"><a href="#代价是什么？" class="headerlink" title="代价是什么？"></a>代价是什么？</h4><pre><code>索引需要占硬盘空间，这是空间方面的代价。一旦插入新的数据，就需要重新建索引，这是时间上的代价。</code></pre><h4 id="不同场景，不同对待。"><a href="#不同场景，不同对待。" class="headerlink" title="不同场景，不同对待。"></a>不同场景，不同对待。</h4><h5 id="场景一"><a href="#场景一" class="headerlink" title="场景一"></a>场景一</h5><blockquote><p>数据表规模不大，就几千行，即使不建索引，查询语句的返回时间也不长，这时建索引的意义就不大。当然，若就几千行，索引所占的空间也不多，所以这种情况下，顶多属于“性价比”不高。</p></blockquote><h4 id="场景二"><a href="#场景二" class="headerlink" title="场景二"></a>场景二</h4><blockquote><p> 某个商品表里有几百万条商品信息，同时每天会在一个时间点，往其中更新大概十万条左右的商品信息，现在用where语句查询特定商品时（比如where name = ‘XXX’）速度很慢。为了提升查询效率可以建索引，但当每天更新数据时，又会重建索引，这是要耗费时间的。这时就需要综合考虑，甚至可以在更新前删除索引，更新后再重建。</p></blockquote><h4 id="场景三"><a href="#场景三" class="headerlink" title="场景三"></a>场景三</h4><blockquote><p>因为在数据表里ID值都不相同，所以索引能发挥出比较大的作用。相反，如果某个字段重复率很高，如性别字段，或者某个字段大多数值是空（null），那么不建议对该字段建索引。</p></blockquote><h3 id="建立索引原则"><a href="#建立索引原则" class="headerlink" title="建立索引原则"></a>建立索引原则</h3><p>一定是有业务需求了才会建索引。比如在一个商品表里，我们经常要根据name做查询，如果没有索引，查询速度会很慢，这时就需要建索引。但在项目开发中，如果不经常根据商品编号查询，那么就没必要对编号建索引。</p><p>最后再强调一次，建索引是要付出代价的，没事别乱建着玩，同时在一个表上也不能建太多的索引。<br>具体的例子来看索引的正确用法</p><pre><code>语句一：select name from 商品表。不会用到索引，因为没有where语句。语句二：select * from 商品表 where name = ‘Java书’，会用到索引，如果项目里经常用到name来查询，且商品表的数据量很大，而name值的重复率又不高，那么建议建索引。语句三：select * from 商品表 where name like ‘Java%’ 这是个模糊查询，会用到索引，请大家记住，用like进行模糊查询时，如果第一个就是模糊的匹配符，比如where name like ‘%java’，那么在查询时不会走索引。在其他情况下，不论用了多少个%，也不论%的位置，只要不出现在第一个位置，那么都能用到索引。</code></pre><p>学生成绩表里有两个字段：姓名和成绩。现在对成绩这个整数类型的字段建索引。</p><pre><code>第一种情况，当数字型字段遇到非等值操作符时，无法用到索引。比如：</code></pre><p>​ select name from 学生成绩表 where 成绩&gt;95 , 一旦出现大于符号，就不能用到索引，为了用到索引，我们应该改一下SQL语句里的where从句：where 成绩 in (96,97,98,99,100)</p><pre><code>第二种情况，如果对索引字段进行了某种左值操作，那么无法用到索引。</code></pre><p>​ 能用到索引的写法：select name from 学生成绩表 where 成绩 = 60</p><p>​ 不能用到索引的写法：select name from 学生成绩表 where 成绩+40 = 100</p><pre><code>第三种情况，如果对索引字段进行了函数操作，那么无法用到索引。</code></pre><p>​ 比如SQL语句：select * from 商品表 where substr(name) = ‘J’，我们希望查询商品名首字母是J的记录，可一旦针对name使用函数，即使name字段上有索引，也无法用到。<br>​ </p><blockquote><p>非聚集索引和聚集索引的区别在于， 通过聚集索引可以查到需要查找的数据， 而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。</p></blockquote><p>不管以任何方式查询表， 最终都会利用主键通过聚集索引来定位到数据， 聚集索引（主键）是通往真实数据所在的唯一路径。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;面试知识，数据库索引优化&lt;/p&gt;
&lt;h4 id=&quot;什么问题？&quot;&gt;&lt;a href=&quot;#什么问题？&quot; class=&quot;headerlink&quot; title=&quot;什么问题？&quot;&gt;&lt;/a&gt;什么问题？&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;索引有什么代价？哪些场景下你需要建索引？或者有时候反过来问，哪些场景下不推荐建索引。
建好索引之后，怎么才能最高效地利用索引？或者反过来问，请说出一个无法有效利用已建索引的案例。
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;索引的好处？&quot;&gt;&lt;a href=&quot;#索引的好处？&quot; class=&quot;headerlink&quot; title=&quot;索引的好处？&quot;&gt;&lt;/a&gt;索引的好处？&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;快速查询数据。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>如何处理负载、高并发问题</title>
    <link href="https://icocos.github.io/2019/04/27/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E8%B4%9F%E8%BD%BD%E3%80%81%E9%AB%98%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98/"/>
    <id>https://icocos.github.io/2019/04/27/如何处理负载、高并发问题/</id>
    <published>2019-04-27T10:47:41.000Z</published>
    <updated>2019-05-22T09:07:52.595Z</updated>
    
    <content type="html"><![CDATA[<p>从低成本、高性能和高扩张性的角度来说有如下处理方案：</p><h5 id="1、HTML静态化"><a href="#1、HTML静态化" class="headerlink" title="1、HTML静态化"></a>1、HTML静态化</h5><p>其实大家都知道，效率最高、消耗最小的就是纯静态化的html页面，所以我们尽可能使我们的  网站上的页面采用静态页面来实现，这个最简单的方法其实也是最有效的方法。</p><h5 id="2、图片服务器分离"><a href="#2、图片服务器分离" class="headerlink" title="2、图片服务器分离"></a>2、图片服务器分离</h5><p>​    把图片单独存储，尽量减少图片等大流量的开销，可以放在一些相关的平台上，如骑牛等</p><a id="more"></a><h5 id="3、数据库集群和库表散列及缓存"><a href="#3、数据库集群和库表散列及缓存" class="headerlink" title="3、数据库集群和库表散列及缓存"></a>3、数据库集群和库表散列及缓存</h5><p>数据库的并发连接为100，一台数据库远远不够，可以从读写分离、主从复制，数据库集群方面来着手。另外尽量减少数据库的访问，可以使用缓存数据库如memcache、redis。</p><h5 id="4、镜像："><a href="#4、镜像：" class="headerlink" title="4、镜像："></a>4、镜像：</h5><p>   尽量减少下载，可以把不同的请求分发到多个镜像端。</p><h5 id="5、负载均衡："><a href="#5、负载均衡：" class="headerlink" title="5、负载均衡："></a>5、负载均衡：</h5><p>   Apache的最大并发连接为1500，只能增加服务器，可以从硬件上着手，如F5服务器。当然硬件的成本比较高，我们往往从软件方面着手。</p><p>   负载均衡 （Load Balancing） 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力，同时能够提高网络的灵活性和可用性。目前使用最为广泛的负载均衡软件是Nginx、LVS、HAProxy。我分别来说下三种的优缺点:</p><h5 id="Nginx的优点是："><a href="#Nginx的优点是：" class="headerlink" title="Nginx的优点是："></a>Nginx的优点是：</h5><ol><li><p>工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，Nginx单凭这点可利用的场合就远多于LVS了。 </p></li><li><p>Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大，这点本人深有体会； </p></li><li><p>Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。 </p></li><li><p>可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。 </p></li><li><p>Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。 </p></li><li><p>Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。 </p></li><li><p>Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。 </p></li><li><p>Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有 lighttpd了，不过 lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃。 </p></li><li><p>Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。</p></li></ol><h5 id="Nginx的缺点是："><a href="#Nginx的缺点是：" class="headerlink" title="Nginx的缺点是："></a>Nginx的缺点是：</h5><ol><li>Nginx仅能支持http、https和Email协议，这样就在适用范围上面小些，这个是它的缺点。</li><li>对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。</li></ol><h4 id="LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability-、可靠性（Reliability-和可管理性（Manageability-。"><a href="#LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability-、可靠性（Reliability-和可管理性（Manageability-。" class="headerlink" title="LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。"></a>LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。</h4><h5 id="LVS的优点是："><a href="#LVS的优点是：" class="headerlink" title="LVS的优点是："></a>LVS的优点是：</h5><ol><li>抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低。</li><li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。</li><li>工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived。</li><li>无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会受到大流量的影响。</li><li>应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等。</li></ol><h5 id="LVS的缺点是："><a href="#LVS的缺点是：" class="headerlink" title="LVS的缺点是："></a>LVS的缺点是：</h5><ol><li>软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。</li><li>如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。</li></ol><h5 id="HAProxy的特点是："><a href="#HAProxy的特点是：" class="headerlink" title="HAProxy的特点是："></a>HAProxy的特点是：</h5><ol><li>HAProxy也是支持虚拟主机的。</li><li>HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态。</li><li>HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。</li><li>HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，大家可以用LVS+Keepalived对MySQL主从做负载均衡。</li><li>HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：</li></ol><p>① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；<br>② static-rr，表示根据权重，建议关注；<br>③ leastconn，表示最少连接者先处理，建议关注；<br>④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；<br>⑤ ri，表示根据请求的URI；<br>⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parametername；<br>⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；<br>⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。</p><h5 id="Nginx和LVS对比的总结："><a href="#Nginx和LVS对比的总结：" class="headerlink" title="Nginx和LVS对比的总结："></a>Nginx和LVS对比的总结：</h5><ol><li><p>Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所以Nginx单凭这点可利用的场合就远多于LVS了；但Nginx有用的这些功能使其可调整度要高于LVS，所以经常要去触碰触碰，触碰多了，人为出问题的几率也就会大。   </p></li><li><p>Nginx对网络稳定性的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，这是Nginx的一大优势！Nginx同时还能区分内外网，如果是同时拥有内外网的节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。</p></li><li><p>Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了；LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。 </p></li><li><p>Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的。 </p></li><li><p>Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而恼火。 </p></li><li><p>Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用 apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相当多的资源占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。 </p></li><li><p>Nginx能支持http、https和email（email的功能比较少用），LVS所支持的应用在这点上会比Nginx更多。在使用上，一般最前端所采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给 LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得具体分析，如果是比较小的网站（日PV小于1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从低成本、高性能和高扩张性的角度来说有如下处理方案：&lt;/p&gt;
&lt;h5 id=&quot;1、HTML静态化&quot;&gt;&lt;a href=&quot;#1、HTML静态化&quot; class=&quot;headerlink&quot; title=&quot;1、HTML静态化&quot;&gt;&lt;/a&gt;1、HTML静态化&lt;/h5&gt;&lt;p&gt;其实大家都知道，效率最高、消耗最小的就是纯静态化的html页面，所以我们尽可能使我们的  网站上的页面采用静态页面来实现，这个最简单的方法其实也是最有效的方法。&lt;/p&gt;
&lt;h5 id=&quot;2、图片服务器分离&quot;&gt;&lt;a href=&quot;#2、图片服务器分离&quot; class=&quot;headerlink&quot; title=&quot;2、图片服务器分离&quot;&gt;&lt;/a&gt;2、图片服务器分离&lt;/h5&gt;&lt;p&gt;​    把图片单独存储，尽量减少图片等大流量的开销，可以放在一些相关的平台上，如骑牛等&lt;/p&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="高负载" scheme="https://icocos.github.io/tags/%E9%AB%98%E8%B4%9F%E8%BD%BD/"/>
    
      <category term="高并发" scheme="https://icocos.github.io/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>MYSQL 事务处理常见有两种方法</title>
    <link href="https://icocos.github.io/2019/04/26/MYSQL%20%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%E5%B8%B8%E8%A7%81%E6%9C%89%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <id>https://icocos.github.io/2019/04/26/MYSQL 事务处理常见有两种方法/</id>
    <published>2019-04-26T10:47:41.000Z</published>
    <updated>2019-05-22T09:17:25.529Z</updated>
    
    <content type="html"><![CDATA[<p> MYSQL在操作大量的数据或者比较重要的数据的时候，事务处理很重要，比如银行的转账，支付，等等，作为开发人员事务是必须的一步。</p><h5 id="1、用-BEGIN-ROLLBACK-COMMIT来实现"><a href="#1、用-BEGIN-ROLLBACK-COMMIT来实现" class="headerlink" title="1、用 BEGIN, ROLLBACK, COMMIT来实现"></a>1、用 BEGIN, ROLLBACK, COMMIT来实现</h5><ul><li>BEGIN 开始一个事务</li><li>ROLLBACK 事务回滚</li><li>COMMIT 事务确认</li></ul><a id="more"></a><h5 id="2、直接用-SET-来改变-MySQL-的自动提交模式"><a href="#2、直接用-SET-来改变-MySQL-的自动提交模式" class="headerlink" title="2、直接用 SET 来改变 MySQL 的自动提交模式:"></a>2、直接用 SET 来改变 MySQL 的自动提交模式:</h5><ul><li>SET AUTOCOMMIT=0 禁止自动提交</li><li>SET AUTOCOMMIT=1 开启自动提交</li></ul><blockquote><p>注意的是，在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。</p></blockquote><p>MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！</p><h3 id="一、php事务处理概述："><a href="#一、php事务处理概述：" class="headerlink" title="一、php事务处理概述："></a>一、php事务处理概述：</h3><ul><li><p>事务:是若干事件的集合</p></li><li><p>事务处理:当所有事件执行成功,事务才执行;若有任何一个事件不能成功执行,事务的其它事件也不被执行。</p></li></ul><p>只要你的MySQL版本支持BDB或InnoDB表类型，那么你的MySQL就具有事务处理的能力。这里面，又以InnoDB表类型用的最多，虽然后来发生了诸如Oracle收购InnoDB等令MySQL不爽的事情，但是这类商业事件与技术无关，下面就以InnoDB表类型为例简单说一下MySQL中的事务处理。</p><h3 id="二、php事务处理代码："><a href="#二、php事务处理代码：" class="headerlink" title="二、php事务处理代码："></a>二、php事务处理代码：</h3><pre><code>&lt;?phptry{$pdo=new PDO(&quot;mysql:host=localhost;dbname=psp&quot;,&quot;root&quot;,&quot;&quot;);$pdo-&gt;exec(&quot;set names utf8&quot;);$pdo-&gt;setAttribute(PDO::ATTR_ERRMODE,PDO::ERRMODE_EXCEPTION);//设置异常处理模式$pdo-&gt;setAttribute(PDO::ATTR_AUTOCOMMIT,0);//关闭自动提交}catch(PDOException $e){echo &quot;数据库连接失败&quot;;exit;}try{$age=10;$pdo-&gt;beginTransaction();//开始事务$affected_rows1=$pdo-&gt;exec(&quot;update kfry set k_age=k_age+{$age} where k_name=&apos;user1&apos;&quot;);$affected_rows2=$pdo-&gt;exec(&quot;update kfry set k_age=k_age-{$age} where k_name=&apos;user2&apos;&quot;);//随意更改使之执行成功或失败/* if($affected_rows1&amp;&amp;$affected_rows2){$pdo-&gt;commit();echo &quot;操作成功&quot;;}else{$pdo-&gt;rollback();} */if(!$affected_rows1)throw new PDOException(&quot;加入错误&quot;);if(!$affected_rows2)throw new PDOException(&quot;减少错误&quot;);echo &quot;操作成功&quot;;$pdo-&gt;commit();//如果执行到此处前面两个更新sql语句执行成功，整个事务执行成功}catch(PDOException $e){echo &quot;操作失败：&quot;.$e-&gt;getMessage();$pdo-&gt;rollback();//执行事务中的语句出了问题，整个事务全部撤销}$pdo-&gt;setAttribute(PDO::ATTR_AUTOCOMMIT,1);//测试是否成功echo &quot;\n操作结果为:\n&quot;;$sql=&quot;select * from kfry&quot;;$result=$pdo-&gt;query($sql);foreach($result as $v){echo $v[&apos;k_name&apos;].&quot; &quot;.$v[&apos;k_age&apos;].&quot;\n&quot;;}?&gt;</code></pre><p>以上就是php 事务处理详解的详细内容，更多请关注php中文网其它相关文章！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt; MYSQL在操作大量的数据或者比较重要的数据的时候，事务处理很重要，比如银行的转账，支付，等等，作为开发人员事务是必须的一步。&lt;/p&gt;
&lt;h5 id=&quot;1、用-BEGIN-ROLLBACK-COMMIT来实现&quot;&gt;&lt;a href=&quot;#1、用-BEGIN-ROLLBACK-COMMIT来实现&quot; class=&quot;headerlink&quot; title=&quot;1、用 BEGIN, ROLLBACK, COMMIT来实现&quot;&gt;&lt;/a&gt;1、用 BEGIN, ROLLBACK, COMMIT来实现&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;BEGIN 开始一个事务&lt;/li&gt;
&lt;li&gt;ROLLBACK 事务回滚&lt;/li&gt;
&lt;li&gt;COMMIT 事务确认&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>Web安全的一次探讨</title>
    <link href="https://icocos.github.io/2019/03/13/Web%E5%AE%89%E5%85%A8%E7%9A%84%E4%B8%80%E6%AC%A1%E6%8E%A2%E8%AE%A8/"/>
    <id>https://icocos.github.io/2019/03/13/Web安全的一次探讨/</id>
    <published>2019-03-13T04:14:14.000Z</published>
    <updated>2019-05-22T09:17:14.833Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、SQL注入攻击-SQL-Injection"><a href="#一、SQL注入攻击-SQL-Injection" class="headerlink" title="一、SQL注入攻击(SQL Injection)"></a>一、SQL注入攻击(SQL Injection)</h3><p>攻击者把sql命令插入到web表单的输入域或页面请求的字符串，欺骗服务器执行恶意的sql命令。常见的sql注入攻击类似：</p><h5 id="登录页面中输入内容直接用来构造动态的sql语句，例如："><a href="#登录页面中输入内容直接用来构造动态的sql语句，例如：" class="headerlink" title="登录页面中输入内容直接用来构造动态的sql语句，例如："></a>登录页面中输入内容直接用来构造动态的sql语句，例如：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$query = &apos;select * from users where login = &apos;. $username. &apos;and password = &apos;. $password;</span><br></pre></td></tr></table></figure><a id="more"></a><p>攻击者如果在用户名或者密码框输入<code>or &#39;1&#39; =1</code>，这样我们执行的sql语句就变成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from users where login = &apos;&apos; or &apos;1&apos; = 1 and ...</span><br></pre></td></tr></table></figure><p>这样就绕过了我们的登录验证。类似的还有很多，用户通过输入恶意的sql命令来绕过我们的验证，欺骗我们的系统。</p><h5 id="防范的方法："><a href="#防范的方法：" class="headerlink" title="防范的方法："></a>防范的方法：</h5><ol><li>检查变量数据类型和格式</li><li>过滤特殊的符号</li><li>绑定变量，使用预处理语句（当我们绑定变量的时候，就算有特殊字符sql也会认为是个变量而不是sql命令）</li></ol><h3 id="二、跨站脚本攻击-Cross-Site-Scripting-XSS；因为CSS被用了所以叫XSS"><a href="#二、跨站脚本攻击-Cross-Site-Scripting-XSS；因为CSS被用了所以叫XSS" class="headerlink" title="二、跨站脚本攻击(Cross Site Scripting, XSS；因为CSS被用了所以叫XSS)"></a>二、跨站脚本攻击(Cross Site Scripting, XSS；因为CSS被用了所以叫XSS)</h3><p>攻击者将恶意代码注入到网页上，其他用户在加载网页时就会执行代码，攻击者可能会得到各种私密的信息，如cookie等。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">    echo &apos;你好！&apos;.$_GET[&apos;name&apos;];</span><br></pre></td></tr></table></figure><p>如果用户传入一段脚本<code>&lt;script&gt;[code]&lt;/script&gt;</code>，那么脚本也会执行，如果code的内容是获取到cookie并发送到某个指定的位置，获取了敏感的信息。亦或是利用用户的身份去执行一些不正当的操作。</p><h5 id="防范的方法：-1"><a href="#防范的方法：-1" class="headerlink" title="防范的方法："></a>防范的方法：</h5><ol><li>输出的时候过滤特殊的字符，转换成html编码，过滤输出的变量（PHP可以使用htmlspecialchars）</li></ol><h3 id="三、跨站请求伪造攻击-Cross-Site-Request-Forgeries-CSRF"><a href="#三、跨站请求伪造攻击-Cross-Site-Request-Forgeries-CSRF" class="headerlink" title="三、跨站请求伪造攻击(Cross Site Request Forgeries, CSRF)"></a>三、跨站请求伪造攻击(Cross Site Request Forgeries, CSRF)</h3><p>攻击者伪造目标用户的HTTP请求，然后此请求发送到有CSRF漏洞的网站，网站执行此请求后，引发跨站请求伪造攻击。攻击者利用隐蔽的HTTP连接，让目标用户在不注意的情况下单击这个链接，由于是用户自己点击的，而他又是合法用户拥有合法权限，所以目标用户能够在网站内执行特定的HTTP链接，从而达到攻击者的目的。  </p><blockquote><p>  用户刚刚登陆了银行A网站，建立了会话，A网站可以进行转账操作<code>http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000</code>在没有退出的情况下去访问危险网站B网站，B网站有一个图片是这样的<code>&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt;</code>，不小心点了B网站，用户发现账上少了1000块。  </p></blockquote><p>可能有人会说，修改操作并不会用get请求。那么假设银行A网站的表单如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;form action=&quot;Transfer.php&quot; method=&quot;POST&quot;&gt;</span><br><span class="line">    &lt;p&gt;ToBankId: &lt;input type=&quot;text&quot; name=&quot;toBankId&quot; /&gt;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;Money: &lt;input type=&quot;text&quot; name=&quot;money&quot; /&gt;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;&lt;input type=&quot;submit&quot; value=&quot;Transfer&quot; /&gt;&lt;/p&gt;</span><br><span class="line">&lt;/form&gt;</span><br></pre></td></tr></table></figure><p>后台处理页面如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">session_start();</span><br><span class="line">if (isset($_REQUEST[&apos;toBankId&apos;] &amp;&amp; isset($_POST[&apos;money&apos;]))</span><br><span class="line">&#123;</span><br><span class="line">    buy_stocks($_REQUEST[&apos;toBankId&apos;],$_REQUEST[&apos;money&apos;]);</span><br><span class="line">&#125;</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure><p>B网站这时候也相应的改了代码:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">　　　　&lt;script type=&quot;text/javascript&quot;&gt;</span><br><span class="line">　　　　　　function steal()</span><br><span class="line">　　　　　　&#123;</span><br><span class="line">          　　　　 iframe = document.frames[&quot;steal&quot;];</span><br><span class="line">　　     　　      iframe.document.Submit(&quot;transfer&quot;);</span><br><span class="line">　　　　　　&#125;</span><br><span class="line">　　　　&lt;/script&gt;</span><br><span class="line">　　&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">　　&lt;body onload=&quot;steal()&quot;&gt;</span><br><span class="line">　　　　&lt;iframe name=&quot;steal&quot; display=&quot;none&quot;&gt;</span><br><span class="line">　　　　　　&lt;form method=&quot;POST&quot; name=&quot;transfer&quot;　action=&quot;http://www.myBank.com/Transfer.php&quot;&gt;</span><br><span class="line">　　　　　　　　&lt;input type=&quot;hidden&quot; name=&quot;toBankId&quot; value=&quot;11&quot;&gt;</span><br><span class="line">　　　　　　　　&lt;input type=&quot;hidden&quot; name=&quot;money&quot; value=&quot;1000&quot;&gt;</span><br><span class="line">　　　　　　&lt;/form&gt;</span><br><span class="line">　　　　&lt;/iframe&gt;</span><br><span class="line">　　&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>用户一点到B网站，发现又少了1000块…….</p><h5 id="防范方法："><a href="#防范方法：" class="headerlink" title="防范方法："></a>防范方法：</h5><ul><li>对表单进行cookie hash校验，将一个随机值的hash写入cookie，每次提交表单，都在服务端对这个hash进行校验（建立在用户的cookie没有被盗取）</li></ul><h3 id="四、Session固定攻击-Session-Fixation"><a href="#四、Session固定攻击-Session-Fixation" class="headerlink" title="四、Session固定攻击(Session Fixation)"></a>四、Session固定攻击(Session Fixation)</h3><p>攻击者预先设定session id，让合法用户使用这个session id来访问被攻击的应用程序，一旦用户的会话ID被成功固定，攻击者就可以通过此session id来冒充用户访问应用程序。例如：  </p><ol><li>攻击者先访问目标网站，获得了自己的session_id，如SID=123</li><li>攻击者给目标用户发送链接，并带上了自己的session_id，如<code>http:///www.bank.com/?SID=123</code>，</li><li>目标用户点击了<code>http:///www.bank.com/?SID=123</code>，输入用户名密码登录，由于session_id不会变更，那么攻击者就可以通过访问<code>http:///www.bank.com/?SID=123</code>来获取目标用户的身份。</li></ol><h5 id="防范方法：-1"><a href="#防范方法：-1" class="headerlink" title="防范方法："></a>防范方法：</h5><ol><li>定期更改session_id</li><li>更改session_id的名字</li></ol><h3 id="五、Session劫持-Session-Hijacking"><a href="#五、Session劫持-Session-Hijacking" class="headerlink" title="五、Session劫持(Session Hijacking)"></a>五、Session劫持(Session Hijacking)</h3><p>攻击者利用各种手段来获取目标用户的session id。一旦获取到session id，那么攻击者可以利用目标用户的身份来登录网站，获取目标用户的操作权限。</p><h5 id="攻击者获取目标用户session-id的方法"><a href="#攻击者获取目标用户session-id的方法" class="headerlink" title="攻击者获取目标用户session id的方法:"></a>攻击者获取目标用户session id的方法:</h5><ol><li>暴力破解:尝试各种session id，直到破解为止;</li><li>计算:如果session id使用非随机的方式产生，那么就有可能计算出来;</li><li>窃取:使用网络截获，xss攻击等方法获得<br>防范方法：</li><li>定期更改session id</li><li>更改session的名称</li><li>关闭透明化session id</li><li>设置HttpOnly。通过设置Cookie的HttpOnly为true，可以防止客户端脚本访问这个Cookie，从而有效的防止XSS攻击。</li></ol><h3 id="六、文件上传漏洞-File-Upload-Attack"><a href="#六、文件上传漏洞-File-Upload-Attack" class="headerlink" title="六、文件上传漏洞(File Upload Attack)"></a>六、文件上传漏洞(File Upload Attack)</h3><p>攻击者利用程序缺陷绕过系统对文件的验证与处理策略将恶意代码上传到服务器并获得执行服务器端命令的能力。  </p><h5 id="常用的攻击手段有："><a href="#常用的攻击手段有：" class="headerlink" title="常用的攻击手段有："></a>常用的攻击手段有：</h5><ol><li>上传Web脚本代码，Web容器解释执行上传的恶意脚本；</li><li>上传Flash跨域策略文件crossdomain.xml，修改访问权限(其他策略文件利用方式类似)；</li><li>上传病毒、木马文件，诱骗用户和管理员下载执行；</li><li>上传包含脚本的图片，某些浏览器的低级版本会执行该脚本，用于钓鱼和欺诈。<br>总的来说，利用的上传文件要么具备可执行能力(恶意代码)，要么具备影响服务器行为的能力(配置文件)。<br>防范方法：  </li><li>文件上传的目录设置为不可执行；</li><li>判断文件类型，设置白名单。对于图片的处理，可以使用压缩函数或者resize函数，在处理图片的同时破坏图片中可能包含的HTML代码；</li><li>使用随机数改写文件名和文件路径：一个是上传后无法访问；再来就是像shell、.php 、.rar和crossdomain.xml这种文件，都将因为重命名而无法攻击；</li><li>单独设置文件服务器的域名：由于浏览器同源策略的关系，一系列客户端攻击将失效，比如上传crossdomain.xml、上传包含Javascript的XSS利用等问题将得到解决。</li></ol><h3 id="MYSQL安全"><a href="#MYSQL安全" class="headerlink" title="MYSQL安全"></a>MYSQL安全</h3><ol><li>使用预处理语句防止sql注入</li><li>写入数据库的数据要进行特殊字符转义</li><li>查询的错误信息不要返回给用户，将错误记录到日志   </li><li>定期做数据库备份</li><li>不给查询用户root权限，合理分配权限</li><li>关闭远程访问数据库的权限</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、SQL注入攻击-SQL-Injection&quot;&gt;&lt;a href=&quot;#一、SQL注入攻击-SQL-Injection&quot; class=&quot;headerlink&quot; title=&quot;一、SQL注入攻击(SQL Injection)&quot;&gt;&lt;/a&gt;一、SQL注入攻击(SQL Injection)&lt;/h3&gt;&lt;p&gt;攻击者把sql命令插入到web表单的输入域或页面请求的字符串，欺骗服务器执行恶意的sql命令。常见的sql注入攻击类似：&lt;/p&gt;
&lt;h5 id=&quot;登录页面中输入内容直接用来构造动态的sql语句，例如：&quot;&gt;&lt;a href=&quot;#登录页面中输入内容直接用来构造动态的sql语句，例如：&quot; class=&quot;headerlink&quot; title=&quot;登录页面中输入内容直接用来构造动态的sql语句，例如：&quot;&gt;&lt;/a&gt;登录页面中输入内容直接用来构造动态的sql语句，例如：&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$query = &amp;apos;select * from users where login = &amp;apos;. $username. &amp;apos;and password = &amp;apos;. $password;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>关于mysql最左前缀原则</title>
    <link href="https://icocos.github.io/2019/03/01/%E5%85%B3%E4%BA%8Emysql%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E5%8E%9F%E5%88%99/"/>
    <id>https://icocos.github.io/2019/03/01/关于mysql最左前缀原则/</id>
    <published>2019-03-01T10:47:41.000Z</published>
    <updated>2019-05-22T09:06:40.679Z</updated>
    
    <content type="html"><![CDATA[<h4 id="背景知识："><a href="#背景知识：" class="headerlink" title="背景知识："></a>背景知识：</h4><ol><li>mysql中可以使用explain关键字来查看sql语句的执行计划。</li><li>最左前缀原则主要使用在联合索引中</li><li>数据库版本Mysql5.5.53</li></ol><a id="more"></a><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>mysql建立多列索引（联合索引）有最左前缀的原则，即最左优先，如：</p><ul><li>如果有一个2列的索引(col1,col2),则已经对(col1)、(col1,col2)上建立了索引；</li><li>如果有一个3列索引(col1,col2,col3)，则已经对(col1)、(col1,col2)、(col1,col2,col3)上建立了索引；</li></ul><p>1、b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道第一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。</p><p>2、比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。（这种情况无法用到联合索引）</p><p>关于最左前缀的使用，有下面两条说明：</p><ul><li>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a  = 1 and b = 2 and c &gt; 3 and d = 4  如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</li><li>=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式</li></ul><p>联合索引有一个最左前缀原则，所以建立联合索引的时候，这个联合索引的字段顺序非常重要</p><p>下面写了例子说明这个：</p><pre><code>CREATE TABLE `test_myisam` (`id` int(11) NOT NULL AUTO_INCREMENT,`conference_id` varchar(200) NOT NULL,`account` varchar(100) DEFAULT NULL,`status` int(2) DEFAULT NULL COMMENT &apos;0:invite,  1:cancel_invite,  2:decline,  3:connect&apos;,`duration` bigint(20) unsigned DEFAULT NULL,`create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,PRIMARY KEY (`id`)) ENGINE=myisam AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;</code></pre><p>以上表结构，我想通过三列进行查询 account ,status,create_time进行查询统计。</p><h5 id="如何建立索引？"><a href="#如何建立索引？" class="headerlink" title="如何建立索引？"></a>如何建立索引？</h5><p>因为我们有可能按照acccount单独统计，或者按照account status，或者是account，status，create_time进行统计，如何建立索引？？？</p><p>下面是建立索引前后的对比600万数据</p><p>如何生成：执行如下脚本，account和日期不同还有status不同，分别生成一百万。</p><pre><code>CREATE  PROCEDURE `add_data_myisam_cp_27`()begindeclare v_rows int(10) default 1000000;declare v_count int(10) default 0;id_loop:LOOPinsert into test_myisam values(null,round(rand()*1000000000),&apos;cloudp&apos;,round(rand()*3),round(rand()*100000),&apos;2016-07-27 00:00:22&apos;);set v_count= v_count + 1;if v_count&gt;v_rows thenleave id_loop;end if;end loop id_loop;end;</code></pre><p>测试结果利用建立的索引性能提高了三倍：</p><pre><code>MariaDB [prf]&gt; select count(1) from test_myisam where account=&apos;cloudp&apos; and status =3 and date(create_time)=&apos;2016-07-27&apos;;+----------+| count(1) |+----------+|   167400 |+----------+1 row in set (1.28 sec)MariaDB [prf]&gt; create index as_index on test_myisam(account,status,create_time);Query OK, 6000006 rows affected (31.60 sec)Records: 6000006  Duplicates: 0  Warnings: 0MariaDB [prf]&gt; select count(1) from test_myisam where account=&apos;cloudp&apos; and status =3 and date(create_time)=&apos;2016-07-27&apos;;+----------+| count(1) |+----------+|   167400 |+----------+1 row in set (0.42 sec)MariaDB [prf]&gt; explain select count(1) from test_myisam where account=&apos;cloudp&apos; and status =3 and date(create_time)=&apos;2016-07-27&apos;;+------+-------------+-------------+------+---------------+----------+---------+-------------+--------+--------------------------+| id   | select_type | table       | type | possible_keys | key      | key_len | ref         | rows   | Extra                    |+------+-------------+-------------+------+---------------+----------+---------+-------------+--------+--------------------------+|    1 | SIMPLE      | test_myisam | ref  | as_index      | as_index | 308     | const,const | 520216 | Using where; Using index |+------+-------------+-------------+------+---------------+----------+---------+-------------+--------+--------------------------+1 row in set (0.00 sec)</code></pre><p>从1.28秒下降到0.42秒<br>但是这个date(create_time)会对每一列都会转换后对比，这里会比较消耗性能；</p><h5 id="如何利用上索引？？"><a href="#如何利用上索引？？" class="headerlink" title="如何利用上索引？？"></a>如何利用上索引？？</h5><p>修改为：</p><pre><code>MariaDB [prf]&gt; explain select count(1) from test_myisam where account=&apos;cloudp&apos; and status =3 and date(create_time)=&apos;2016-07-27&apos;;+------+-------------+-------------+------+---------------+----------+---------+-------------+--------+--------------------------+| id   | select_type | table       | type | possible_keys | key      | key_len | ref         | rows   | Extra                    |+------+-------------+-------------+------+---------------+----------+---------+-------------+--------+--------------------------+|    1 | SIMPLE      | test_myisam | ref  | as_index      | as_index | 308     | const,const | 520216 | Using where; Using index |+------+-------------+-------------+------+---------------+----------+---------+-------------+--------+--------------------------+1 row in set (0.00 sec)MariaDB [prf]&gt; select count(1) from test_myisam where account=&apos;cloudp&apos; and status =3 and create_time  between &apos;2016-07-27&apos; and &apos;2016-07-28&apos;;+----------+| count(1) |+----------+|   167400 |+----------+1 row in set (0.15 sec)MariaDB [prf]&gt; explain select count(1) from test_myisam where account=&apos;cloudp&apos; and status =3 and create_time  between &apos;2016-07-27&apos; and &apos;2016-07-28&apos;;+------+-------------+-------------+-------+---------------+----------+---------+------+--------+--------------------------+| id   | select_type | table       | type  | possible_keys | key      | key_len | ref  | rows   | Extra                    |+------+-------------+-------------+-------+---------------+----------+---------+------+--------+--------------------------+|    1 | SIMPLE      | test_myisam | range | as_index      | as_index | 312     | NULL | 174152 | Using where; Using index |+------+-------------+-------------+-------+---------------+----------+---------+------+--------+--------------------------+1 row in set (0.00 sec)</code></pre><p>如上效率又提高了三倍，是因为扫描的数据行数减少了，最后一个create_time如果不用索引需要扫描52016行，如果使用了索引扫描174152行，命中的行数为：167400行，命中率非常高了。</p><h5 id="这里有个疑问："><a href="#这里有个疑问：" class="headerlink" title="这里有个疑问："></a>这里有个疑问：</h5><blockquote><p> 如果按照天进行统计，create_time作为联合索引的第一列，如何使用上这个索引呢？？？？</p></blockquote><p>至今没有想清楚，如果这一列是date类型可以直接用上索引，如果在oracle中可以date(create_time)建立函数式索引。但是mysql貌似不支持函数式索引。</p><h5 id="一个解决方式是："><a href="#一个解决方式是：" class="headerlink" title="一个解决方式是："></a>一个解决方式是：</h5><blockquote><p>create_time定义为 date类型，在每一列存入的时候，通过触发器自动把这一行修改为date类型。</p></blockquote><p>如果有好的注意欢迎留言探讨，目前没有好的方式加上create_time，可以从业务上解决，就是每天的统计计算完成以后，直接把数据推到历史表中，统计结果单独存放。</p><h5 id="最后说一下关于索引失效的问题："><a href="#最后说一下关于索引失效的问题：" class="headerlink" title="最后说一下关于索引失效的问题："></a>最后说一下关于索引失效的问题：</h5><ol><li>如果条件中有or，即使其中有条件带索引也不会使用(<strong>这也是为什么尽量少用or的原因</strong>)。<strong>注意：要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引</strong></li><li>对于多列索引，不是使用的第一部分，则不会使用索引（即不符合最左前缀原则）</li><li>like查询是以%开头</li><li>如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引</li><li>如果mysql估计使用全表扫描要比使用索引快,则不使用索引</li></ol><h6 id="此外，查看索引的使用情况"><a href="#此外，查看索引的使用情况" class="headerlink" title="此外，查看索引的使用情况"></a>此外，查看索引的使用情况</h6><ul><li><p>show status like ‘Handler_read%’;</p></li><li><p>handler_read_key:这个值越高越好，越高表示使用索引查询到的次数</p></li><li>handler_read_rnd_next:这个值越高，说明查询低效</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;背景知识：&quot;&gt;&lt;a href=&quot;#背景知识：&quot; class=&quot;headerlink&quot; title=&quot;背景知识：&quot;&gt;&lt;/a&gt;背景知识：&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;mysql中可以使用explain关键字来查看sql语句的执行计划。&lt;/li&gt;
&lt;li&gt;最左前缀原则主要使用在联合索引中&lt;/li&gt;
&lt;li&gt;数据库版本Mysql5.5.53&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="MySQL" scheme="https://icocos.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://icocos.github.io/tags/MySQL/"/>
    
      <category term="最佳左前缀" scheme="https://icocos.github.io/tags/%E6%9C%80%E4%BD%B3%E5%B7%A6%E5%89%8D%E7%BC%80/"/>
    
  </entry>
  
  <entry>
    <title>高并发大流解决量方案</title>
    <link href="https://icocos.github.io/2019/02/17/%E9%AB%98%E5%B9%B6%E5%8F%91%E5%A4%A7%E6%B5%81%E8%A7%A3%E5%86%B3%E9%87%8F%E6%96%B9%E6%A1%88/"/>
    <id>https://icocos.github.io/2019/02/17/高并发大流解决量方案/</id>
    <published>2019-02-17T04:14:14.000Z</published>
    <updated>2019-05-22T09:17:27.845Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h3><ul><li>QPS:每秒钟请求或者查询的数量，通常是指每秒相应请求数（http）<ul><li>QPS不等于并发连接数，QPS是每秒的HTTP请求数量，并发连接数是指系统同时处理的请求数量  </li><li>峰值的每秒请求数（QPS）= (总PV数 <em> 80%)/(6小时秒数 </em> 20%)  </li><li>峰值QPS的计算规律主要是80%的访问量集中在20%的访问时间</li></ul></li><li>吞吐量：单位时间内处理请求的数量</li><li>响应时间：从请求发出到收到响应花费的时间</li><li>PV(page view)综合浏览量，即页面点击数。通常日PV在千万级就是高并发的网站</li><li>UV(unique visitor)独立访客，一定时间内相同访客访问网站，只计算为1个独立访客</li></ul><a id="more"></a><ul><li><p>带宽：计算带宽大小，我们需要关注两个指标，峰值流量和平均大小</p><blockquote><p>日网站的带宽 = PV/统计时间（秒） <em> 平均页面大小（KB） </em> 8  </p></blockquote></li><li><p>压力测试</p><ul><li>1.测试能承受的最大并发  </li><li>2.测试最大承受QPS值  </li></ul></li></ul><h5 id="ab-apache-benchmark-工具使用"><a href="#ab-apache-benchmark-工具使用" class="headerlink" title="ab(apache benchmark)工具使用:"></a>ab(apache benchmark)工具使用:</h5><p>ab会创建多个并发访问线程，模拟多个访问者同时对一个URL地址进行访问。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ab的基本使用</span><br><span class="line">ab -c 100 -n 5000 url</span><br><span class="line">并发请求100次，总共5000次</span><br><span class="line"></span><br><span class="line">测试时注意被测试机器的CPU、内存、网络都不超过最高限度的75%</span><br></pre></td></tr></table></figure><p>此处介绍一些QPS的数值：</p><ol><li>50：小型网站，一般服务器即可应付</li><li>100：假设数据库每次请求都在0.01秒内完成，单个页面只有一个sql，100QPS意味着1秒钟要完成100次请求，但是我们数据库不一定能完成100次查询。此时优化方案为：数据库缓存、数据库负载均衡</li><li>800：假设网站有百兆带宽，意味着实际出口的带宽为8M左右，如果每个页面只有10K，在这个QPS下，带宽已经吃完。此时的方案：CDN加速，负载均衡</li><li>1000： 假设使用nosql来缓存数据库查询（memcache或redis），每个页面对nosql的请求远大于直接对DB的请求</li><li>2000： 业务分离，做分布式存储</li></ol><h3 id="二、优化方案"><a href="#二、优化方案" class="headerlink" title="二、优化方案"></a>二、优化方案</h3><ul><li>流量优化：  </li></ul><ol><li>防盗链处理 </li><li>减少前端http请求（合并css、js等静态资源）</li><li>添加异步请求，减少http请求的并发量</li><li>启用浏览器的缓存和使用文件压缩</li><li>CDN加速，减轻服务器压力和带宽压力<ul><li>服务端优化  </li></ul><ol><li>页面静态化</li><li>并发处理</li></ol><ul><li>数据库优化  </li></ul><ol><li>数据库缓存</li><li>分库分表，分区操作</li><li>读写分离</li><li>负载均衡</li></ol><ul><li>web服务器优化  </li></ul><ol><li>负载均衡</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、概念&quot;&gt;&lt;a href=&quot;#一、概念&quot; class=&quot;headerlink&quot; title=&quot;一、概念&quot;&gt;&lt;/a&gt;一、概念&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;QPS:每秒钟请求或者查询的数量，通常是指每秒相应请求数（http）&lt;ul&gt;
&lt;li&gt;QPS不等于并发连接数，QPS是每秒的HTTP请求数量，并发连接数是指系统同时处理的请求数量  &lt;/li&gt;
&lt;li&gt;峰值的每秒请求数（QPS）= (总PV数 &lt;em&gt; 80%)/(6小时秒数 &lt;/em&gt; 20%)  &lt;/li&gt;
&lt;li&gt;峰值QPS的计算规律主要是80%的访问量集中在20%的访问时间&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;吞吐量：单位时间内处理请求的数量&lt;/li&gt;
&lt;li&gt;响应时间：从请求发出到收到响应花费的时间&lt;/li&gt;
&lt;li&gt;PV(page view)综合浏览量，即页面点击数。通常日PV在千万级就是高并发的网站&lt;/li&gt;
&lt;li&gt;UV(unique visitor)独立访客，一定时间内相同访客访问网站，只计算为1个独立访客&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>深入理解PHP之：Nginx 与 FPM 的工作机制</title>
    <link href="https://icocos.github.io/2019/02/15/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3PHP%E4%B9%8B%EF%BC%9ANginx-%E4%B8%8E-FPM-%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
    <id>https://icocos.github.io/2019/02/15/深入理解PHP之：Nginx-与-FPM-的工作机制/</id>
    <published>2019-02-15T09:54:22.000Z</published>
    <updated>2019-05-21T08:52:03.574Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>网络上有很多关于如何配置 Nginx + FPM 的文章，但它们更多从操作的角度出发，告诉我们怎么做，但却没有告诉我们为什么要这么做，本文从 Nginx 与 FPM 的工作机制出发，探讨配置背后的原理，让我们真正理解 Nginx 与 PHP 是如何协同工作的。</p><h4 id="内容："><a href="#内容：" class="headerlink" title="内容："></a>内容：</h4><p>要说 Nginx 与 PHP 是如何协同工作的，首先得说 CGI (Common Gateway Interface) 和 FastCGI 这两个协议。</p><a id="more"></a><blockquote><p>CGI 是 Web Server 与后台语言交互的协议，有了这个协议，开发者可以使用任何语言处理 Web Server 发来的请求，动态的生成内容。但 CGI 有一个致命的缺点，那就是每处理一个请求都需要 fork 一个全新的进程，随着 Web 的兴起，高并发越来越成为常态，这样低效的方式明显不能满足需求。就这样，FastCGI 诞生了，CGI 很快就退出了历史的舞台。FastCGI，顾名思义为更快的 CGI，它允许在一个进程内处理多个请求，而不是一个请求处理完毕就直接结束进程，性能上有了很大的提高。</p></blockquote><p>FPM (FastCGI Process Manager)，它是 FastCGI 的实现，任何实现了 FastCGI 协议的 Web Server 都能够与之通信。FPM 之于标准的 FastCGI，也提供了一些增强功能，具体可以参考官方文档：PHP: FPM Installation。</p><pre><code>FPM 是一个 PHP 进程管理器，包含 master 进程和 worker 进程两种进程：master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个 (具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方，下图是我本机上 fpm 的进程情况，1一个 master 进程，3个 worker 进程：</code></pre><p><img src="http://img0.ph.126.net/WMv1Zu5I-rlmKMoUTc68-Q==/6631597730303787300.png" alt="fpm进程"></p><p>从 FPM 接收到请求，到处理完毕，其具体的流程如下：</p><pre><code>1. FPM 的 master 进程接收到请求2. master 进程根据配置指派特定的 worker进程进行请求处理，如果没有可用进程，返回错误，这也是我们配合 Nginx 遇到502错误比较多的原因。3. worker 进程处理请求，如果超时，返回504错误4. 请求处理结束，返回结果</code></pre><p>FPM 从接收到处理请求的流程就是这样了，那么 Nginx 又是如何发送请求给 fpm 的呢？这就需要从 Nginx 层面来说明了。</p><p>Nginx 不仅仅是一个 Web 服务器，也是一个功能强大的 Proxy 服务器，除了进行 http 请求的代理，也可以进行许多其他协议请求的代理，包括本文与 fpm 相关的 fastcgi 协议。为了能够使 Nginx 理解 fastcgi 协议，Nginx 提供了 fastcgi 模块来将 http 请求映射为对应的 fastcgi 请求。</p><blockquote><p>Nginx 的 fastcgi 模块提供了 fastcgi_param 指令来主要处理这些映射关系，下面 Ubuntu 下 Nginx 的一个配置文件，其主要完成的工作是将 Nginx 中的变量翻译成 PHP 中能够理解的变量。</p></blockquote><p><img src="http://img2.ph.126.net/QWqq90MIXEcQnTA7ft1WVg==/6631819831652599451.jpg" alt="fastcgi_param"></p><p>除此之外，非常重要的就是 fastcgi_pass 指令了，这个指令用于指定 fpm 进程监听的地址，Nginx 会把所有的 php 请求翻译成 fastcgi 请求之后再发送到这个地址。下面一个简单的可以工作的 Nginx 配置文件：</p><p><img src="http://img0.ph.126.net/tLal8xnxIanLB_mfp2dHUQ==/6631751661931678563.jpg" alt="nginx配置"></p><p>在这个配置文件中，我们新建了一个虚拟主机，监听在 80 端口，Web 根目录为 /home/rf/projects/wordpress。然后我们通过 location 指令，将所有的以 .php 结尾的请求都交给 fastcgi 模块处理，从而把所有的 php 请求都交给了 fpm 处理，从而完成 Nginx 到 fpm 的闭环。</p><p>如此以来，Nginx 与 FPM 通信的整个流程应该比较清晰了吧。</p><ol><li>nginx是web服务器，提供http服务。</li><li>php代码需要php解析器解析。所以这里要有个nginx和php解析器通信的问题。就出现了一个fastcgi的协议来解决通信问题。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;p&gt;网络上有很多关于如何配置 Nginx + FPM 的文章，但它们更多从操作的角度出发，告诉我们怎么做，但却没有告诉我们为什么要这么做，本文从 Nginx 与 FPM 的工作机制出发，探讨配置背后的原理，让我们真正理解 Nginx 与 PHP 是如何协同工作的。&lt;/p&gt;
&lt;h4 id=&quot;内容：&quot;&gt;&lt;a href=&quot;#内容：&quot; class=&quot;headerlink&quot; title=&quot;内容：&quot;&gt;&lt;/a&gt;内容：&lt;/h4&gt;&lt;p&gt;要说 Nginx 与 PHP 是如何协同工作的，首先得说 CGI (Common Gateway Interface) 和 FastCGI 这两个协议。&lt;/p&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="Nginx" scheme="https://icocos.github.io/tags/Nginx/"/>
    
      <category term="FPM" scheme="https://icocos.github.io/tags/FPM/"/>
    
  </entry>
  
  <entry>
    <title>LVS负载均衡（LVS简介、三种工作模式、十种调度算法）</title>
    <link href="https://icocos.github.io/2019/01/25/LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%EF%BC%88LVS%E7%AE%80%E4%BB%8B%E3%80%81%E4%B8%89%E7%A7%8D%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E3%80%81%E5%8D%81%E7%A7%8D%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%EF%BC%89/"/>
    <id>https://icocos.github.io/2019/01/25/LVS负载均衡（LVS简介、三种工作模式、十种调度算法）/</id>
    <published>2019-01-25T10:47:41.000Z</published>
    <updated>2019-05-22T09:17:26.696Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、LVS简介"><a href="#一、LVS简介" class="headerlink" title="一、LVS简介"></a>一、LVS简介</h3><p>LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。</p><p>该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。</p><a id="more"></a><blockquote><p> 最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。</p></blockquote><h3 id="二、三种工作模式的解析。"><a href="#二、三种工作模式的解析。" class="headerlink" title="二、三种工作模式的解析。"></a>二、三种工作模式的解析。</h3><h5 id="1、基于NAT的LVS模式负载均衡"><a href="#1、基于NAT的LVS模式负载均衡" class="headerlink" title="1、基于NAT的LVS模式负载均衡"></a>1、基于NAT的LVS模式负载均衡</h5><p> NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。VS/NAT工作模式拓扑结构如图2所示，LVS负载调度器可以使用两块网卡配置不同的IP地址，eth0设置为私钥IP与内部网络通过交换设备相互连接，eth1设备为外网IP与外部网络联通。</p><ul><li>第一步，用户通过互联网DNS服务器解析到公司负载均衡设备上面的外网地址，相对于真实服务器而言，LVS外网IP又称VIP（Virtual IP Address），用户通过访问VIP，即可连接后端的真实服务器（Real Server），而这一切对用户而言都是透明的，用户以为自己访问的就是真实服务器，但他并不知道自己访问的VIP仅仅是一个调度器，也不清楚后端的真实服务器到底在哪里、有多少真实服务器。</li><li>第二步，用户将请求发送至124.126.147.168，此时LVS将根据预设的算法选择后端的一台真实服务器（192.168.0.1~192.168.0.3），将数据请求包转发给真实服务器，并且在转发之前LVS会修改数据包中的目标地址以及目标端口，目标地址与目标端口将被修改为选出的真实服务器IP地址以及相应的端口。</li><li>第三步，真实的服务器将响应数据包返回给LVS调度器，调度器在得到响应的数据包后会将源地址和源端口修改为VIP及调度器相应的端口，修改完成后，由调度器将响应数据包发送回终端用户，另外，由于LVS调度器有一个连接Hash表，该表中会记录连接请求及转发信息，当同一个连接的下一个数据包发送给调度器时，从该Hash表中可以直接找到之前的连接记录，并根据记录信息选出相同的真实服务器及端口信息。</li></ul><h5 id="2、基于TUN的LVS负载均衡"><a href="#2、基于TUN的LVS负载均衡" class="headerlink" title="2、基于TUN的LVS负载均衡"></a>2、基于TUN的LVS负载均衡</h5><p>在LVS（NAT）模式的集群环境中，由于所有的数据请求及响应的数据包都需要经过LVS调度器转发，如果后端服务器的数量大于10台，则调度器就会成为整个集群环境的瓶颈。我们知道，数据请求包往往远小于响应数据包的大小。因为响应数据包中包含有客户需要的具体数据，所以LVS（TUN）的思路就是将请求与响应数据分离，让调度器仅处理数据请求，而让真实服务器响应数据包直接返回给客户端。</p><p>VS/TUN工作模式拓扑结构如图3所示。其中，IP隧道（IP tunning）是一种数据包封装技术，它可以将原始数据包封装并添加新的包头（内容包括新的源地址及端口、目标地址及端口），从而实现将一个目标为调度器的VIP地址的数据包封装，通过隧道转发给后端的真实服务器（Real Server），通过将客户端发往调度器的原始数据包封装，并在其基础上添加新的数据包头（修改目标地址为调度器选择出来的真实服务器的IP地址及对应端口），LVS（TUN）模式要求真实服务器可以直接与外部网络连接，真实服务器在收到请求数据包后直接给客户端主机响应数据。</p><h5 id="3、基于DR的LVS负载均衡"><a href="#3、基于DR的LVS负载均衡" class="headerlink" title="3、基于DR的LVS负载均衡"></a>3、基于DR的LVS负载均衡</h5><p>在LVS（TUN）模式下，由于需要在LVS调度器与真实服务器之间创建隧道连接，这同样会增加服务器的负担。与LVS（TUN）类似，DR模式也叫直接路由模式，其体系结构如图4所示，该模式中LVS依然仅承担数据的入站请求以及根据算法选出合理的真实服务器，最终由后端真实服务器负责将响应数据包发送返回给客户端。与隧道模式不同的是，直接路由模式（DR模式）要求调度器与后端服务器必须在同一个局域网内，VIP地址需要在调度器与后端所有的服务器间共享，因为最终的真实服务器给客户端回应数据包时需要设置源IP为VIP地址，目标IP为客户端IP，这样客户端访问的是调度器的VIP地址，回应的源地址也依然是该VIP地址（真实服务器上的VIP），客户端是感觉不到后端服务器存在的。由于多台计算机都设置了同样一个VIP地址，所以在直接路由模式中要求调度器的VIP地址是对外可见的，客户端需要将请求数据包发送到调度器主机，而所有的真实服务器的VIP地址必须配置在Non-ARP的网络设备上，也就是该网络设备并不会向外广播自己的MAC及对应的IP地址，真实服务器的VIP对外界是不可见的，但真实服务器却可以接受目标地址VIP的网络请求，并在回应数据包时将源地址设置为该VIP地址。调度器根据算法在选出真实服务器后，在不修改数据报文的情况下，将数据帧的MAC地址修改为选出的真实服务器的MAC地址，通过交换机将该数据帧发给真实服务器。整个过程中，真实服务器的VIP不需要对外界可见。</p><h3 id="三、LVS负载均衡调度算法"><a href="#三、LVS负载均衡调度算法" class="headerlink" title="三、LVS负载均衡调度算法"></a>三、LVS负载均衡调度算法</h3><p>根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术，LVS在内核中主要实现了一下十种调度算法。</p><h5 id="1-轮询调度"><a href="#1-轮询调度" class="headerlink" title="1.轮询调度"></a>1.轮询调度</h5><p>轮询调度（Round Robin 简称’RR’）算法就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器。</p><h5 id="2-加权轮询调度"><a href="#2-加权轮询调度" class="headerlink" title="2.加权轮询调度"></a>2.加权轮询调度</h5><p>加权轮询（Weight Round Robin 简称’WRR’）算法主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。</p><h5 id="3-最小连接调度"><a href="#3-最小连接调度" class="headerlink" title="3.最小连接调度"></a>3.最小连接调度</h5><p>最小连接调度（Least Connections 简称’LC’）算法是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态的调度算法，它通过服务器当前活跃的连接数来估计服务器的情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中断或者超时，其连接数减1。</p><p>（集群系统的真实服务器具有相近的系统性能，采用最小连接调度算法可以比较好地均衡负载。)</p><h5 id="4-加权最小连接调度"><a href="#4-加权最小连接调度" class="headerlink" title="4.加权最小连接调度"></a>4.加权最小连接调度</h5><p>加权最少连接（Weight Least Connections 简称’WLC’）算法是最小连接调度的超集，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。</p><h5 id="5-基于局部的最少连接"><a href="#5-基于局部的最少连接" class="headerlink" title="5.基于局部的最少连接"></a>5.基于局部的最少连接</h5><p>基于局部的最少连接调度（Locality-Based Least Connections 简称’LBLC’）算法是针对请求报文的目标IP地址的 负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和Cache命中率，从而提升整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则使用’最少连接’的原则选出一个可用的服务器，将请求发送到服务器。</p><h5 id="6-带复制的基于局部性的最少连接"><a href="#6-带复制的基于局部性的最少连接" class="headerlink" title="6.带复制的基于局部性的最少连接"></a>6.带复制的基于局部性的最少连接</h5><p>带复制的基于局部性的最少连接（Locality-Based Least Connections with Replication  简称’LBLCR’）算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统，它与LBLC算法不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。按’最小连接’原则从该服务器组中选出一一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按’最小连接’原则从整个集群中选出一台服务器，将该服务器加入到这个服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。</p><h5 id="7-目标地址散列调度"><a href="#7-目标地址散列调度" class="headerlink" title="7.目标地址散列调度"></a>7.目标地址散列调度</h5><p>目标地址散列调度（Destination Hashing 简称’DH’）算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。</p><h5 id="8-源地址散列调度U"><a href="#8-源地址散列调度U" class="headerlink" title="8.源地址散列调度U"></a>8.源地址散列调度U</h5><p>源地址散列调度（Source Hashing  简称’SH’）算法先根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同，它的算法流程与目标地址散列调度算法的基本相似。</p><h5 id="9-最短的期望的延迟"><a href="#9-最短的期望的延迟" class="headerlink" title="9.最短的期望的延迟"></a>9.最短的期望的延迟</h5><p>最短的期望的延迟调度（Shortest Expected Delay 简称’SED’）算法基于WLC算法。举个例子吧，ABC三台服务器的权重分别为1、2、3 。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用SED算法后会进行一个运算</p><p>A：（1+1）/1=2   B：（1+2）/2=3/2   C：（1+3）/3=4/3   就把请求交给得出运算结果最小的服务器。</p><h5 id="10-最少队列调度"><a href="#10-最少队列调度" class="headerlink" title="10.最少队列调度"></a>10.最少队列调度</h5><p>最少队列调度（Never Queue 简称’NQ’）算法，无需队列。如果有realserver的连接数等于0就直接分配过去，不需要在进行SED运算。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、LVS简介&quot;&gt;&lt;a href=&quot;#一、LVS简介&quot; class=&quot;headerlink&quot; title=&quot;一、LVS简介&quot;&gt;&lt;/a&gt;一、LVS简介&lt;/h3&gt;&lt;p&gt;LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。&lt;/p&gt;
&lt;p&gt;该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。&lt;/p&gt;
    
    </summary>
    
      <category term="PHP" scheme="https://icocos.github.io/categories/PHP/"/>
    
    
      <category term="PHP" scheme="https://icocos.github.io/tags/PHP/"/>
    
      <category term="实战" scheme="https://icocos.github.io/tags/%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
</feed>
